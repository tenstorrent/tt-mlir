//proposed IR for case of abs L1 -> DRAM
//not complete
module attributes {ttcore.system_desc = #ttcore.system_desc<[{role = host, target_triple = "x86_64-pc-linux"}], [{arch = <wormhole_b0>, grid = 8x8, coord_translation_offsets = 18x18, l1_size = 1499136, num_dram_channels = 12, dram_channel_size = 1073741824, noc_l1_address_align_bytes = 16, pcie_address_align_bytes = 32, noc_dram_address_align_bytes = 32, l1_unreserved_base = 102656, erisc_l1_unreserved_base = 98304, dram_unreserved_base = 1920032, dram_unreserved_end = 1073125888, supported_data_types = [<f32>, <f16>, <bf16>, <bfp_f8>, <bfp_bf8>, <bfp_f4>, <bfp_bf4>, <bfp_f2>, <bfp_bf2>, <u32>, <u16>, <u8>, <si32>], supported_tile_sizes = [ 4x16,  16x16,  32x16,  4x32,  16x32,  32x32], dst_physical_size_tiles = 16, num_cbs = 32, num_compute_threads = 1, num_datamovement_threads = 2}], [0], [1 : i32], [ 0x0x0x0]>} {
  ttcore.device @default_device = <workerGrid = #ttcore.grid<8x8, (d0, d1) -> (0, d0, d1)>, l1Map = (d0, d1, d2)[s0] -> (0, d0, d1, d2 + s0), dramMap = (d0, d1, d2)[s0, s1, s2, s3, s4, s5, s6] -> (0, 0, (((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) mod 12, ((((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) floordiv s4) floordiv 12) * s4 + ((d0 * s1) * (s2 * (s3 * s6)) + d1 * (s2 * (s3 * s6)) + d2) mod s4 + s5), meshShape = , chipIds = [0]>
  func.func @abs(%arg0: tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>>) -> tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>> {
    %0 = d2m.empty() : tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>>
    %cast = ttir.ttnn_metal_layout_cast %arg0 : tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>> -> tensor<8x8x4x4x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = map(0)>>
    %view = d2m.view_layout %cast : tensor<8x8x4x4x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = map(0)>> -> tensor<1x1x32x32x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = (d0, d1, d2, d3) -> ((d2 * 32 + d3) floordiv 128, (d3 floordiv 4) mod 8, (d2 + d3 floordiv 32) mod 4, d3 mod 4)>>
    %cast_0 = ttir.ttnn_metal_layout_cast %0 : tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>> -> tensor<8x8x4x4x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = map(0)>>
    %view_1 = d2m.view_layout %cast_0 : tensor<8x8x4x4x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = map(0)>> -> tensor<1x1x32x32x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = (d0, d1, d2, d3) -> ((d2 * 32 + d3) floordiv 128, (d3 floordiv 4) mod 8, (d2 + d3 floordiv 32) mod 4, d3 mod 4)>>
    %1 = d2m.generic {block_factors = [1, 1], grid = #ttcore.grid<1x1>, indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = [#ttcore.iterator_type<parallel>, #ttcore.iterator_type<parallel>], threads = [#d2m.thread<compute>]}
        ins(%view : tensor<1x1x32x32x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = (d0, d1, d2, d3) -> ((d2 * 32 + d3) floordiv 128, (d3 floordiv 4) mod 8, (d2 + d3 floordiv 32) mod 4, d3 mod 4)>>)
        outs(%view_1 : tensor<1x1x32x32x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = (d0, d1, d2, d3) -> ((d2 * 32 + d3) floordiv 128, (d3 floordiv 4) mod 8, (d2 + d3 floordiv 32) mod 4, d3 mod 4)>>)  {
    ^compute0(%cb0: !d2m.cb<tensor<32x32x!ttcore.tile<32x32, bf16>>>, %cb1: !d2m.cb<tensor<32x32x!ttcore.tile<32x32, bf16>>>):
      %2 = d2m.wait %cb0 : <tensor<32x32x!ttcore.tile<32x32, bf16>>> -> tensor<32x32x!ttcore.tile<32x32, bf16>>
      %3 = d2m.reserve %cb1 : <tensor<32x32x!ttcore.tile<32x32, bf16>>> -> tensor<32x32x!ttcore.tile<32x32, bf16>>
      %4 = linalg.generic {indexing_maps = [affine_map<(d0, d1) -> (d0, d1)>, affine_map<(d0, d1) -> (d0, d1)>], iterator_types = ["parallel", "parallel"]} ins(%2 : tensor<32x32x!ttcore.tile<32x32, bf16>>) outs(%3 : tensor<32x32x!ttcore.tile<32x32, bf16>>) {
      ^bb0(%in: !ttcore.tile<32x32, bf16>, %out: !ttcore.tile<32x32, bf16>):
        %5 = "d2m.tile_abs"(%in) : (!ttcore.tile<32x32, bf16>) -> !ttcore.tile<32x32, bf16>
        linalg.yield %5 : !ttcore.tile<32x32, bf16>
      } -> tensor<32x32x!ttcore.tile<32x32, bf16>>
      d2m.yield %4 : (tensor<32x32x!ttcore.tile<32x32, bf16>>)
    } : tensor<1x1x32x32x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = (d0, d1, d2, d3) -> ((d2 * 32 + d3) floordiv 128, (d3 floordiv 4) mod 8, (d2 + d3 floordiv 32) mod 4, d3 mod 4)>>
    %cast_2 = ttir.ttnn_metal_layout_cast %1 : tensor<1x1x32x32x!ttcore.tile<32x32, bf16>, #ttcore.metal_layout<logical_shape = 1024x1024, dim_alignments = 32x32, collapsed_intervals = dense<[[0, -1]]> : tensor<1x2xi64>, undef, l1, sharded, index_map = (d0, d1, d2, d3) -> ((d2 * 32 + d3) floordiv 128, (d3 floordiv 4) mod 8, (d2 + d3 floordiv 32) mod 4, d3 mod 4)>> -> tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>>
    return %cast_2 : tensor<1024x1024xbf16, #ttnn.ttnn_layout<(d0, d1) -> (d0, d1), <8x8>, memref<4x4x!ttcore.tile<32x32, bf16>, #ttnn.buffer_type<l1>>, <block_sharded>, exactGrid = true>>
  }
}
