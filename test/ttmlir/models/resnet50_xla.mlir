module @resnet50_xla_full_model {
  func.func @main(%arg0: tensor<1000xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___classifier_1_bias"}, %arg1: tensor<1000x2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___classifier_1_weight"}, %arg2: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_3_layers_0_shortcut_normalization_running_var"}, %arg3: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_3_layers_0_shortcut_normalization_running_mean"}, %arg4: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_3_layers_0_shortcut_normalization_bias"}, %arg5: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_3_layers_0_shortcut_normalization_weight"}, %arg6: tensor<2048x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_3_layers_0_shortcut_convolution_weight"}, %arg7: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_2_layers_0_shortcut_normalization_running_var"}, %arg8: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_2_layers_0_shortcut_normalization_running_mean"}, %arg9: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_2_layers_0_shortcut_normalization_bias"}, %arg10: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_2_layers_0_shortcut_normalization_weight"}, %arg11: tensor<1024x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_2_layers_0_shortcut_convolution_weight"}, %arg12: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_1_layers_0_shortcut_normalization_running_var"}, %arg13: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_1_layers_0_shortcut_normalization_running_mean"}, %arg14: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_1_layers_0_shortcut_normalization_bias"}, %arg15: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_1_layers_0_shortcut_normalization_weight"}, %arg16: tensor<512x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_1_layers_0_shortcut_convolution_weight"}, %arg17: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_0_layers_0_shortcut_normalization_running_var"}, %arg18: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_0_layers_0_shortcut_normalization_running_mean"}, %arg19: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_0_layers_0_shortcut_normalization_bias"}, %arg20: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_0_layers_0_shortcut_normalization_weight"}, %arg21: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_encoder_stages_0_layers_0_shortcut_convolution_weight"}, %arg22: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_embedder_embedder_normalization_running_var"}, %arg23: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_embedder_embedder_normalization_running_mean"}, %arg24: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_embedder_embedder_normalization_bias"}, %arg25: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_embedder_embedder_normalization_weight"}, %arg26: tensor<64x3x7x7xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "l__self___resnet_embedder_embedder_convolution_weight"}, %arg27: tensor<8x3x224x224xbf16> {ttcore.argument_type = #ttcore.argument_type<input>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "args_0"}, %arg28: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___2___normalization_running_var"}, %arg29: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___2___normalization_running_mean"}, %arg30: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___2___normalization_bias"}, %arg31: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___2___normalization_weight"}, %arg32: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___2___convolution_weight"}, %arg33: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___1___normalization_running_var"}, %arg34: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___1___normalization_running_mean"}, %arg35: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___1___normalization_bias"}, %arg36: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___1___normalization_weight"}, %arg37: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___1___convolution_weight"}, %arg38: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___0___normalization_running_var"}, %arg39: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___0___normalization_running_mean"}, %arg40: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___0___normalization_bias"}, %arg41: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___0___normalization_weight"}, %arg42: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_0_layer___0___convolution_weight"}, %arg43: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___2___normalization_running_var"}, %arg44: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___2___normalization_running_mean"}, %arg45: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___2___normalization_bias"}, %arg46: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___2___normalization_weight"}, %arg47: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___2___convolution_weight"}, %arg48: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___1___normalization_running_var"}, %arg49: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___1___normalization_running_mean"}, %arg50: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___1___normalization_bias"}, %arg51: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___1___normalization_weight"}, %arg52: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___1___convolution_weight"}, %arg53: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___0___normalization_running_var"}, %arg54: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___0___normalization_running_mean"}, %arg55: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___0___normalization_bias"}, %arg56: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___0___normalization_weight"}, %arg57: tensor<64x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_1_layer___0___convolution_weight"}, %arg58: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___2___normalization_running_var"}, %arg59: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___2___normalization_running_mean"}, %arg60: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___2___normalization_bias"}, %arg61: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___2___normalization_weight"}, %arg62: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___2___convolution_weight"}, %arg63: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___1___normalization_running_var"}, %arg64: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___1___normalization_running_mean"}, %arg65: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___1___normalization_bias"}, %arg66: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___1___normalization_weight"}, %arg67: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___1___convolution_weight"}, %arg68: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___0___normalization_running_var"}, %arg69: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___0___normalization_running_mean"}, %arg70: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___0___normalization_bias"}, %arg71: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___0___normalization_weight"}, %arg72: tensor<64x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_0_layers_2_layer___0___convolution_weight"}, %arg73: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___2___normalization_running_var"}, %arg74: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___2___normalization_running_mean"}, %arg75: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___2___normalization_bias"}, %arg76: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___2___normalization_weight"}, %arg77: tensor<512x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___2___convolution_weight"}, %arg78: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___1___normalization_running_var"}, %arg79: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___1___normalization_running_mean"}, %arg80: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___1___normalization_bias"}, %arg81: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___1___normalization_weight"}, %arg82: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___1___convolution_weight"}, %arg83: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___0___normalization_running_var"}, %arg84: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___0___normalization_running_mean"}, %arg85: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___0___normalization_bias"}, %arg86: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___0___normalization_weight"}, %arg87: tensor<128x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_0_layer___0___convolution_weight"}, %arg88: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___2___normalization_running_var"}, %arg89: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___2___normalization_running_mean"}, %arg90: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___2___normalization_bias"}, %arg91: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___2___normalization_weight"}, %arg92: tensor<512x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___2___convolution_weight"}, %arg93: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___1___normalization_running_var"}, %arg94: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___1___normalization_running_mean"}, %arg95: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___1___normalization_bias"}, %arg96: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___1___normalization_weight"}, %arg97: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___1___convolution_weight"}, %arg98: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___0___normalization_running_var"}, %arg99: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___0___normalization_running_mean"}, %arg100: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___0___normalization_bias"}, %arg101: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___0___normalization_weight"}, %arg102: tensor<128x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_1_layer___0___convolution_weight"}, %arg103: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___2___normalization_running_var"}, %arg104: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___2___normalization_running_mean"}, %arg105: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___2___normalization_bias"}, %arg106: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___2___normalization_weight"}, %arg107: tensor<512x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___2___convolution_weight"}, %arg108: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___1___normalization_running_var"}, %arg109: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___1___normalization_running_mean"}, %arg110: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___1___normalization_bias"}, %arg111: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___1___normalization_weight"}, %arg112: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___1___convolution_weight"}, %arg113: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___0___normalization_running_var"}, %arg114: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___0___normalization_running_mean"}, %arg115: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___0___normalization_bias"}, %arg116: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___0___normalization_weight"}, %arg117: tensor<128x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_2_layer___0___convolution_weight"}, %arg118: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___2___normalization_running_var"}, %arg119: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___2___normalization_running_mean"}, %arg120: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___2___normalization_bias"}, %arg121: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___2___normalization_weight"}, %arg122: tensor<512x128x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___2___convolution_weight"}, %arg123: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___1___normalization_running_var"}, %arg124: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___1___normalization_running_mean"}, %arg125: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___1___normalization_bias"}, %arg126: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___1___normalization_weight"}, %arg127: tensor<128x128x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___1___convolution_weight"}, %arg128: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___0___normalization_running_var"}, %arg129: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___0___normalization_running_mean"}, %arg130: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___0___normalization_bias"}, %arg131: tensor<128xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___0___normalization_weight"}, %arg132: tensor<128x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_1_layers_3_layer___0___convolution_weight"}, %arg133: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___2___normalization_running_var"}, %arg134: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___2___normalization_running_mean"}, %arg135: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___2___normalization_bias"}, %arg136: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___2___normalization_weight"}, %arg137: tensor<1024x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___2___convolution_weight"}, %arg138: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___1___normalization_running_var"}, %arg139: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___1___normalization_running_mean"}, %arg140: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___1___normalization_bias"}, %arg141: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___1___normalization_weight"}, %arg142: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___1___convolution_weight"}, %arg143: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___0___normalization_running_var"}, %arg144: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___0___normalization_running_mean"}, %arg145: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___0___normalization_bias"}, %arg146: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___0___normalization_weight"}, %arg147: tensor<256x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_0_layer___0___convolution_weight"}, %arg148: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___2___normalization_running_var"}, %arg149: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___2___normalization_running_mean"}, %arg150: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___2___normalization_bias"}, %arg151: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___2___normalization_weight"}, %arg152: tensor<1024x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___2___convolution_weight"}, %arg153: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___1___normalization_running_var"}, %arg154: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___1___normalization_running_mean"}, %arg155: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___1___normalization_bias"}, %arg156: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___1___normalization_weight"}, %arg157: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___1___convolution_weight"}, %arg158: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___0___normalization_running_var"}, %arg159: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___0___normalization_running_mean"}, %arg160: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___0___normalization_bias"}, %arg161: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___0___normalization_weight"}, %arg162: tensor<256x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_1_layer___0___convolution_weight"}, %arg163: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___2___normalization_running_var"}, %arg164: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___2___normalization_running_mean"}, %arg165: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___2___normalization_bias"}, %arg166: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___2___normalization_weight"}, %arg167: tensor<1024x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___2___convolution_weight"}, %arg168: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___1___normalization_running_var"}, %arg169: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___1___normalization_running_mean"}, %arg170: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___1___normalization_bias"}, %arg171: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___1___normalization_weight"}, %arg172: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___1___convolution_weight"}, %arg173: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___0___normalization_running_var"}, %arg174: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___0___normalization_running_mean"}, %arg175: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___0___normalization_bias"}, %arg176: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___0___normalization_weight"}, %arg177: tensor<256x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_2_layer___0___convolution_weight"}, %arg178: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___2___normalization_running_var"}, %arg179: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___2___normalization_running_mean"}, %arg180: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___2___normalization_bias"}, %arg181: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___2___normalization_weight"}, %arg182: tensor<1024x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___2___convolution_weight"}, %arg183: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___1___normalization_running_var"}, %arg184: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___1___normalization_running_mean"}, %arg185: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___1___normalization_bias"}, %arg186: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___1___normalization_weight"}, %arg187: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___1___convolution_weight"}, %arg188: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___0___normalization_running_var"}, %arg189: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___0___normalization_running_mean"}, %arg190: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___0___normalization_bias"}, %arg191: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___0___normalization_weight"}, %arg192: tensor<256x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_3_layer___0___convolution_weight"}, %arg193: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___2___normalization_running_var"}, %arg194: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___2___normalization_running_mean"}, %arg195: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___2___normalization_bias"}, %arg196: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___2___normalization_weight"}, %arg197: tensor<1024x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___2___convolution_weight"}, %arg198: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___1___normalization_running_var"}, %arg199: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___1___normalization_running_mean"}, %arg200: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___1___normalization_bias"}, %arg201: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___1___normalization_weight"}, %arg202: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___1___convolution_weight"}, %arg203: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___0___normalization_running_var"}, %arg204: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___0___normalization_running_mean"}, %arg205: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___0___normalization_bias"}, %arg206: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___0___normalization_weight"}, %arg207: tensor<256x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_4_layer___0___convolution_weight"}, %arg208: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___2___normalization_running_var"}, %arg209: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___2___normalization_running_mean"}, %arg210: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___2___normalization_bias"}, %arg211: tensor<1024xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___2___normalization_weight"}, %arg212: tensor<1024x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___2___convolution_weight"}, %arg213: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___1___normalization_running_var"}, %arg214: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___1___normalization_running_mean"}, %arg215: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___1___normalization_bias"}, %arg216: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___1___normalization_weight"}, %arg217: tensor<256x256x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___1___convolution_weight"}, %arg218: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___0___normalization_running_var"}, %arg219: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___0___normalization_running_mean"}, %arg220: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___0___normalization_bias"}, %arg221: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___0___normalization_weight"}, %arg222: tensor<256x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_2_layers_5_layer___0___convolution_weight"}, %arg223: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___2___normalization_running_var"}, %arg224: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___2___normalization_running_mean"}, %arg225: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___2___normalization_bias"}, %arg226: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___2___normalization_weight"}, %arg227: tensor<2048x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___2___convolution_weight"}, %arg228: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___1___normalization_running_var"}, %arg229: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___1___normalization_running_mean"}, %arg230: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___1___normalization_bias"}, %arg231: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___1___normalization_weight"}, %arg232: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___1___convolution_weight"}, %arg233: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___0___normalization_running_var"}, %arg234: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___0___normalization_running_mean"}, %arg235: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___0___normalization_bias"}, %arg236: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___0___normalization_weight"}, %arg237: tensor<512x1024x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_0_layer___0___convolution_weight"}, %arg238: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___2___normalization_running_var"}, %arg239: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___2___normalization_running_mean"}, %arg240: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___2___normalization_bias"}, %arg241: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___2___normalization_weight"}, %arg242: tensor<2048x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___2___convolution_weight"}, %arg243: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___1___normalization_running_var"}, %arg244: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___1___normalization_running_mean"}, %arg245: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___1___normalization_bias"}, %arg246: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___1___normalization_weight"}, %arg247: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___1___convolution_weight"}, %arg248: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___0___normalization_running_var"}, %arg249: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___0___normalization_running_mean"}, %arg250: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___0___normalization_bias"}, %arg251: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___0___normalization_weight"}, %arg252: tensor<512x2048x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_1_layer___0___convolution_weight"}, %arg253: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___2___normalization_running_var"}, %arg254: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___2___normalization_running_mean"}, %arg255: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___2___normalization_bias"}, %arg256: tensor<2048xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___2___normalization_weight"}, %arg257: tensor<2048x512x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___2___convolution_weight"}, %arg258: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___1___normalization_running_var"}, %arg259: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___1___normalization_running_mean"}, %arg260: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___1___normalization_bias"}, %arg261: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___1___normalization_weight"}, %arg262: tensor<512x512x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___1___convolution_weight"}, %arg263: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___0___normalization_running_var"}, %arg264: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___0___normalization_running_mean"}, %arg265: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___0___normalization_bias"}, %arg266: tensor<512xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___0___normalization_weight"}, %arg267: tensor<512x2048x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>, ttcore.shard_status = #ttcore.shard_status<unsharded>, ttir.name = "getattr_l__self___resnet_encoder_stages_3_layers_2_layer___0___convolution_weight"}) -> (tensor<8x1000xbf16> {ttcore.shard_status = #ttcore.shard_status<unsharded>}) {
    %0 = "ttir.constant"() <{value = dense<2.038570e-02> : tensor<8x2048xbf16>}> : () -> tensor<8x2048xbf16>
    %1 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x2048x7x7xbf16>}> : () -> tensor<8x2048x7x7xbf16>
    %2 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x512x7x7xbf16>}> : () -> tensor<8x512x7x7xbf16>
    %3 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x512x14x14xbf16>}> : () -> tensor<8x512x14x14xbf16>
    %4 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x1024x14x14xbf16>}> : () -> tensor<8x1024x14x14xbf16>
    %5 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x256x14x14xbf16>}> : () -> tensor<8x256x14x14xbf16>
    %6 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x256x28x28xbf16>}> : () -> tensor<8x256x28x28xbf16>
    %7 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x512x28x28xbf16>}> : () -> tensor<8x512x28x28xbf16>
    %8 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x128x28x28xbf16>}> : () -> tensor<8x128x28x28xbf16>
    %9 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x128x56x56xbf16>}> : () -> tensor<8x128x56x56xbf16>
    %10 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x256x56x56xbf16>}> : () -> tensor<8x256x56x56xbf16>
    %11 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x64x56x56xbf16>}> : () -> tensor<8x64x56x56xbf16>
    %12 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<8x64x112x112xbf16>}> : () -> tensor<8x64x112x112xbf16>
    %13 = "ttir.reshape"(%arg22) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %14 = "ttir.reshape"(%13) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %15 = "ttir.permute"(%arg26) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x3x7x7xbf16>) -> tensor<64x3x7x7xbf16>
    %16 = "ttir.conv2d"(%arg27, %15) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 3, 3, 3, 3>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x3x224x224xbf16>, tensor<64x3x7x7xbf16>) -> tensor<8x64x112x112xbf16>
    %17 = "ttir.reshape"(%arg25) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %18 = "ttir.reshape"(%17) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %19 = "ttir.reshape"(%arg24) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %20 = "ttir.reshape"(%19) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %21 = "ttir.reshape"(%arg23) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %22 = "ttir.reshape"(%21) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %23 = "ttir.batch_norm_inference"(%16, %18, %20, %22, %14) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x112x112xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x112x112xbf16>
    %24 = "ttir.maximum"(%23, %12) : (tensor<8x64x112x112xbf16>, tensor<8x64x112x112xbf16>) -> tensor<8x64x112x112xbf16>
    %25 = "ttir.pad"(%24) <{padding = array<i32: 0, 0, 0, 0, 1, 1, 1, 1>, value = 0xFF800000 : f32}> : (tensor<8x64x112x112xbf16>) -> tensor<8x64x114x114xbf16>
    %26 = "ttir.permute"(%25) <{permutation = array<i64: 0, 2, 3, 1>}> : (tensor<8x64x114x114xbf16>) -> tensor<8x114x114x64xbf16>
    %27 = "ttir.max_pool2d"(%26) <{ceil_mode = false, dilation = array<i32: 1, 1>, kernel = array<i32: 3, 3>, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 2, 2>}> : (tensor<8x114x114x64xbf16>) -> tensor<8x56x56x64xbf16>
    %28 = "ttir.permute"(%27) <{permutation = array<i64: 0, 3, 1, 2>}> : (tensor<8x56x56x64xbf16>) -> tensor<8x64x56x56xbf16>
    %29 = "ttir.reshape"(%arg17) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %30 = "ttir.reshape"(%29) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %31 = "ttir.reshape"(%arg38) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %32 = "ttir.reshape"(%31) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %33 = "ttir.reshape"(%arg33) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %34 = "ttir.reshape"(%33) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %35 = "ttir.reshape"(%arg28) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %36 = "ttir.reshape"(%35) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %37 = "ttir.reshape"(%arg53) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %38 = "ttir.reshape"(%37) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %39 = "ttir.reshape"(%arg48) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %40 = "ttir.reshape"(%39) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %41 = "ttir.reshape"(%arg43) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %42 = "ttir.reshape"(%41) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %43 = "ttir.reshape"(%arg68) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %44 = "ttir.reshape"(%43) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %45 = "ttir.reshape"(%arg63) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %46 = "ttir.reshape"(%45) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %47 = "ttir.reshape"(%arg58) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %48 = "ttir.reshape"(%47) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %49 = "ttir.reshape"(%arg12) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %50 = "ttir.reshape"(%49) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %51 = "ttir.reshape"(%arg83) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %52 = "ttir.reshape"(%51) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %53 = "ttir.reshape"(%arg78) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %54 = "ttir.reshape"(%53) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %55 = "ttir.reshape"(%arg73) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %56 = "ttir.reshape"(%55) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %57 = "ttir.reshape"(%arg98) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %58 = "ttir.reshape"(%57) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %59 = "ttir.reshape"(%arg93) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %60 = "ttir.reshape"(%59) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %61 = "ttir.reshape"(%arg88) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %62 = "ttir.reshape"(%61) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %63 = "ttir.reshape"(%arg113) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %64 = "ttir.reshape"(%63) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %65 = "ttir.reshape"(%arg108) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %66 = "ttir.reshape"(%65) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %67 = "ttir.reshape"(%arg103) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %68 = "ttir.reshape"(%67) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %69 = "ttir.reshape"(%arg128) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %70 = "ttir.reshape"(%69) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %71 = "ttir.reshape"(%arg123) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %72 = "ttir.reshape"(%71) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %73 = "ttir.reshape"(%arg118) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %74 = "ttir.reshape"(%73) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %75 = "ttir.reshape"(%arg7) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %76 = "ttir.reshape"(%75) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %77 = "ttir.reshape"(%arg143) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %78 = "ttir.reshape"(%77) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %79 = "ttir.reshape"(%arg138) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %80 = "ttir.reshape"(%79) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %81 = "ttir.reshape"(%arg133) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %82 = "ttir.reshape"(%81) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %83 = "ttir.reshape"(%arg158) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %84 = "ttir.reshape"(%83) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %85 = "ttir.reshape"(%arg153) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %86 = "ttir.reshape"(%85) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %87 = "ttir.reshape"(%arg148) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %88 = "ttir.reshape"(%87) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %89 = "ttir.reshape"(%arg173) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %90 = "ttir.reshape"(%89) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %91 = "ttir.reshape"(%arg168) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %92 = "ttir.reshape"(%91) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %93 = "ttir.reshape"(%arg163) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %94 = "ttir.reshape"(%93) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %95 = "ttir.reshape"(%arg188) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %96 = "ttir.reshape"(%95) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %97 = "ttir.reshape"(%arg183) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %98 = "ttir.reshape"(%97) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %99 = "ttir.reshape"(%arg178) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %100 = "ttir.reshape"(%99) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %101 = "ttir.reshape"(%arg203) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %102 = "ttir.reshape"(%101) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %103 = "ttir.reshape"(%arg198) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %104 = "ttir.reshape"(%103) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %105 = "ttir.reshape"(%arg193) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %106 = "ttir.reshape"(%105) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %107 = "ttir.reshape"(%arg218) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %108 = "ttir.reshape"(%107) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %109 = "ttir.reshape"(%arg213) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %110 = "ttir.reshape"(%109) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %111 = "ttir.reshape"(%arg208) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %112 = "ttir.reshape"(%111) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %113 = "ttir.reshape"(%arg2) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %114 = "ttir.reshape"(%113) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %115 = "ttir.reshape"(%arg233) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %116 = "ttir.reshape"(%115) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %117 = "ttir.reshape"(%arg228) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %118 = "ttir.reshape"(%117) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %119 = "ttir.reshape"(%arg223) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %120 = "ttir.reshape"(%119) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %121 = "ttir.reshape"(%arg248) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %122 = "ttir.reshape"(%121) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %123 = "ttir.reshape"(%arg243) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %124 = "ttir.reshape"(%123) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %125 = "ttir.reshape"(%arg238) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %126 = "ttir.reshape"(%125) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %127 = "ttir.reshape"(%arg263) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %128 = "ttir.reshape"(%127) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %129 = "ttir.reshape"(%arg258) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %130 = "ttir.reshape"(%129) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %131 = "ttir.reshape"(%arg253) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %132 = "ttir.reshape"(%131) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %133 = "ttir.permute"(%arg42) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x64x1x1xbf16>) -> tensor<64x64x1x1xbf16>
    %134 = "ttir.conv2d"(%28, %133) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<64x64x1x1xbf16>) -> tensor<8x64x56x56xbf16>
    %135 = "ttir.reshape"(%arg41) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %136 = "ttir.reshape"(%135) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %137 = "ttir.reshape"(%arg40) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %138 = "ttir.reshape"(%137) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %139 = "ttir.reshape"(%arg39) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %140 = "ttir.reshape"(%139) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %141 = "ttir.batch_norm_inference"(%134, %136, %138, %140, %32) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x56x56xbf16>
    %142 = "ttir.maximum"(%141, %11) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16>
    %143 = "ttir.permute"(%arg37) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x64x3x3xbf16>) -> tensor<64x64x3x3xbf16>
    %144 = "ttir.conv2d"(%142, %143) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<64x64x3x3xbf16>) -> tensor<8x64x56x56xbf16>
    %145 = "ttir.reshape"(%arg36) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %146 = "ttir.reshape"(%145) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %147 = "ttir.reshape"(%arg35) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %148 = "ttir.reshape"(%147) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %149 = "ttir.reshape"(%arg34) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %150 = "ttir.reshape"(%149) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %151 = "ttir.batch_norm_inference"(%144, %146, %148, %150, %34) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x56x56xbf16>
    %152 = "ttir.maximum"(%151, %11) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16>
    %153 = "ttir.permute"(%arg32) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x64x1x1xbf16>) -> tensor<256x64x1x1xbf16>
    %154 = "ttir.conv2d"(%152, %153) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<8x256x56x56xbf16>
    %155 = "ttir.reshape"(%arg31) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %156 = "ttir.reshape"(%155) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %157 = "ttir.reshape"(%arg30) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %158 = "ttir.reshape"(%157) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %159 = "ttir.reshape"(%arg29) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %160 = "ttir.reshape"(%159) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %161 = "ttir.batch_norm_inference"(%154, %156, %158, %160, %36) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x56x56xbf16>
    %162 = "ttir.permute"(%arg21) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x64x1x1xbf16>) -> tensor<256x64x1x1xbf16>
    %163 = "ttir.conv2d"(%28, %162) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<8x256x56x56xbf16>
    %164 = "ttir.reshape"(%arg20) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %165 = "ttir.reshape"(%164) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %166 = "ttir.reshape"(%arg19) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %167 = "ttir.reshape"(%166) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %168 = "ttir.reshape"(%arg18) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %169 = "ttir.reshape"(%168) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %170 = "ttir.batch_norm_inference"(%163, %165, %167, %169, %30) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x56x56xbf16>
    %171 = "ttir.add"(%161, %170) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16>
    %172 = "ttir.maximum"(%171, %10) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16>
    %173 = "ttir.permute"(%arg57) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x256x1x1xbf16>) -> tensor<64x256x1x1xbf16>
    %174 = "ttir.conv2d"(%172, %173) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x56x56xbf16>, tensor<64x256x1x1xbf16>) -> tensor<8x64x56x56xbf16>
    %175 = "ttir.reshape"(%arg56) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %176 = "ttir.reshape"(%175) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %177 = "ttir.reshape"(%arg55) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %178 = "ttir.reshape"(%177) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %179 = "ttir.reshape"(%arg54) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %180 = "ttir.reshape"(%179) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %181 = "ttir.batch_norm_inference"(%174, %176, %178, %180, %38) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x56x56xbf16>
    %182 = "ttir.maximum"(%181, %11) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16>
    %183 = "ttir.permute"(%arg52) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x64x3x3xbf16>) -> tensor<64x64x3x3xbf16>
    %184 = "ttir.conv2d"(%182, %183) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<64x64x3x3xbf16>) -> tensor<8x64x56x56xbf16>
    %185 = "ttir.reshape"(%arg51) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %186 = "ttir.reshape"(%185) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %187 = "ttir.reshape"(%arg50) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %188 = "ttir.reshape"(%187) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %189 = "ttir.reshape"(%arg49) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %190 = "ttir.reshape"(%189) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %191 = "ttir.batch_norm_inference"(%184, %186, %188, %190, %40) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x56x56xbf16>
    %192 = "ttir.maximum"(%191, %11) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16>
    %193 = "ttir.permute"(%arg47) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x64x1x1xbf16>) -> tensor<256x64x1x1xbf16>
    %194 = "ttir.conv2d"(%192, %193) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<8x256x56x56xbf16>
    %195 = "ttir.reshape"(%arg46) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %196 = "ttir.reshape"(%195) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %197 = "ttir.reshape"(%arg45) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %198 = "ttir.reshape"(%197) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %199 = "ttir.reshape"(%arg44) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %200 = "ttir.reshape"(%199) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %201 = "ttir.batch_norm_inference"(%194, %196, %198, %200, %42) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x56x56xbf16>
    %202 = "ttir.add"(%201, %172) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16>
    %203 = "ttir.maximum"(%202, %10) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16>
    %204 = "ttir.permute"(%arg72) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x256x1x1xbf16>) -> tensor<64x256x1x1xbf16>
    %205 = "ttir.conv2d"(%203, %204) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x56x56xbf16>, tensor<64x256x1x1xbf16>) -> tensor<8x64x56x56xbf16>
    %206 = "ttir.reshape"(%arg71) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %207 = "ttir.reshape"(%206) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %208 = "ttir.reshape"(%arg70) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %209 = "ttir.reshape"(%208) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %210 = "ttir.reshape"(%arg69) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %211 = "ttir.reshape"(%210) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %212 = "ttir.batch_norm_inference"(%205, %207, %209, %211, %44) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x56x56xbf16>
    %213 = "ttir.maximum"(%212, %11) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16>
    %214 = "ttir.permute"(%arg67) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<64x64x3x3xbf16>) -> tensor<64x64x3x3xbf16>
    %215 = "ttir.conv2d"(%213, %214) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<64x64x3x3xbf16>) -> tensor<8x64x56x56xbf16>
    %216 = "ttir.reshape"(%arg66) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %217 = "ttir.reshape"(%216) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %218 = "ttir.reshape"(%arg65) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %219 = "ttir.reshape"(%218) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %220 = "ttir.reshape"(%arg64) <{shape = [1 : i32, 1 : i32, 64 : i32]}> : (tensor<64xbf16>) -> tensor<1x1x64xbf16>
    %221 = "ttir.reshape"(%220) <{shape = [64 : i32]}> : (tensor<1x1x64xbf16>) -> tensor<64xbf16>
    %222 = "ttir.batch_norm_inference"(%215, %217, %219, %221, %46) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<8x64x56x56xbf16>
    %223 = "ttir.maximum"(%222, %11) : (tensor<8x64x56x56xbf16>, tensor<8x64x56x56xbf16>) -> tensor<8x64x56x56xbf16>
    %224 = "ttir.permute"(%arg62) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x64x1x1xbf16>) -> tensor<256x64x1x1xbf16>
    %225 = "ttir.conv2d"(%223, %224) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<8x256x56x56xbf16>
    %226 = "ttir.reshape"(%arg61) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %227 = "ttir.reshape"(%226) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %228 = "ttir.reshape"(%arg60) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %229 = "ttir.reshape"(%228) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %230 = "ttir.reshape"(%arg59) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %231 = "ttir.reshape"(%230) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %232 = "ttir.batch_norm_inference"(%225, %227, %229, %231, %48) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x56x56xbf16>
    %233 = "ttir.add"(%232, %203) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16>
    %234 = "ttir.maximum"(%233, %10) : (tensor<8x256x56x56xbf16>, tensor<8x256x56x56xbf16>) -> tensor<8x256x56x56xbf16>
    %235 = "ttir.permute"(%arg87) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x256x1x1xbf16>) -> tensor<128x256x1x1xbf16>
    %236 = "ttir.conv2d"(%234, %235) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x56x56xbf16>, tensor<128x256x1x1xbf16>) -> tensor<8x128x56x56xbf16>
    %237 = "ttir.reshape"(%arg86) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %238 = "ttir.reshape"(%237) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %239 = "ttir.reshape"(%arg85) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %240 = "ttir.reshape"(%239) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %241 = "ttir.reshape"(%arg84) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %242 = "ttir.reshape"(%241) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %243 = "ttir.batch_norm_inference"(%236, %238, %240, %242, %52) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x56x56xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x56x56xbf16>
    %244 = "ttir.maximum"(%243, %9) : (tensor<8x128x56x56xbf16>, tensor<8x128x56x56xbf16>) -> tensor<8x128x56x56xbf16>
    %245 = "ttir.permute"(%arg82) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x128x3x3xbf16>) -> tensor<128x128x3x3xbf16>
    %246 = "ttir.conv2d"(%244, %245) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x128x56x56xbf16>, tensor<128x128x3x3xbf16>) -> tensor<8x128x28x28xbf16>
    %247 = "ttir.reshape"(%arg81) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %248 = "ttir.reshape"(%247) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %249 = "ttir.reshape"(%arg80) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %250 = "ttir.reshape"(%249) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %251 = "ttir.reshape"(%arg79) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %252 = "ttir.reshape"(%251) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %253 = "ttir.batch_norm_inference"(%246, %248, %250, %252, %54) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %254 = "ttir.maximum"(%253, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %255 = "ttir.permute"(%arg77) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x128x1x1xbf16>) -> tensor<512x128x1x1xbf16>
    %256 = "ttir.conv2d"(%254, %255) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<512x128x1x1xbf16>) -> tensor<8x512x28x28xbf16>
    %257 = "ttir.reshape"(%arg76) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %258 = "ttir.reshape"(%257) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %259 = "ttir.reshape"(%arg75) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %260 = "ttir.reshape"(%259) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %261 = "ttir.reshape"(%arg74) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %262 = "ttir.reshape"(%261) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %263 = "ttir.batch_norm_inference"(%256, %258, %260, %262, %56) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x28x28xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x28x28xbf16>
    %264 = "ttir.permute"(%arg16) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x256x1x1xbf16>) -> tensor<512x256x1x1xbf16>
    %265 = "ttir.conv2d"(%234, %264) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x256x56x56xbf16>, tensor<512x256x1x1xbf16>) -> tensor<8x512x28x28xbf16>
    %266 = "ttir.reshape"(%arg15) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %267 = "ttir.reshape"(%266) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %268 = "ttir.reshape"(%arg14) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %269 = "ttir.reshape"(%268) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %270 = "ttir.reshape"(%arg13) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %271 = "ttir.reshape"(%270) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %272 = "ttir.batch_norm_inference"(%265, %267, %269, %271, %50) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x28x28xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x28x28xbf16>
    %273 = "ttir.add"(%263, %272) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %274 = "ttir.maximum"(%273, %7) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %275 = "ttir.permute"(%arg102) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x512x1x1xbf16>) -> tensor<128x512x1x1xbf16>
    %276 = "ttir.conv2d"(%274, %275) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x28x28xbf16>, tensor<128x512x1x1xbf16>) -> tensor<8x128x28x28xbf16>
    %277 = "ttir.reshape"(%arg101) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %278 = "ttir.reshape"(%277) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %279 = "ttir.reshape"(%arg100) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %280 = "ttir.reshape"(%279) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %281 = "ttir.reshape"(%arg99) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %282 = "ttir.reshape"(%281) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %283 = "ttir.batch_norm_inference"(%276, %278, %280, %282, %58) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %284 = "ttir.maximum"(%283, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %285 = "ttir.permute"(%arg97) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x128x3x3xbf16>) -> tensor<128x128x3x3xbf16>
    %286 = "ttir.conv2d"(%284, %285) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<128x128x3x3xbf16>) -> tensor<8x128x28x28xbf16>
    %287 = "ttir.reshape"(%arg96) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %288 = "ttir.reshape"(%287) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %289 = "ttir.reshape"(%arg95) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %290 = "ttir.reshape"(%289) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %291 = "ttir.reshape"(%arg94) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %292 = "ttir.reshape"(%291) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %293 = "ttir.batch_norm_inference"(%286, %288, %290, %292, %60) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %294 = "ttir.maximum"(%293, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %295 = "ttir.permute"(%arg92) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x128x1x1xbf16>) -> tensor<512x128x1x1xbf16>
    %296 = "ttir.conv2d"(%294, %295) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<512x128x1x1xbf16>) -> tensor<8x512x28x28xbf16>
    %297 = "ttir.reshape"(%arg91) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %298 = "ttir.reshape"(%297) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %299 = "ttir.reshape"(%arg90) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %300 = "ttir.reshape"(%299) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %301 = "ttir.reshape"(%arg89) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %302 = "ttir.reshape"(%301) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %303 = "ttir.batch_norm_inference"(%296, %298, %300, %302, %62) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x28x28xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x28x28xbf16>
    %304 = "ttir.add"(%303, %274) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %305 = "ttir.maximum"(%304, %7) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %306 = "ttir.permute"(%arg117) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x512x1x1xbf16>) -> tensor<128x512x1x1xbf16>
    %307 = "ttir.conv2d"(%305, %306) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x28x28xbf16>, tensor<128x512x1x1xbf16>) -> tensor<8x128x28x28xbf16>
    %308 = "ttir.reshape"(%arg116) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %309 = "ttir.reshape"(%308) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %310 = "ttir.reshape"(%arg115) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %311 = "ttir.reshape"(%310) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %312 = "ttir.reshape"(%arg114) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %313 = "ttir.reshape"(%312) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %314 = "ttir.batch_norm_inference"(%307, %309, %311, %313, %64) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %315 = "ttir.maximum"(%314, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %316 = "ttir.permute"(%arg112) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x128x3x3xbf16>) -> tensor<128x128x3x3xbf16>
    %317 = "ttir.conv2d"(%315, %316) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<128x128x3x3xbf16>) -> tensor<8x128x28x28xbf16>
    %318 = "ttir.reshape"(%arg111) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %319 = "ttir.reshape"(%318) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %320 = "ttir.reshape"(%arg110) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %321 = "ttir.reshape"(%320) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %322 = "ttir.reshape"(%arg109) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %323 = "ttir.reshape"(%322) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %324 = "ttir.batch_norm_inference"(%317, %319, %321, %323, %66) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %325 = "ttir.maximum"(%324, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %326 = "ttir.permute"(%arg107) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x128x1x1xbf16>) -> tensor<512x128x1x1xbf16>
    %327 = "ttir.conv2d"(%325, %326) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<512x128x1x1xbf16>) -> tensor<8x512x28x28xbf16>
    %328 = "ttir.reshape"(%arg106) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %329 = "ttir.reshape"(%328) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %330 = "ttir.reshape"(%arg105) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %331 = "ttir.reshape"(%330) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %332 = "ttir.reshape"(%arg104) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %333 = "ttir.reshape"(%332) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %334 = "ttir.batch_norm_inference"(%327, %329, %331, %333, %68) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x28x28xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x28x28xbf16>
    %335 = "ttir.add"(%334, %305) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %336 = "ttir.maximum"(%335, %7) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %337 = "ttir.permute"(%arg132) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x512x1x1xbf16>) -> tensor<128x512x1x1xbf16>
    %338 = "ttir.conv2d"(%336, %337) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x28x28xbf16>, tensor<128x512x1x1xbf16>) -> tensor<8x128x28x28xbf16>
    %339 = "ttir.reshape"(%arg131) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %340 = "ttir.reshape"(%339) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %341 = "ttir.reshape"(%arg130) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %342 = "ttir.reshape"(%341) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %343 = "ttir.reshape"(%arg129) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %344 = "ttir.reshape"(%343) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %345 = "ttir.batch_norm_inference"(%338, %340, %342, %344, %70) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %346 = "ttir.maximum"(%345, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %347 = "ttir.permute"(%arg127) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<128x128x3x3xbf16>) -> tensor<128x128x3x3xbf16>
    %348 = "ttir.conv2d"(%346, %347) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<128x128x3x3xbf16>) -> tensor<8x128x28x28xbf16>
    %349 = "ttir.reshape"(%arg126) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %350 = "ttir.reshape"(%349) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %351 = "ttir.reshape"(%arg125) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %352 = "ttir.reshape"(%351) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %353 = "ttir.reshape"(%arg124) <{shape = [1 : i32, 1 : i32, 128 : i32]}> : (tensor<128xbf16>) -> tensor<1x1x128xbf16>
    %354 = "ttir.reshape"(%353) <{shape = [128 : i32]}> : (tensor<1x1x128xbf16>) -> tensor<128xbf16>
    %355 = "ttir.batch_norm_inference"(%348, %350, %352, %354, %72) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x128x28x28xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>, tensor<128xbf16>) -> tensor<8x128x28x28xbf16>
    %356 = "ttir.maximum"(%355, %8) : (tensor<8x128x28x28xbf16>, tensor<8x128x28x28xbf16>) -> tensor<8x128x28x28xbf16>
    %357 = "ttir.permute"(%arg122) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x128x1x1xbf16>) -> tensor<512x128x1x1xbf16>
    %358 = "ttir.conv2d"(%356, %357) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x128x28x28xbf16>, tensor<512x128x1x1xbf16>) -> tensor<8x512x28x28xbf16>
    %359 = "ttir.reshape"(%arg121) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %360 = "ttir.reshape"(%359) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %361 = "ttir.reshape"(%arg120) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %362 = "ttir.reshape"(%361) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %363 = "ttir.reshape"(%arg119) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %364 = "ttir.reshape"(%363) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %365 = "ttir.batch_norm_inference"(%358, %360, %362, %364, %74) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x28x28xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x28x28xbf16>
    %366 = "ttir.add"(%365, %336) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %367 = "ttir.maximum"(%366, %7) : (tensor<8x512x28x28xbf16>, tensor<8x512x28x28xbf16>) -> tensor<8x512x28x28xbf16>
    %368 = "ttir.permute"(%arg147) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x512x1x1xbf16>) -> tensor<256x512x1x1xbf16>
    %369 = "ttir.conv2d"(%367, %368) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x28x28xbf16>, tensor<256x512x1x1xbf16>) -> tensor<8x256x28x28xbf16>
    %370 = "ttir.reshape"(%arg146) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %371 = "ttir.reshape"(%370) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %372 = "ttir.reshape"(%arg145) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %373 = "ttir.reshape"(%372) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %374 = "ttir.reshape"(%arg144) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %375 = "ttir.reshape"(%374) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %376 = "ttir.batch_norm_inference"(%369, %371, %373, %375, %78) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x28x28xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x28x28xbf16>
    %377 = "ttir.maximum"(%376, %6) : (tensor<8x256x28x28xbf16>, tensor<8x256x28x28xbf16>) -> tensor<8x256x28x28xbf16>
    %378 = "ttir.permute"(%arg142) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x256x3x3xbf16>) -> tensor<256x256x3x3xbf16>
    %379 = "ttir.conv2d"(%377, %378) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x256x28x28xbf16>, tensor<256x256x3x3xbf16>) -> tensor<8x256x14x14xbf16>
    %380 = "ttir.reshape"(%arg141) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %381 = "ttir.reshape"(%380) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %382 = "ttir.reshape"(%arg140) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %383 = "ttir.reshape"(%382) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %384 = "ttir.reshape"(%arg139) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %385 = "ttir.reshape"(%384) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %386 = "ttir.batch_norm_inference"(%379, %381, %383, %385, %80) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %387 = "ttir.maximum"(%386, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %388 = "ttir.permute"(%arg137) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x256x1x1xbf16>) -> tensor<1024x256x1x1xbf16>
    %389 = "ttir.conv2d"(%387, %388) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<1024x256x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %390 = "ttir.reshape"(%arg136) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %391 = "ttir.reshape"(%390) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %392 = "ttir.reshape"(%arg135) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %393 = "ttir.reshape"(%392) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %394 = "ttir.reshape"(%arg134) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %395 = "ttir.reshape"(%394) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %396 = "ttir.batch_norm_inference"(%389, %391, %393, %395, %82) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %397 = "ttir.permute"(%arg11) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x512x1x1xbf16>) -> tensor<1024x512x1x1xbf16>
    %398 = "ttir.conv2d"(%367, %397) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x512x28x28xbf16>, tensor<1024x512x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %399 = "ttir.reshape"(%arg10) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %400 = "ttir.reshape"(%399) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %401 = "ttir.reshape"(%arg9) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %402 = "ttir.reshape"(%401) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %403 = "ttir.reshape"(%arg8) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %404 = "ttir.reshape"(%403) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %405 = "ttir.batch_norm_inference"(%398, %400, %402, %404, %76) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %406 = "ttir.add"(%396, %405) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %407 = "ttir.maximum"(%406, %4) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %408 = "ttir.permute"(%arg162) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x1024x1x1xbf16>) -> tensor<256x1024x1x1xbf16>
    %409 = "ttir.conv2d"(%407, %408) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<256x1024x1x1xbf16>) -> tensor<8x256x14x14xbf16>
    %410 = "ttir.reshape"(%arg161) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %411 = "ttir.reshape"(%410) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %412 = "ttir.reshape"(%arg160) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %413 = "ttir.reshape"(%412) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %414 = "ttir.reshape"(%arg159) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %415 = "ttir.reshape"(%414) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %416 = "ttir.batch_norm_inference"(%409, %411, %413, %415, %84) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %417 = "ttir.maximum"(%416, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %418 = "ttir.permute"(%arg157) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x256x3x3xbf16>) -> tensor<256x256x3x3xbf16>
    %419 = "ttir.conv2d"(%417, %418) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<256x256x3x3xbf16>) -> tensor<8x256x14x14xbf16>
    %420 = "ttir.reshape"(%arg156) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %421 = "ttir.reshape"(%420) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %422 = "ttir.reshape"(%arg155) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %423 = "ttir.reshape"(%422) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %424 = "ttir.reshape"(%arg154) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %425 = "ttir.reshape"(%424) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %426 = "ttir.batch_norm_inference"(%419, %421, %423, %425, %86) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %427 = "ttir.maximum"(%426, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %428 = "ttir.permute"(%arg152) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x256x1x1xbf16>) -> tensor<1024x256x1x1xbf16>
    %429 = "ttir.conv2d"(%427, %428) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<1024x256x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %430 = "ttir.reshape"(%arg151) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %431 = "ttir.reshape"(%430) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %432 = "ttir.reshape"(%arg150) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %433 = "ttir.reshape"(%432) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %434 = "ttir.reshape"(%arg149) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %435 = "ttir.reshape"(%434) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %436 = "ttir.batch_norm_inference"(%429, %431, %433, %435, %88) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %437 = "ttir.add"(%436, %407) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %438 = "ttir.maximum"(%437, %4) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %439 = "ttir.permute"(%arg177) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x1024x1x1xbf16>) -> tensor<256x1024x1x1xbf16>
    %440 = "ttir.conv2d"(%438, %439) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<256x1024x1x1xbf16>) -> tensor<8x256x14x14xbf16>
    %441 = "ttir.reshape"(%arg176) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %442 = "ttir.reshape"(%441) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %443 = "ttir.reshape"(%arg175) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %444 = "ttir.reshape"(%443) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %445 = "ttir.reshape"(%arg174) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %446 = "ttir.reshape"(%445) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %447 = "ttir.batch_norm_inference"(%440, %442, %444, %446, %90) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %448 = "ttir.maximum"(%447, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %449 = "ttir.permute"(%arg172) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x256x3x3xbf16>) -> tensor<256x256x3x3xbf16>
    %450 = "ttir.conv2d"(%448, %449) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<256x256x3x3xbf16>) -> tensor<8x256x14x14xbf16>
    %451 = "ttir.reshape"(%arg171) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %452 = "ttir.reshape"(%451) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %453 = "ttir.reshape"(%arg170) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %454 = "ttir.reshape"(%453) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %455 = "ttir.reshape"(%arg169) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %456 = "ttir.reshape"(%455) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %457 = "ttir.batch_norm_inference"(%450, %452, %454, %456, %92) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %458 = "ttir.maximum"(%457, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %459 = "ttir.permute"(%arg167) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x256x1x1xbf16>) -> tensor<1024x256x1x1xbf16>
    %460 = "ttir.conv2d"(%458, %459) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<1024x256x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %461 = "ttir.reshape"(%arg166) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %462 = "ttir.reshape"(%461) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %463 = "ttir.reshape"(%arg165) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %464 = "ttir.reshape"(%463) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %465 = "ttir.reshape"(%arg164) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %466 = "ttir.reshape"(%465) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %467 = "ttir.batch_norm_inference"(%460, %462, %464, %466, %94) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %468 = "ttir.add"(%467, %438) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %469 = "ttir.maximum"(%468, %4) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %470 = "ttir.permute"(%arg192) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x1024x1x1xbf16>) -> tensor<256x1024x1x1xbf16>
    %471 = "ttir.conv2d"(%469, %470) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<256x1024x1x1xbf16>) -> tensor<8x256x14x14xbf16>
    %472 = "ttir.reshape"(%arg191) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %473 = "ttir.reshape"(%472) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %474 = "ttir.reshape"(%arg190) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %475 = "ttir.reshape"(%474) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %476 = "ttir.reshape"(%arg189) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %477 = "ttir.reshape"(%476) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %478 = "ttir.batch_norm_inference"(%471, %473, %475, %477, %96) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %479 = "ttir.maximum"(%478, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %480 = "ttir.permute"(%arg187) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x256x3x3xbf16>) -> tensor<256x256x3x3xbf16>
    %481 = "ttir.conv2d"(%479, %480) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<256x256x3x3xbf16>) -> tensor<8x256x14x14xbf16>
    %482 = "ttir.reshape"(%arg186) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %483 = "ttir.reshape"(%482) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %484 = "ttir.reshape"(%arg185) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %485 = "ttir.reshape"(%484) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %486 = "ttir.reshape"(%arg184) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %487 = "ttir.reshape"(%486) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %488 = "ttir.batch_norm_inference"(%481, %483, %485, %487, %98) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %489 = "ttir.maximum"(%488, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %490 = "ttir.permute"(%arg182) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x256x1x1xbf16>) -> tensor<1024x256x1x1xbf16>
    %491 = "ttir.conv2d"(%489, %490) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<1024x256x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %492 = "ttir.reshape"(%arg181) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %493 = "ttir.reshape"(%492) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %494 = "ttir.reshape"(%arg180) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %495 = "ttir.reshape"(%494) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %496 = "ttir.reshape"(%arg179) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %497 = "ttir.reshape"(%496) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %498 = "ttir.batch_norm_inference"(%491, %493, %495, %497, %100) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %499 = "ttir.add"(%498, %469) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %500 = "ttir.maximum"(%499, %4) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %501 = "ttir.permute"(%arg207) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x1024x1x1xbf16>) -> tensor<256x1024x1x1xbf16>
    %502 = "ttir.conv2d"(%500, %501) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<256x1024x1x1xbf16>) -> tensor<8x256x14x14xbf16>
    %503 = "ttir.reshape"(%arg206) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %504 = "ttir.reshape"(%503) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %505 = "ttir.reshape"(%arg205) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %506 = "ttir.reshape"(%505) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %507 = "ttir.reshape"(%arg204) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %508 = "ttir.reshape"(%507) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %509 = "ttir.batch_norm_inference"(%502, %504, %506, %508, %102) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %510 = "ttir.maximum"(%509, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %511 = "ttir.permute"(%arg202) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x256x3x3xbf16>) -> tensor<256x256x3x3xbf16>
    %512 = "ttir.conv2d"(%510, %511) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<256x256x3x3xbf16>) -> tensor<8x256x14x14xbf16>
    %513 = "ttir.reshape"(%arg201) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %514 = "ttir.reshape"(%513) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %515 = "ttir.reshape"(%arg200) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %516 = "ttir.reshape"(%515) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %517 = "ttir.reshape"(%arg199) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %518 = "ttir.reshape"(%517) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %519 = "ttir.batch_norm_inference"(%512, %514, %516, %518, %104) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %520 = "ttir.maximum"(%519, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %521 = "ttir.permute"(%arg197) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x256x1x1xbf16>) -> tensor<1024x256x1x1xbf16>
    %522 = "ttir.conv2d"(%520, %521) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<1024x256x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %523 = "ttir.reshape"(%arg196) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %524 = "ttir.reshape"(%523) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %525 = "ttir.reshape"(%arg195) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %526 = "ttir.reshape"(%525) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %527 = "ttir.reshape"(%arg194) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %528 = "ttir.reshape"(%527) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %529 = "ttir.batch_norm_inference"(%522, %524, %526, %528, %106) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %530 = "ttir.add"(%529, %500) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %531 = "ttir.maximum"(%530, %4) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %532 = "ttir.permute"(%arg222) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x1024x1x1xbf16>) -> tensor<256x1024x1x1xbf16>
    %533 = "ttir.conv2d"(%531, %532) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<256x1024x1x1xbf16>) -> tensor<8x256x14x14xbf16>
    %534 = "ttir.reshape"(%arg221) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %535 = "ttir.reshape"(%534) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %536 = "ttir.reshape"(%arg220) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %537 = "ttir.reshape"(%536) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %538 = "ttir.reshape"(%arg219) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %539 = "ttir.reshape"(%538) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %540 = "ttir.batch_norm_inference"(%533, %535, %537, %539, %108) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %541 = "ttir.maximum"(%540, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %542 = "ttir.permute"(%arg217) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<256x256x3x3xbf16>) -> tensor<256x256x3x3xbf16>
    %543 = "ttir.conv2d"(%541, %542) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<256x256x3x3xbf16>) -> tensor<8x256x14x14xbf16>
    %544 = "ttir.reshape"(%arg216) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %545 = "ttir.reshape"(%544) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %546 = "ttir.reshape"(%arg215) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %547 = "ttir.reshape"(%546) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %548 = "ttir.reshape"(%arg214) <{shape = [1 : i32, 1 : i32, 256 : i32]}> : (tensor<256xbf16>) -> tensor<1x1x256xbf16>
    %549 = "ttir.reshape"(%548) <{shape = [256 : i32]}> : (tensor<1x1x256xbf16>) -> tensor<256xbf16>
    %550 = "ttir.batch_norm_inference"(%543, %545, %547, %549, %110) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x256x14x14xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<8x256x14x14xbf16>
    %551 = "ttir.maximum"(%550, %5) : (tensor<8x256x14x14xbf16>, tensor<8x256x14x14xbf16>) -> tensor<8x256x14x14xbf16>
    %552 = "ttir.permute"(%arg212) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<1024x256x1x1xbf16>) -> tensor<1024x256x1x1xbf16>
    %553 = "ttir.conv2d"(%551, %552) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x256x14x14xbf16>, tensor<1024x256x1x1xbf16>) -> tensor<8x1024x14x14xbf16>
    %554 = "ttir.reshape"(%arg211) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %555 = "ttir.reshape"(%554) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %556 = "ttir.reshape"(%arg210) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %557 = "ttir.reshape"(%556) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %558 = "ttir.reshape"(%arg209) <{shape = [1 : i32, 1 : i32, 1024 : i32]}> : (tensor<1024xbf16>) -> tensor<1x1x1024xbf16>
    %559 = "ttir.reshape"(%558) <{shape = [1024 : i32]}> : (tensor<1x1x1024xbf16>) -> tensor<1024xbf16>
    %560 = "ttir.batch_norm_inference"(%553, %555, %557, %559, %112) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x1024x14x14xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>, tensor<1024xbf16>) -> tensor<8x1024x14x14xbf16>
    %561 = "ttir.add"(%560, %531) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %562 = "ttir.maximum"(%561, %4) : (tensor<8x1024x14x14xbf16>, tensor<8x1024x14x14xbf16>) -> tensor<8x1024x14x14xbf16>
    %563 = "ttir.permute"(%arg237) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x1024x1x1xbf16>) -> tensor<512x1024x1x1xbf16>
    %564 = "ttir.conv2d"(%562, %563) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<512x1024x1x1xbf16>) -> tensor<8x512x14x14xbf16>
    %565 = "ttir.reshape"(%arg236) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %566 = "ttir.reshape"(%565) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %567 = "ttir.reshape"(%arg235) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %568 = "ttir.reshape"(%567) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %569 = "ttir.reshape"(%arg234) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %570 = "ttir.reshape"(%569) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %571 = "ttir.batch_norm_inference"(%564, %566, %568, %570, %116) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x14x14xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x14x14xbf16>
    %572 = "ttir.maximum"(%571, %3) : (tensor<8x512x14x14xbf16>, tensor<8x512x14x14xbf16>) -> tensor<8x512x14x14xbf16>
    %573 = "ttir.permute"(%arg232) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x512x3x3xbf16>) -> tensor<512x512x3x3xbf16>
    %574 = "ttir.conv2d"(%572, %573) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x512x14x14xbf16>, tensor<512x512x3x3xbf16>) -> tensor<8x512x7x7xbf16>
    %575 = "ttir.reshape"(%arg231) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %576 = "ttir.reshape"(%575) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %577 = "ttir.reshape"(%arg230) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %578 = "ttir.reshape"(%577) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %579 = "ttir.reshape"(%arg229) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %580 = "ttir.reshape"(%579) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %581 = "ttir.batch_norm_inference"(%574, %576, %578, %580, %118) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x7x7xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x7x7xbf16>
    %582 = "ttir.maximum"(%581, %2) : (tensor<8x512x7x7xbf16>, tensor<8x512x7x7xbf16>) -> tensor<8x512x7x7xbf16>
    %583 = "ttir.permute"(%arg227) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<2048x512x1x1xbf16>) -> tensor<2048x512x1x1xbf16>
    %584 = "ttir.conv2d"(%582, %583) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x7x7xbf16>, tensor<2048x512x1x1xbf16>) -> tensor<8x2048x7x7xbf16>
    %585 = "ttir.reshape"(%arg226) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %586 = "ttir.reshape"(%585) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %587 = "ttir.reshape"(%arg225) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %588 = "ttir.reshape"(%587) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %589 = "ttir.reshape"(%arg224) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %590 = "ttir.reshape"(%589) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %591 = "ttir.batch_norm_inference"(%584, %586, %588, %590, %120) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x2048x7x7xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>) -> tensor<8x2048x7x7xbf16>
    %592 = "ttir.permute"(%arg6) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<2048x1024x1x1xbf16>) -> tensor<2048x1024x1x1xbf16>
    %593 = "ttir.conv2d"(%562, %592) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 2, 2>, width_dim = 3 : i64}> : (tensor<8x1024x14x14xbf16>, tensor<2048x1024x1x1xbf16>) -> tensor<8x2048x7x7xbf16>
    %594 = "ttir.reshape"(%arg5) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %595 = "ttir.reshape"(%594) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %596 = "ttir.reshape"(%arg4) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %597 = "ttir.reshape"(%596) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %598 = "ttir.reshape"(%arg3) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %599 = "ttir.reshape"(%598) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %600 = "ttir.batch_norm_inference"(%593, %595, %597, %599, %114) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x2048x7x7xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>) -> tensor<8x2048x7x7xbf16>
    %601 = "ttir.add"(%591, %600) : (tensor<8x2048x7x7xbf16>, tensor<8x2048x7x7xbf16>) -> tensor<8x2048x7x7xbf16>
    %602 = "ttir.maximum"(%601, %1) : (tensor<8x2048x7x7xbf16>, tensor<8x2048x7x7xbf16>) -> tensor<8x2048x7x7xbf16>
    %603 = "ttir.permute"(%arg252) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x2048x1x1xbf16>) -> tensor<512x2048x1x1xbf16>
    %604 = "ttir.conv2d"(%602, %603) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x2048x7x7xbf16>, tensor<512x2048x1x1xbf16>) -> tensor<8x512x7x7xbf16>
    %605 = "ttir.reshape"(%arg251) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %606 = "ttir.reshape"(%605) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %607 = "ttir.reshape"(%arg250) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %608 = "ttir.reshape"(%607) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %609 = "ttir.reshape"(%arg249) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %610 = "ttir.reshape"(%609) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %611 = "ttir.batch_norm_inference"(%604, %606, %608, %610, %122) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x7x7xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x7x7xbf16>
    %612 = "ttir.maximum"(%611, %2) : (tensor<8x512x7x7xbf16>, tensor<8x512x7x7xbf16>) -> tensor<8x512x7x7xbf16>
    %613 = "ttir.permute"(%arg247) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x512x3x3xbf16>) -> tensor<512x512x3x3xbf16>
    %614 = "ttir.conv2d"(%612, %613) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x7x7xbf16>, tensor<512x512x3x3xbf16>) -> tensor<8x512x7x7xbf16>
    %615 = "ttir.reshape"(%arg246) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %616 = "ttir.reshape"(%615) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %617 = "ttir.reshape"(%arg245) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %618 = "ttir.reshape"(%617) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %619 = "ttir.reshape"(%arg244) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %620 = "ttir.reshape"(%619) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %621 = "ttir.batch_norm_inference"(%614, %616, %618, %620, %124) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x7x7xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x7x7xbf16>
    %622 = "ttir.maximum"(%621, %2) : (tensor<8x512x7x7xbf16>, tensor<8x512x7x7xbf16>) -> tensor<8x512x7x7xbf16>
    %623 = "ttir.permute"(%arg242) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<2048x512x1x1xbf16>) -> tensor<2048x512x1x1xbf16>
    %624 = "ttir.conv2d"(%622, %623) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x7x7xbf16>, tensor<2048x512x1x1xbf16>) -> tensor<8x2048x7x7xbf16>
    %625 = "ttir.reshape"(%arg241) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %626 = "ttir.reshape"(%625) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %627 = "ttir.reshape"(%arg240) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %628 = "ttir.reshape"(%627) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %629 = "ttir.reshape"(%arg239) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %630 = "ttir.reshape"(%629) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %631 = "ttir.batch_norm_inference"(%624, %626, %628, %630, %126) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x2048x7x7xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>) -> tensor<8x2048x7x7xbf16>
    %632 = "ttir.add"(%631, %602) : (tensor<8x2048x7x7xbf16>, tensor<8x2048x7x7xbf16>) -> tensor<8x2048x7x7xbf16>
    %633 = "ttir.maximum"(%632, %1) : (tensor<8x2048x7x7xbf16>, tensor<8x2048x7x7xbf16>) -> tensor<8x2048x7x7xbf16>
    %634 = "ttir.permute"(%arg267) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x2048x1x1xbf16>) -> tensor<512x2048x1x1xbf16>
    %635 = "ttir.conv2d"(%633, %634) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x2048x7x7xbf16>, tensor<512x2048x1x1xbf16>) -> tensor<8x512x7x7xbf16>
    %636 = "ttir.reshape"(%arg266) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %637 = "ttir.reshape"(%636) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %638 = "ttir.reshape"(%arg265) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %639 = "ttir.reshape"(%638) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %640 = "ttir.reshape"(%arg264) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %641 = "ttir.reshape"(%640) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %642 = "ttir.batch_norm_inference"(%635, %637, %639, %641, %128) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x7x7xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x7x7xbf16>
    %643 = "ttir.maximum"(%642, %2) : (tensor<8x512x7x7xbf16>, tensor<8x512x7x7xbf16>) -> tensor<8x512x7x7xbf16>
    %644 = "ttir.permute"(%arg262) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<512x512x3x3xbf16>) -> tensor<512x512x3x3xbf16>
    %645 = "ttir.conv2d"(%643, %644) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 1, 1, 1, 1>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x7x7xbf16>, tensor<512x512x3x3xbf16>) -> tensor<8x512x7x7xbf16>
    %646 = "ttir.reshape"(%arg261) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %647 = "ttir.reshape"(%646) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %648 = "ttir.reshape"(%arg260) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %649 = "ttir.reshape"(%648) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %650 = "ttir.reshape"(%arg259) <{shape = [1 : i32, 1 : i32, 512 : i32]}> : (tensor<512xbf16>) -> tensor<1x1x512xbf16>
    %651 = "ttir.reshape"(%650) <{shape = [512 : i32]}> : (tensor<1x1x512xbf16>) -> tensor<512xbf16>
    %652 = "ttir.batch_norm_inference"(%645, %647, %649, %651, %130) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x512x7x7xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>, tensor<512xbf16>) -> tensor<8x512x7x7xbf16>
    %653 = "ttir.maximum"(%652, %2) : (tensor<8x512x7x7xbf16>, tensor<8x512x7x7xbf16>) -> tensor<8x512x7x7xbf16>
    %654 = "ttir.permute"(%arg257) <{permutation = array<i64: 0, 1, 2, 3>}> : (tensor<2048x512x1x1xbf16>) -> tensor<2048x512x1x1xbf16>
    %655 = "ttir.conv2d"(%653, %654) <{batch_dim = 0 : i64, channel_dim = 1 : i64, dilation = array<i32: 1, 1>, groups = 1 : i32, height_dim = 2 : i64, padding = array<i32: 0, 0, 0, 0>, stride = array<i32: 1, 1>, width_dim = 3 : i64}> : (tensor<8x512x7x7xbf16>, tensor<2048x512x1x1xbf16>) -> tensor<8x2048x7x7xbf16>
    %656 = "ttir.reshape"(%arg256) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %657 = "ttir.reshape"(%656) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %658 = "ttir.reshape"(%arg255) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %659 = "ttir.reshape"(%658) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %660 = "ttir.reshape"(%arg254) <{shape = [1 : i32, 1 : i32, 2048 : i32]}> : (tensor<2048xbf16>) -> tensor<1x1x2048xbf16>
    %661 = "ttir.reshape"(%660) <{shape = [2048 : i32]}> : (tensor<1x1x2048xbf16>) -> tensor<2048xbf16>
    %662 = "ttir.batch_norm_inference"(%655, %657, %659, %661, %132) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<8x2048x7x7xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>, tensor<2048xbf16>) -> tensor<8x2048x7x7xbf16>
    %663 = "ttir.add"(%662, %633) : (tensor<8x2048x7x7xbf16>, tensor<8x2048x7x7xbf16>) -> tensor<8x2048x7x7xbf16>
    %664 = "ttir.maximum"(%663, %1) : (tensor<8x2048x7x7xbf16>, tensor<8x2048x7x7xbf16>) -> tensor<8x2048x7x7xbf16>
    %665 = "ttir.sum"(%664) <{dim_arg = [2 : i32, 3 : i32], keep_dim = false}> : (tensor<8x2048x7x7xbf16>) -> tensor<8x2048xbf16>
    %666 = "ttir.multiply"(%665, %0) : (tensor<8x2048xbf16>, tensor<8x2048xbf16>) -> tensor<8x2048xbf16>
    %667 = "ttir.reshape"(%arg1) <{shape = [1 : i32, 1000 : i32, 2048 : i32]}> : (tensor<1000x2048xbf16>) -> tensor<1x1000x2048xbf16>
    %668 = "ttir.reshape"(%667) <{shape = [1000 : i32, 2048 : i32]}> : (tensor<1x1000x2048xbf16>) -> tensor<1000x2048xbf16>
    %669 = "ttir.permute"(%668) <{permutation = array<i64: 1, 0>}> : (tensor<1000x2048xbf16>) -> tensor<2048x1000xbf16>
    %670 = "ttir.dot_general"(%666, %669) <{batch_dims_lhs = array<i64>, batch_dims_rhs = array<i64>, contract_dims_lhs = array<i64: 1>, contract_dims_rhs = array<i64: 0>}> : (tensor<8x2048xbf16>, tensor<2048x1000xbf16>) -> tensor<8x1000xbf16>
    %671 = "ttir.reshape"(%arg0) <{shape = [1 : i32, 1 : i32, 1000 : i32]}> : (tensor<1000xbf16>) -> tensor<1x1x1000xbf16>
    %672 = "ttir.reshape"(%671) <{shape = [1000 : i32]}> : (tensor<1x1x1000xbf16>) -> tensor<1000xbf16>
    %673 = "ttir.reshape"(%672) <{shape = [1 : i32, 1000 : i32]}> : (tensor<1000xbf16>) -> tensor<1x1000xbf16>
    %674 = "ttir.broadcast"(%673) <{broadcast_dimensions = array<i64: 8, 1>}> : (tensor<1x1000xbf16>) -> tensor<8x1000xbf16>
    %675 = "ttir.add"(%670, %674) : (tensor<8x1000xbf16>, tensor<8x1000xbf16>) -> tensor<8x1000xbf16>
    return %675 : tensor<8x1000xbf16>
  }
}
