// REQUIRES: opmodel
// RUN: ttmlir-opt --ttir-to-ttnn-backend-pipeline="system-desc-path=%system_desc_path% enable-optimizer=true memory-layout-analysis-enabled=true enable-fusing-conv2d-with-multiply-pattern=true" -o %t %s --mlir-print-debuginfo
// RUN: FileCheck %s --input-file=%t
// RUN: ttmlir-translate --ttnn-to-flatbuffer -o %t.ttnn %t

module {
func.func @resnet50_first_module(%arg17: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg18: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg19: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg20: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg21: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg22: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg23: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg24: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg25: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg26: tensor<64x3x7x7xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg27: tensor<1x3x224x224xbf16> {ttcore.argument_type = #ttcore.argument_type<input>}, %arg28: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg29: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg30: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg31: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg32: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg33: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg34: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg35: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg36: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg37: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg38: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg39: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg40: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg41: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg42: tensor<64x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg43: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg44: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg45: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg46: tensor<256xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg47: tensor<256x64x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg48: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg49: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg50: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg51: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg52: tensor<64x64x3x3xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg53: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg54: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<constant>}, %arg55: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg56: tensor<64xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}, %arg57: tensor<64x256x1x1xbf16> {ttcore.argument_type = #ttcore.argument_type<parameter>}) -> tensor<1x256x56x56xbf16> {
    %0 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<1x256x56x56xbf16>}> : () -> tensor<1x256x56x56xbf16>
    %1 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<1x64x56x56xbf16>}> : () -> tensor<1x64x56x56xbf16>
    %2 = "ttir.constant"() <{value = dense<0.000000e+00> : tensor<1x64x112x112xbf16>}> : () -> tensor<1x64x112x112xbf16>
    // CHECK: "ttnn.conv2d"
    %3 = "ttir.conv2d"(%arg27, %arg26) <{stride = array<i32: 2, 2>, padding = array<i32: 3, 3, 3, 3>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x3x224x224xbf16>, tensor<64x3x7x7xbf16>) -> tensor<1x64x112x112xbf16>
    // CHECK-NOT: "ttnn.batch_norm_inference"
    // CHECK-NOT: "ttnn.multiply"
    // CHECK-NOT: "ttnn.add"
    %4 = "ttir.batch_norm_inference"(%3, %arg25, %arg24, %arg23, %arg22) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x64x112x112xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<1x64x112x112xbf16>
    %5 = "ttir.maximum"(%4, %2) : (tensor<1x64x112x112xbf16>, tensor<1x64x112x112xbf16>) -> tensor<1x64x112x112xbf16>
    %6 = "ttir.pad"(%5) <{padding = array<i32: 0, 0, 0, 0, 1, 1, 1, 1>, value = 0xFF800000 : f32}> : (tensor<1x64x112x112xbf16>) -> tensor<1x64x114x114xbf16>
    %7 = "ttir.pooling"(%6) <{base_dilations = array<i64: 1, 1, 1, 1>, operandSegmentSizes = array<i32: 1, 1>, padding = array<i64: 0, 0, 0, 0, 0, 0, 0, 0>, pooling_method = #ttir<pooling_method Max>, window_dilations = array<i64: 1, 1, 1, 1>, window_dimensions = array<i64: 1, 1, 3, 3>, window_strides = array<i64: 1, 1, 2, 2>}> : (tensor<1x64x114x114xbf16>) -> tensor<1x64x56x56xbf16>
    // CHECK: "ttnn.conv2d"
    %8 = "ttir.conv2d"(%7, %arg42) <{stride = array<i32: 1, 1>, padding = array<i32: 0, 0, 0, 0>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x64x56x56xbf16>, tensor<64x64x1x1xbf16>) -> tensor<1x64x56x56xbf16>
    %9 = "ttir.batch_norm_inference"(%8, %arg41, %arg40, %arg39, %arg38) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<1x64x56x56xbf16>
    %10 = "ttir.maximum"(%9, %1) : (tensor<1x64x56x56xbf16>, tensor<1x64x56x56xbf16>) -> tensor<1x64x56x56xbf16>
    %11 = "ttir.conv2d"(%10, %arg37) <{stride = array<i32: 1, 1>, padding = array<i32: 1, 1, 1, 1>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x64x56x56xbf16>, tensor<64x64x3x3xbf16>) -> tensor<1x64x56x56xbf16>
    %12 = "ttir.batch_norm_inference"(%11, %arg36, %arg35, %arg34, %arg33) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<1x64x56x56xbf16>
    %13 = "ttir.maximum"(%12, %1) : (tensor<1x64x56x56xbf16>, tensor<1x64x56x56xbf16>) -> tensor<1x64x56x56xbf16>
    %14 = "ttir.conv2d"(%13, %arg32) <{stride = array<i32: 1, 1>, padding = array<i32: 0, 0, 0, 0>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<1x256x56x56xbf16>
    %15 = "ttir.batch_norm_inference"(%14, %arg31, %arg30, %arg29, %arg28) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<1x256x56x56xbf16>
    %16 = "ttir.conv2d"(%7, %arg21) <{stride = array<i32: 1, 1>, padding = array<i32: 0, 0, 0, 0>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<1x256x56x56xbf16>
    %17 = "ttir.batch_norm_inference"(%16, %arg20, %arg19, %arg18, %arg17) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<1x256x56x56xbf16>
    %18 = "ttir.add"(%15, %17) : (tensor<1x256x56x56xbf16>, tensor<1x256x56x56xbf16>) -> tensor<1x256x56x56xbf16>
    %19 = "ttir.maximum"(%18, %0) : (tensor<1x256x56x56xbf16>, tensor<1x256x56x56xbf16>) -> tensor<1x256x56x56xbf16>
    %20 = "ttir.conv2d"(%19, %arg57) <{stride = array<i32: 1, 1>, padding = array<i32: 0, 0, 0, 0>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x256x56x56xbf16>, tensor<64x256x1x1xbf16>) -> tensor<1x64x56x56xbf16>
    %21 = "ttir.batch_norm_inference"(%20, %arg56, %arg55, %arg54, %arg53) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<1x64x56x56xbf16>
    %22 = "ttir.maximum"(%21, %1) : (tensor<1x64x56x56xbf16>, tensor<1x64x56x56xbf16>) -> tensor<1x64x56x56xbf16>
    %23 = "ttir.conv2d"(%22, %arg52) <{stride = array<i32: 1, 1>, padding = array<i32: 1, 1, 1, 1>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x64x56x56xbf16>, tensor<64x64x3x3xbf16>) -> tensor<1x64x56x56xbf16>
    %24 = "ttir.batch_norm_inference"(%23, %arg51, %arg50, %arg49, %arg48) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x64x56x56xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>, tensor<64xbf16>) -> tensor<1x64x56x56xbf16>
    %25 = "ttir.maximum"(%24, %1) : (tensor<1x64x56x56xbf16>, tensor<1x64x56x56xbf16>) -> tensor<1x64x56x56xbf16>
    %26 = "ttir.conv2d"(%25, %arg47) <{stride = array<i32: 1, 1>, padding = array<i32: 0, 0, 0, 0>, dilation = array<i32: 1, 1>, groups = 1 : i32, batch_dim = 0 : i64, height_dim = 2 : i64, width_dim = 3 : i64, channel_dim = 1 : i64}> : (tensor<1x64x56x56xbf16>, tensor<256x64x1x1xbf16>) -> tensor<1x256x56x56xbf16>
    %27 = "ttir.batch_norm_inference"(%26, %arg46, %arg45, %arg44, %arg43) <{dimension = 1 : i32, epsilon = 9.99999974E-6 : f32}> : (tensor<1x256x56x56xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>, tensor<256xbf16>) -> tensor<1x256x56x56xbf16>
    %28 = "ttir.add"(%27, %19) : (tensor<1x256x56x56xbf16>, tensor<1x256x56x56xbf16>) -> tensor<1x256x56x56xbf16>
    return %28 : tensor<1x256x56x56xbf16>
  }
}
