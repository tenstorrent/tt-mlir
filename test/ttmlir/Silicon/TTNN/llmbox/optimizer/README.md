# LLMBox Optimizer Tests

The goal of these tests is to replicate e2e model testing in tt-mlir. They are single layer versions of large models and should be used for development and verification for most perf related features.

## Requirements

- An **llmbox** (or quietbox) machine with 8 Wormhole chips configured as a 2x4 mesh.
- The project must be built with runtime and opmodel enabled:
  ```bash
  cmake -G Ninja -B build -DCMAKE_BUILD_TYPE=Release \
    -DTTMLIR_ENABLE_RUNTIME=ON -DTTMLIR_ENABLE_OPMODEL=ON

  cmake --build build

  cmake --build build -- ttrt
  ```
- An up-to-date system descriptor matching the current machine. Generate it with:
  ```bash
  ttrt query --save-artifacts
  ```
- The `SYSTEM_DESC_PATH` environment variable must point to the descriptor:
  ```bash
  export SYSTEM_DESC_PATH=$(pwd)/ttrt-artifacts/system_desc.ttsys
  ```

## Running

```bash
source env/activate
llvm-lit -a test/ttmlir/Silicon/TTNN/llmbox/optimizer/
```

To run a single test:

```bash
llvm-lit -a test/ttmlir/Silicon/TTNN/llmbox/optimizer/llama_3_1_70b_1layer_2x4mesh.mlir
```

## Tests

### llama_3_1_70b_1layer_2x4mesh.mlir

Single decoder layer extracted from the Llama 3.1 70B model. The TTIR input was generated by running the e2e test with `--num-layers 1`:

```bash
pytest -svv ../tt-forge/benchmark/tt-xla/test_llms.py::test_llama_3_1_70b_tp --num-layers 1
```

The pipeline options match the tt-xla compilation path:
- `mesh-shape=2,4`
- `optimization-level=1`
- `experimental-bfp8-weights=true`
- `enable-permute-matmul-fusion=false`
- `enable-cpu-hoisted-const-eval=false`
