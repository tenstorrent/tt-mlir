include "ttmlir/Target/Common/types.fbs";
include "ttmlir/Target/TTNN/types.fbs";
include "ttmlir/Target/TTNN/operations/configs.fbs";

namespace tt.target.ttnn;

table SoftmaxOp {
  in: tt.target.ttnn.TensorRef;
  out: tt.target.ttnn.TensorRef;
  dimension: int32;
  numeric_stable: bool = false;
  compute_config: tt.target.ttnn.DeviceComputeKernelConfig;
}

table BatchNormInferenceOp {
  input: tt.target.ttnn.TensorRef;
  running_mean: tt.target.ttnn.TensorRef;
  running_var: tt.target.ttnn.TensorRef;
  epsilon: float;
  weight: tt.target.ttnn.TensorRef;
  bias: tt.target.ttnn.TensorRef;
  memory_config: tt.target.ttnn.MemoryConfig;
  out: tt.target.ttnn.TensorRef;
  compute_config: tt.target.ttnn.DeviceComputeKernelConfig;
}

table BatchNormTrainingOp {
  input: tt.target.ttnn.TensorRef;
  running_mean: tt.target.ttnn.TensorRef;
  running_var: tt.target.ttnn.TensorRef;
  epsilon: float;
  momentum: float;
  weight: tt.target.ttnn.TensorRef;
  bias: tt.target.ttnn.TensorRef;
  memory_config: tt.target.ttnn.MemoryConfig;
  out: tt.target.ttnn.TensorRef;
  compute_config: tt.target.ttnn.DeviceComputeKernelConfig;
}

table RMSNormOp {
  input: tt.target.ttnn.TensorRef;
  weight: tt.target.ttnn.TensorRef;
  bias: tt.target.ttnn.TensorRef;
  epsilon: float;
  memory_config: tt.target.ttnn.MemoryConfig;
  out: tt.target.ttnn.TensorRef;
  compute_config: tt.target.ttnn.DeviceComputeKernelConfig;
}

table LayerNormOp {
  input: tt.target.ttnn.TensorRef;
  weight: tt.target.ttnn.TensorRef;
  bias: tt.target.ttnn.TensorRef;
  epsilon: float;
  memory_config: tt.target.ttnn.MemoryConfig;
  out: tt.target.ttnn.TensorRef;
}

table GroupNormOp {
  input: tt.target.ttnn.TensorRef;
  input_mask: tt.target.ttnn.TensorRef;
  weight: tt.target.ttnn.TensorRef;
  bias: tt.target.ttnn.TensorRef;
  num_groups: int64;
  epsilon: float;
  memory_config: tt.target.ttnn.MemoryConfig;
  out: tt.target.ttnn.TensorRef;
}
