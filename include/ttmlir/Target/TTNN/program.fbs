include "Common/types.fbs";
include "Common/debug_info.fbs";

namespace tt.target.ttnn;

table GetDeviceOp {
  mesh: Dim2d;
  chip_ids: [uint32];
  out: tt.target.DeviceRef;
}

table ToMemoryConfigOp {
  in0: tt.target.TensorRef;
  memcfg: MemoryConfigDesc;
  out: tt.target.TensorRef;
}

table ToLayoutOp {
  in: tt.target.TensorRef;
  layout: tt.target.TensorLayout;
  dtype: tt.target.DataType = null;
  memcfg: tt.target.MemoryConfigDesc;
  device: tt.target.DeviceRef;
  out: tt.target.TensorRef;
}

table TypecastOp {
  in: tt.target.TensorRef;
  dtype: tt.target.DataType;
  out: tt.target.TensorRef;
}

table ToDeviceOp {
  in: tt.target.TensorRef;
  device: tt.target.DeviceRef;
  memcfg: tt.target.MemoryConfigDesc;
  out: tt.target.TensorRef;
}

table UpdateCacheOp {
  cache: tt.target.TensorRef;
  input: tt.target.TensorRef;
  update_index: tt.target.TensorRef;
  batch_offset: uint32;
}

table FillCacheOp {
  cache: tt.target.TensorRef;
  input: tt.target.TensorRef;
  batch_offset: uint32;
}

table FromDeviceOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
}

table EmptyOp {
  shape: [int64];
  dtype: DataType;
  layout: TensorLayout;
  num_shards: uint32;
  device: tt.target.DeviceRef;         // optional
  memcfg: tt.target.MemoryConfigDesc;  // optional
  strategy: tt.target.DistributionStrategy;
  out: tt.target.TensorRef;
}

table FullOp {
  device: tt.target.DeviceRef;
  fill_value: float;
  num_shards: uint32;
  strategy: tt.target.DistributionStrategy;
  out: tt.target.TensorRef;
}

table ArangeOp {
  start: float;
  end: float;
  step: float;
  dtype: tt.target.DataType = null; // optional
  device: tt.target.DeviceRef; // optional
  memcfg: tt.target.MemoryConfigDesc;  // optional
  out: tt.target.TensorRef;
}

enum EltwiseOpType: uint32 {
  Add,
  Multiply,
  Subtract,
  Relu,
  GreaterEqual,
  Sqrt,
  Div,
  Sigmoid,
  Reciprocal,
  Exp,
  Maximum,
  Abs,
  Neg,
  Rsqrt,
  Typecast,
  Equal,
  NotEqual,
  LessEqual,
  LessThan,
  GreaterThan,
  LogicalAnd,
  LogicalOr,
  LogicalNot,
  Cbrt,
  Minimum,
  Ceil,
  Sin,
  Cos,
  Log,
  Log1p,
  Expm1,
  Sign,
  Remainder,
  IsFinite,
  Floor,
  Where,
  Gelu,
  LogicalXor,
  Clamp,
  LeakyRelu,
  Scatter,
  Tan,
  Tanh
}

table ClampOpParams {
  min: float;
  max: float;
}

table EltwiseOpWithFloatParams {
  parameter: float;
}

union EltwiseOpParams {
  ClampOpParams,
  EltwiseOpWithFloatParams,
}

table EltwiseOp {
  type: EltwiseOpType;
  ins: [tt.target.TensorRef];
  out: tt.target.TensorRef;
  params: EltwiseOpParams;
}

enum ReductionOpType: uint32 {
  Sum,
  Mean,
  Max,
}

table ReductionOp {
  type: ReductionOpType;
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  dim_arg: [int32];
  keep_dim: bool;
}

table EmbeddingOp {
  input: tt.target.TensorRef;
  weight: tt.target.TensorRef;
  out: tt.target.TensorRef;
}

table SoftmaxOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  dimension: int32;
}

table TransposeOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  dim0: int32;
  dim1: int32;
}

table ConcatOp {
 inputs: [tt.target.TensorRef];
 out: tt.target.TensorRef;
 dim: int32;
}

table ReshapeOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  shape: [int32];
}

table SliceOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  begins: [int64];
  ends: [int64];
  step: [int64];
}

table LinearOp {
  in0: tt.target.TensorRef;
  in1: tt.target.TensorRef;
  bias: tt.target.TensorRef;
  out: tt.target.TensorRef;
}

// ANCHOR: adding_an_op_matmul_fbs
table MatmulOp {
  in0: tt.target.TensorRef;
  in1: tt.target.TensorRef;
  out: tt.target.TensorRef;
}
// ANCHOR_END: adding_an_op_matmul_fbs

table Conv2dOp {
  input: tt.target.TensorRef;
  weight: tt.target.TensorRef;
  bias: tt.target.TensorRef;
  out: tt.target.TensorRef;
  device: tt.target.DeviceRef;
  in_channels: uint32;
  out_channels: uint32;
  batch_size: uint32;
  input_height: uint32;
  input_width: uint32;
  kernel_height: uint32;
  kernel_width: uint32;
  stride_height: uint32;
  stride_width: uint32;
  padding_height: uint32;
  padding_width: uint32;
  dilation_height: uint32;
  dilation_width: uint32;
  groups: uint32;
}

table MaxPool2dOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  device: tt.target.DeviceRef;
  batch_size: uint32;
  input_height: uint32;
  input_width: uint32;
  channels: uint32;
  kernel_height: uint32;
  kernel_width: uint32;
  stride_height: uint32;
  stride_width: uint32;
  dilation_height: uint32;
  dilation_width: uint32;
  ceil_mode: bool;
  padding_height: uint32;
  padding_width: uint32;
}

table DeallocateOp {
  in: tt.target.TensorRef;
  force: bool;
}

table AllGatherOp {
  in: tt.target.TensorRef;
  out: tt.target.TensorRef;
  dim: uint32;
  num_links: uint32;
}

union OpType {
  GetDeviceOp,
  ToMemoryConfigOp,
  ToLayoutOp,
  TypecastOp,
  ToDeviceOp,
  FromDeviceOp,
  EmptyOp,
  FullOp,
  EltwiseOp,
  LinearOp,
  MatmulOp,
  ReductionOp,
  EmbeddingOp,
  SoftmaxOp,
  TransposeOp,
  Conv2dOp,
  ConcatOp,
  ReshapeOp,
  SliceOp,
  MaxPool2dOp,
  DeallocateOp,
  AllGatherOp,
  ArangeOp,
  UpdateCacheOp,
  FillCacheOp,
}

table Operation {
  type: OpType;
  debug_info: string;
  loc_info: string;
}

table Program {
  name: string;
  inputs: [TensorRef];
  outputs: [TensorRef];
  operations: [Operation];
  debug_info: DebugInfo;
}
