include "Common/types.fbs";

namespace tt.target.ttnn;

enum TensorMemoryLayout: ushort {
  Interleaved,
  SingleBank,
  HeightSharded,
  WidthSharded,
  BlockSharded,
}

enum StorageType: ushort {
    Owned,
    Device,
    Borrowed,
    MultiDevice,
    MultiDeviceHost,
}

enum MeshShardDirection: uint32 {
  FullToShardShape,
  ShardToFullShape,
}

enum MeshShardType: uint32 {
  Manual,
  Replicate,
  Maximal,
  Devices,
}

table ReplicateTensor {
  replication_factor: uint32;
}

table ShardTensor {
  shard_dim: uint32;
}

table ShardTensor2D {
  shard_mesh: Dim2d;
}

table AllGatherTensor {

}

union DistributedTensorConfig {
  ReplicateTensor,
  ShardTensor,
  ShardTensor2D,
  AllGatherTensor
}

table DistributionStrategy {
  strategy: DistributedTensorConfig;
}

table ShardSpec {
  grid: [Dim2dRange];
  shard_shape: [int32];
}

table MemoryConfig {
  tensor_memory_layout: TensorMemoryLayout;
  buffer_type: BufferType;
  shard_spec: ShardSpec;
}

table Conv2dConfig {
  dtype: DataType;
  weights_dtype: DataType;
  activation: string;
  input_channels_alignment: uint32;
  deallocate_activation: bool;
  reallocate_halo_output: bool;
  act_block_h_override: uint32;
  act_block_w_div: uint32;
  reshard_if_not_optimal: bool;
  override_sharding_config: bool;
  shard_layout: TensorMemoryLayout = null;
  core_grid: bool = null;
  transpose_shards: bool;
  output_layout: TensorLayout;
  enable_act_double_buffer: bool;
  enable_weights_double_buffer: bool;
  enable_split_reader: bool;
  enable_subblock_padding: bool;
}

table MemoryDesc {
  storage_type: StorageType;
  tile_shape: Dim2d;
  data_type: DataType;
  memory_config: MemoryConfig;
  size: uint64;
}

table LayoutDesc {
  oob_val: OOBVal;
  memory_desc: MemoryDesc;
  strategy: DistributionStrategy;
}

table TensorDesc {
  shape: [int];
  layout: LayoutDesc;
}

table TensorRef {
  global_id: uint32;
  size: uint64;
  desc: TensorDesc;
}
