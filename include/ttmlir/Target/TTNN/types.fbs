include "ttmlir/Target/Common/types.fbs";

namespace tt.target.ttnn;

enum TensorMemoryLayout: ushort {
  Interleaved,
  SingleBank,
  HeightSharded,
  WidthSharded,
  BlockSharded,
}

enum StorageType: ushort {
    Owned,
    Device,
    Borrowed,
    MultiDevice,
    MultiDeviceHost,
}

enum MeshShardDirection: uint32 {
  FullToShardShape,
  ShardToFullShape,
}

enum MeshShardType: uint32 {
  Identity,
  Replicate,
  Maximal,
  Devices,
}

struct CoreCoord {
  x: uint64;
  y: uint64;
}

struct CoreRange {
  start_coord: CoreCoord;
  end_coord: CoreCoord;
}

table CoreRangeSet {
  core_ranges: [CoreRange];
}

table ReplicateTensor {
  replication_factor: uint32;
}

table ShardTensor {
  shard_dim: uint32;
}

table ShardTensor2D {
  shard_mesh: Dim2d;
}

table AllGatherTensor {

}

union DistributedTensorConfig {
  ReplicateTensor,
  ShardTensor,
  ShardTensor2D,
  AllGatherTensor
}

table DistributionStrategy {
  strategy: DistributedTensorConfig;
}

table ShardSpec {
  grid: [Dim2dRange];
  shard_shape: [int32];
}

table MemoryConfig {
  tensor_memory_layout: TensorMemoryLayout;
  buffer_type: BufferType;
  shard_spec: ShardSpec;
}

table Conv2dConfig {
  dtype: DataType;
  weights_dtype: DataType;
  activation: string;
  input_channels_alignment: uint32;
  deallocate_activation: bool;
  reallocate_halo_output: bool;
  act_block_h_override: uint32;
  act_block_w_div: uint32;
  reshard_if_not_optimal: bool;
  override_sharding_config: bool;
  shard_layout: TensorMemoryLayout = null;
  core_grid: CoreRangeSet;
  transpose_shards: bool;
  output_layout: TensorLayout;
  preprocess_weights_on_device: bool;
  always_preprocess_weights: bool;
  enable_act_double_buffer: bool;
  enable_weights_double_buffer: bool;
  enable_split_reader: bool;
  enable_subblock_padding: bool;
}

enum UnaryOpType: uint32 {
  Exp,
  Recip,
  Gelu,
  Relu,
  Sqrt,
  Sigmoid,
  Log,
  Tanh,
  Log2,
  Log10,
  Sin,
  Cos,
  Abs,
  AbsInt32,
  Sign,
  Square,
  Eqz,
  Nez,
  Gtz,
  Ltz,
  Gez,
  Lez,
  ReluMax,
  ReluMin,
  Power,
  LeakyRelu,
  Elu,
  Exp2,
  Heaviside,
  Expm1,
  Signbit,
  Asin,
  Acos,
  Rsqrt,
  Relu6,
  Atan,
  Erf,
  Erfc,
  Isinf,
  Isposinf,
  Isneginf,
  Isnan,
  LogicalNotUnary,
  Isfinite,
  Erfinv,
  I0,
  I1,
  Tan,
  Rsub,
  Rdiv,
  Silu,
  Softplus,
  Identity,
  Neg,
  AddUnarySfpu,
  SubUnarySfpu,
  MulUnarySfpu,
  DivUnarySfpu,
  IdentityUint32,
  UnaryNe,
  UnaryGt,
  UnaryLt,
  TiledProd,
  Typecast,
  BitwiseXor,
  BitwiseNot,
  BitwiseAnd,
  BitwiseOr,
  RightShift,
  Floor,
  FloorFloat32,
  Ceil,
  CeilFloat32,
  LeftShift,
  Remainder,
  Fmod,
  Dropout,
  Fill,
  PreluSfpu,
  ZeroPoint
}

table UnaryWithParam {
  op_type: UnaryOpType;
  params: [double];
}

table MatmulMultiCoreReuseProgramConfig {
  compute_with_storage_grid_size: CoreCoord;
  in0_block_w: uint64;
  out_subblock_h: uint64;
  out_subblock_w: uint64;
  per_core_m: uint64;
  per_core_n: uint64;
}

table MatmulMultiCoreReuseMultiCastProgramConfig {
  compute_with_storage_grid_size: CoreCoord;
  in0_block_w: uint64;
  out_subblock_h: uint64;
  out_subblock_w: uint64;
  out_block_h: uint64;
  out_block_w: uint64;
  per_core_m: uint64;
  per_core_n: uint64;
  transpose_mcast: bool;
  fused_activation: UnaryWithParam;
  fuse_batch: bool;
}

table MatmulMultiCoreReuseMultiCast1DProgramConfig {
  compute_with_storage_grid_size: CoreCoord;
  in0_block_w: uint64;
  out_subblock_h: uint64;
  out_subblock_w: uint64;
  out_block_h: uint64;
  out_block_w: uint64;
  per_core_m: uint64;
  per_core_n: uint64;
  fuse_batch: bool;
  fused_activation: UnaryWithParam;
  mcast_in0: bool;
  gather_in0: bool;
  hop_cores: CoreRangeSet;
  num_global_cb_receivers: uint64;
}

table MatmulMultiCoreReuseMultiCastDRAMShardedProgramConfig {
  in0_block_w: uint64;
  per_core_m: uint64;
  per_core_n: uint64;
  fused_activation: UnaryWithParam;
}

union MatmulProgramConfig {
  MatmulMultiCoreReuseProgramConfig,
  MatmulMultiCoreReuseMultiCastProgramConfig,
  MatmulMultiCoreReuseMultiCast1DProgramConfig,
  MatmulMultiCoreReuseMultiCastDRAMShardedProgramConfig
}

table MemoryDesc {
  storage_type: StorageType;
  tile_shape: Dim2d;
  data_type: DataType;
  memory_config: MemoryConfig;
  size: uint64;
}

table LayoutDesc {
  oob_val: OOBVal;
  memory_desc: MemoryDesc;
  strategy: DistributionStrategy;
}

table TensorDesc {
  shape: [int];
  mesh_shape: [int32];
  layout: LayoutDesc;
}

table TensorRef {
  global_id: uint32;
  size: uint64;
  desc: TensorDesc;
}
