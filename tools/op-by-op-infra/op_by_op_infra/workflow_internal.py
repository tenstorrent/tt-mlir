# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

import os
from typing import List, Optional

from tqdm import tqdm
from ttmlir.ir import Module

from .execution_result import convert_to_pydantic_model
from .mlir_module_executor import ExecutionResult, MLIRModuleExecutor
from .mlir_module_splitter import MLIRModuleSplitter
from .pydantic_models import OpTest

# ---------- Utils ----------


def show_workflow_progress() -> bool:
    return os.environ.get("SHOW_WORKFLOW_PROGRESS", "false").lower() in [
        1,
        "1",
        "true",
        "on",
    ]


def progress_bar(*args, **kwargs) -> tqdm:
    """
    Wrapper around `tqdm` that takes an iterable and displays progress bar in console
    showing how iterations of that iterable are progressing.

    Disabled by default. To enable set env var `SHOW_WORKFLOW_PROGRESS=ON`.
    """
    kwargs["disable"] = show_workflow_progress() == False
    return tqdm(*args, **kwargs)


def progress_msg(*args, **kwargs) -> None:
    """
    Wrapper around `tqdm.write` that displays a message in console.

    Disabled by default. To enable set env var `SHOW_WORKFLOW_PROGRESS=ON`.
    """
    if show_workflow_progress():
        tqdm.write(*args, **kwargs)


def convert_results_to_pydantic_models(
    results: List[ExecutionResult],
    *,
    frontend: Optional[str] = None,
    model_name: Optional[str] = None,
) -> List[OpTest]:
    """
    Converts `ExecutionResult`s to `OpTest` pydantic models.

    If any additional key-worded param (carrying attribute of the pydantic model that
    couldn't be filled in infra but has to come from frontend) is provided, it will be
    added to the models.
    """
    models = [convert_to_pydantic_model(result) for result in results]

    # Check if any of the missing attributes were passed to the function and add them
    # to the model if they were.
    missing_attributes_provided = any(
        param is not None for param in [frontend, model_name]
    )
    if missing_attributes_provided:
        for pydantic_model in models:
            add_missing_attributes(
                pydantic_model,
                frontend=frontend,
                model_name=model_name,
            )

    return models


def add_missing_attributes(
    pydantic_model: OpTest,
    *,
    frontend: Optional[str] = None,
    model_name: Optional[str] = None,
) -> None:
    """
    Sets additional attributes of `pydantic_model` in-place.

    Parameters
    ----------
    pydantic_model: OpTest
        Model instance who's attributes we change.

    frontend: Optional[str]
        Name of the frontend using op by op infra.

    model_name: Optional[str]
        Name of the ML model which was passed as original MLIR module to the op by op
        infra. I.e model in which operation `pydantic_model.op_name` is used.
    """
    pydantic_model.frontend = frontend
    pydantic_model.model_name = model_name


# ---------- Workflows ----------


def split_and_execute(
    module: Module | str, compile_only: bool = False
) -> List[ExecutionResult]:
    """
    Splits the original `module` (SHLO/TTIR/TTNN) into constituent operations, compiles
    each of them down to TTNN graph, creates flatbuffer from it and runs it on device.

    This workflow is meant to track execution progress of individual ops from original
    module.

    Returns list of `ExecutionResult`s, each holding info for one particular
    constituent op about how far down the execution pipeline it managed to get.
    """
    progress_msg("\nChosen workflow:")
    progress_msg(split_and_execute.__doc__)

    splitter = MLIRModuleSplitter()
    executor = MLIRModuleExecutor(compile_only)

    results = []

    progress_msg("Splitting module...")
    sub_modules = splitter.split(module)

    for sub_module in progress_bar(sub_modules, desc="Executing submodules..."):
        execution_result = executor.execute(sub_module)
        results.append(execution_result)

    return results


def compile_split_and_execute(module: Module | str) -> List[ExecutionResult]:
    """
    Compiles the original `module` (SHLO/TTIR/TTNN) down to TTNN graph, splits it into
    constituent operations, creates flatbuffer for each of them and runs it on device.

    This workflow is meant to track execution progress of individual ops from TTNN graph
    generated by compiling original module.

    Returns list of `OpTest`s, each holding info for one particular
    constituent op about how far down the execution pipeline it managed to get.
    """
    progress_msg("\nChosen workflow:")
    progress_msg(compile_split_and_execute.__doc__)

    splitter = MLIRModuleSplitter()
    executor = MLIRModuleExecutor()

    results = []

    progress_msg("Compiling module...")
    ttnn_module = executor.compile(module)
    progress_msg("Splitting module...")
    sub_modules = splitter.split(ttnn_module)

    for sub_module in progress_bar(sub_modules, desc="Executing submodules..."):
        execution_result = executor.execute(sub_module)
        results.append(execution_result)

    return results


def split_compile_split_and_execute(module: Module | str) -> List[ExecutionResult]:
    """
    Splits the original `module` (SHLO/TTIR/TTNN) into constituent operations, compiles
    each of them down to TTNN graph, splits it into constituent TTNN operations, creates
    flatbuffer for each of them and runs it on device.

    This workflow is meant to track execution progress of individual ops from TTNN graph
    generated by compiling individual ops from original module.

    Returns list of `ExecutionResult`s, each holding info for one particular
    constituent TTNN op about how far down the execution pipeline it managed to get.
    """
    progress_msg("\nChosen workflow:")
    progress_msg(split_and_execute.__doc__)

    splitter = MLIRModuleSplitter()
    executor = MLIRModuleExecutor()

    results = []

    progress_msg("Splitting module...")
    sub_modules = splitter.split(module)

    for sub_module in progress_bar(
        sub_modules, desc="Compiling, splitting and executing submodules..."
    ):
        progress_msg("Compiling submodule...")
        ttnn_module = executor.compile(sub_module)
        progress_msg("Splitting submodule...")
        ttnn_sub_modules = splitter.split(ttnn_module)

        for ttnn_sub_module in progress_bar(
            ttnn_sub_modules, desc="Executing submodules...", leave=False
        ):
            execution_result = executor.execute(ttnn_sub_module)
            results.append(execution_result)

    return results
