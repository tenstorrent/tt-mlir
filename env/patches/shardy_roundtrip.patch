From 82b34c15f0f6b05e31dc350a1d303dcf5727df49 Mon Sep 17 00:00:00 2001
From: Tapasvi Patel <tpatel@tenstorrent.com>
Date: Wed, 13 Aug 2025 20:12:45 +0000
Subject: [PATCH] Revert "#sdy delete round_trip_import dir since JAX export
 can now export a model with StableHLO + Shardy dialects."

This reverts commit d00f36c2e452cd446f981bedb85e6f972cc6d36a.
---
 shardy/round_trip_import/BUILD                | 117 ++++++++
 shardy/round_trip_import/README.md            |   8 +
 shardy/round_trip_import/constants.h          | 118 +++++++++
 .../import_sdy_custom_calls.cc                | 155 +++++++++++
 .../import_sdy_custom_calls.h                 |  37 +++
 .../round_trip_import/import_shardy_attrs.cc  | 211 +++++++++++++++
 .../round_trip_import/import_shardy_attrs.h   |  40 +++
 .../import_uninlineable_func_calls.cc         | 158 +++++++++++
 .../import_uninlineable_func_calls.h          |  43 +++
 shardy/round_trip_import/pipelines.cc         |  66 +++++
 shardy/round_trip_import/pipelines.h          |  41 +++
 shardy/round_trip_import/shard_map_import.cc  | 197 ++++++++++++++
 shardy/round_trip_import/shard_map_import.h   |  38 +++
 shardy/round_trip_import/test/BUILD           |  21 ++
 .../test/import_uninlineable_func_calls.mlir  | 133 ++++++++++
 .../test/sdy_round_trip_import_pipeline.mlir  | 174 ++++++++++++
 .../test/sdy_round_trip_shard_map_import.mlir | 250 ++++++++++++++++++
 ...y_round_trip_shard_map_import_failure.mlir |  19 ++
 ...nd_trip_sharding_group_import_failure.mlir |  18 ++
 shardy/round_trip_import/utils.cc             | 162 ++++++++++++
 shardy/round_trip_import/utils.h              |  91 +++++++
 shardy/tools/BUILD                            |   1 +
 shardy/tools/sdy_opt_main.cc                  |   4 +
 23 files changed, 2102 insertions(+)
 create mode 100644 shardy/round_trip_import/BUILD
 create mode 100644 shardy/round_trip_import/README.md
 create mode 100644 shardy/round_trip_import/constants.h
 create mode 100644 shardy/round_trip_import/import_sdy_custom_calls.cc
 create mode 100644 shardy/round_trip_import/import_sdy_custom_calls.h
 create mode 100644 shardy/round_trip_import/import_shardy_attrs.cc
 create mode 100644 shardy/round_trip_import/import_shardy_attrs.h
 create mode 100644 shardy/round_trip_import/import_uninlineable_func_calls.cc
 create mode 100644 shardy/round_trip_import/import_uninlineable_func_calls.h
 create mode 100644 shardy/round_trip_import/pipelines.cc
 create mode 100644 shardy/round_trip_import/pipelines.h
 create mode 100644 shardy/round_trip_import/shard_map_import.cc
 create mode 100644 shardy/round_trip_import/shard_map_import.h
 create mode 100644 shardy/round_trip_import/test/BUILD
 create mode 100644 shardy/round_trip_import/test/import_uninlineable_func_calls.mlir
 create mode 100644 shardy/round_trip_import/test/sdy_round_trip_import_pipeline.mlir
 create mode 100644 shardy/round_trip_import/test/sdy_round_trip_shard_map_import.mlir
 create mode 100644 shardy/round_trip_import/test/sdy_round_trip_shard_map_import_failure.mlir
 create mode 100644 shardy/round_trip_import/test/sdy_round_trip_sharding_group_import_failure.mlir
 create mode 100644 shardy/round_trip_import/utils.cc
 create mode 100644 shardy/round_trip_import/utils.h

diff --git a/shardy/round_trip_import/BUILD b/shardy/round_trip_import/BUILD
new file mode 100644
index 0000000..4b66558
--- /dev/null
+++ b/shardy/round_trip_import/BUILD
@@ -0,0 +1,117 @@
+package(default_visibility = ["//visibility:public"])
+
+cc_library(
+    name = "constants",
+    hdrs = ["constants.h"],
+    deps = ["@llvm-project//llvm:Support"],
+)
+
+cc_library(
+    name = "utils",
+    srcs = ["utils.cc"],
+    hdrs = ["utils.h"],
+    deps = [
+        ":constants",
+        "//shardy/dialect/sdy/ir:dialect",
+        "//shardy/dialect/sdy/ir:register",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AsmParser",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:FuncExtensions",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "import_sdy_custom_calls",
+    srcs = ["import_sdy_custom_calls.cc"],
+    hdrs = ["import_sdy_custom_calls.h"],
+    deps = [
+        ":constants",
+        ":utils",
+        "//shardy/dialect/sdy/ir:dialect",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "import_uninlineable_func_calls",
+    srcs = ["import_uninlineable_func_calls.cc"],
+    hdrs = ["import_uninlineable_func_calls.h"],
+    deps = [
+        ":constants",
+        ":utils",
+        "//shardy/dialect/sdy/ir:dialect",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+    ],
+)
+
+cc_library(
+    name = "import_shardy_attrs",
+    srcs = ["import_shardy_attrs.cc"],
+    hdrs = ["import_shardy_attrs.h"],
+    deps = [
+        "constants",
+        ":utils",
+        "//shardy/dialect/sdy/ir:dialect",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AsmParser",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Parser",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "shard_map_import",
+    srcs = ["shard_map_import.cc"],
+    hdrs = ["shard_map_import.h"],
+    deps = [
+        ":constants",
+        ":utils",
+        "//shardy/dialect/sdy/ir:dialect",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "pipelines",
+    srcs = ["pipelines.cc"],
+    hdrs = ["pipelines.h"],
+    deps = [
+        ":import_sdy_custom_calls",
+        ":import_shardy_attrs",
+        ":import_uninlineable_func_calls",
+        ":shard_map_import",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+        "@stablehlo//:stablehlo_passes",
+        "@stablehlo//:stablehlo_passes_optimization",
+    ],
+)
diff --git a/shardy/round_trip_import/README.md b/shardy/round_trip_import/README.md
new file mode 100644
index 0000000..1dcbf6d
--- /dev/null
+++ b/shardy/round_trip_import/README.md
@@ -0,0 +1,8 @@
+#Shardy round_trip_import
+
+This directory only temporarily exists and will be removed once stablehlo
+supports deserialization/serialization with different dialects.
+
+This directory duplicate the xla/service/spmd/shardy implementation for
+addSdyRoundTripImportPipeline and registerSdyRoundTripImportPipeline, to remove
+the xla dependency.
diff --git a/shardy/round_trip_import/constants.h b/shardy/round_trip_import/constants.h
new file mode 100644
index 0000000..e59838d
--- /dev/null
+++ b/shardy/round_trip_import/constants.h
@@ -0,0 +1,118 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_CONSTANTS_H_
+#define SHARDY_ROUND_TRIP_IMPORT_CONSTANTS_H_
+
+#include "llvm/ADT/StringRef.h"
+
+namespace mlir {
+namespace sdy {
+
+// The attribute name for xla::HloSharding.
+inline constexpr llvm::StringRef kXlaShardingAttr = "mhlo.sharding";
+
+// The target name of the Sharding custom call.
+inline constexpr llvm::StringRef kShardingCustomCallTargetName = "Sharding";
+
+// The target name of the Python CPU callback custom call.
+inline constexpr llvm::StringRef kPythonCpuCallbackCustomCallTargetName =
+    "xla_python_cpu_callback";
+
+// The target name of the FFI Python CPU callback custom call.
+inline constexpr llvm::StringRef kFFIPythonCpuCallbackCustomCallTargetName =
+    "xla_ffi_python_cpu_callback";
+
+// The target name of the Python GPU callback custom call.
+inline constexpr llvm::StringRef kPythonGpuCallbackCustomCallTargetName =
+    "xla_python_gpu_callback";
+
+// The target name of the FFI Python GPU callback custom call.
+inline constexpr llvm::StringRef kFFIPythonGpuCallbackCustomCallTargetName =
+    "xla_ffi_python_gpu_callback";
+
+// The attribute name for backend config.
+inline constexpr llvm::StringRef kXlaBackendConfigAttr = "backend_config";
+
+// The attribute name for inlineable.
+inline constexpr llvm::StringRef kXlaInlineableAttr = "inlineable";
+
+// Attribute name for temporarily storing the Shardy sharding during HLO
+// sdy-round-trip. It cannot match the name `kShardingAttr` ("sdy.sharding"), as
+// during sdy-round-trip, going from HLO to StableHLO, the code removes
+// attributes in the `frontend_attributes` field, making them top level. And
+// Shardy verification expects `kShardingAttr` to be of type
+// TensorShardingAttr/TensorShardingPerValueAttr - not a StringAttr.
+inline constexpr llvm::StringRef kShardingRoundTripAttr = "xla.sdy.sharding";
+
+// Attribute name for temporarily storing the Shardy sharding rule during HLO
+// sdy-round-trip. It cannot match the name `kShardingRuleAttr`
+// ("sdy.sharding_rule"), as during sdy-round-trip, going from HLO to StableHLO,
+// the code removes attributes in the `frontend_attributes` field, making them
+// top level. And Shardy verification expects `kShardingRuleAttr` to be of type
+// OpShardingRuleAttr - not a StringAttr.
+inline constexpr llvm::StringRef kShardingRuleRoundTripAttr =
+    "xla.sdy.sharding_rule";
+
+// Attribute name for temporarily storing the Shardonnay meshes during HLO
+// round-trip.
+inline constexpr llvm::StringRef kMeshesRoundTripAttr = "xla.sdy.meshes";
+
+// The target name of the custom call when round tripping during HLO
+// round-trip.
+inline constexpr llvm::StringRef kFuncResultShardingTargetName =
+    "xla.sdy.FuncResultSharding";
+
+// The target name of the ShardingGroup custom call.
+inline constexpr llvm::StringRef kShardingGroupCustomCallTargetName =
+    "xla.sdy.ShardingGroup";
+
+// Sharding group id attribute name. The attribute will be of type `int64_t`
+// and will be used to identify a group of ops that should be sharded together.
+inline constexpr llvm::StringRef kShardingGroupIdAttr =
+    "xla.sdy.sharding_group_id";
+
+// Attribute name for storing frontend attributes in XLA.
+inline constexpr llvm::StringRef kFrontendAttributesAttr =
+    "mhlo.frontend_attributes";
+
+// Attribute name for the in shardings of a `ManualComputationOp`.
+inline constexpr llvm::StringRef kInShardings = "xla.sdy.in_shardings";
+
+// Attribute name for the out shardings of a `ManualComputationOp`.
+inline constexpr llvm::StringRef kOutShardings = "xla.sdy.out_shardings";
+
+// Attribute name for the manual axes of a `ManualComputationOp`.
+inline constexpr llvm::StringRef kManualAxes = "xla.sdy.manual_axes";
+
+// The function name of the of the body of a `ManualComputationOp` during Shardy
+// round tripping. Used
+inline constexpr llvm::StringRef kManualComputationBodyFuncName =
+    "xla.sdy.manual_computation_body";
+
+// The target name of the custom call that changes operands from global to local
+// shape during Shardy round tripping.
+inline constexpr llvm::StringRef kGlobalToLocalShapeCallTargetName =
+    "xla.sdy.GlobalToLocalShape";
+
+// The target name of the custom call that changes results from local to global
+// shape during Shardy round tripping.
+inline constexpr llvm::StringRef kLocalToGlobalShapeCallTargetName =
+    "xla.sdy.LocalToGlobalShape";
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_CONSTANTS_H_
diff --git a/shardy/round_trip_import/import_sdy_custom_calls.cc b/shardy/round_trip_import/import_sdy_custom_calls.cc
new file mode 100644
index 0000000..4daf240
--- /dev/null
+++ b/shardy/round_trip_import/import_sdy_custom_calls.cc
@@ -0,0 +1,155 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "shardy/round_trip_import/import_sdy_custom_calls.h"
+
+#include <cassert>
+#include <cstdint>
+#include <memory>
+#include <optional>
+#include <utility>
+#include <vector>
+
+#include "llvm/ADT/StringRef.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/IR/BuiltinOps.h"
+#include "mlir/IR/MLIRContext.h"
+#include "mlir/IR/OperationSupport.h"
+#include "mlir/Pass/Pass.h"
+#include "mlir/Pass/PassRegistry.h"
+#include "mlir/Support/LLVM.h"
+#include "mlir/Support/LogicalResult.h"
+#include "mlir/Support/TypeID.h"
+#include "mlir/Transforms/DialectConversion.h"
+#include "shardy/dialect/sdy/ir/dialect.h"
+#include "shardy/dialect/sdy/ir/utils.h"
+#include "shardy/round_trip_import/constants.h"
+#include "shardy/round_trip_import/utils.h"
+#include "stablehlo/dialect/StablehloOps.h"
+
+namespace mlir {
+namespace sdy {
+
+namespace {
+
+using ::mlir::stablehlo::CustomCallOp;
+using ::mlir::stablehlo::CustomCallOpAdaptor;
+
+LogicalResult rewriteShardingCustomCall(CustomCallOp op,
+                                        CustomCallOpAdaptor adaptor,
+                                        ConversionPatternRewriter& rewriter) {
+  if (op->getNumResults() != 1) {
+    op.emitError() << "expected CustomCallOp with exactly one result";
+    return failure();
+  }
+  TensorShardingAttr sharding = getSharding(op->getResult(0));
+  if (!sharding) {
+    op.emitError() << "expected CustomCallOp with a sharding attribute";
+    return failure();
+  }
+
+  rewriter.replaceOpWithNewOp<ShardingConstraintOp>(
+      op, adaptor.getInputs().front(), sharding);
+
+  return success();
+}
+
+LogicalResult rewriteShardingGroupCustomCall(
+    CustomCallOp op, CustomCallOpAdaptor adaptor,
+    ConversionPatternRewriter& rewriter) {
+  assert(op.getNumOperands() == 1);
+  assert(op.getNumResults() <= 1);
+  std::optional<IntegerAttr> shardingGroupId =
+      tryGetFrontendAttr<IntegerAttr>(op, kShardingGroupIdAttr);
+  if (!shardingGroupId.has_value()) {
+    return op.emitError() << "expected CustomCallOp with a sharding group id.";
+  }
+  if (!op.use_empty()) {
+    return op.emitError()
+           << "xla.sdy.ShardingGroup CustomCallOp should have no uses.";
+  }
+
+  rewriter.replaceOpWithNewOp<ShardingGroupOp>(op, adaptor.getInputs().front(),
+                                               shardingGroupId->getInt());
+
+  return success();
+}
+
+class SdyCustomCallPattern : public OpConversionPattern<CustomCallOp> {
+  using OpConversionPattern::OpConversionPattern;
+
+  LogicalResult matchAndRewrite(
+      CustomCallOp op, OpAdaptor adaptor,
+      ConversionPatternRewriter& rewriter) const override {
+    if (op.getCallTargetName() == kShardingCustomCallTargetName) {
+      return rewriteShardingCustomCall(op, adaptor, rewriter);
+    }
+
+    if (op.getCallTargetName() == kShardingGroupCustomCallTargetName) {
+      return rewriteShardingGroupCustomCall(op, adaptor, rewriter);
+    }
+
+    return rewriter.notifyMatchFailure(
+        op, "expected CustomCallOp with xla.sdy target name.");
+  }
+};
+
+// Convert custom calls into sdy APIs.
+// * xla.sdy.Sharding -> ShardingConstraintOp
+// * xla.sdy.ShardingGroup -> ShardingGroupOp
+class ImportSdyCustomCallsPass
+    : public PassWrapper<ImportSdyCustomCallsPass, OperationPass<ModuleOp>> {
+ public:
+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(ImportSdyCustomCallsPass)
+
+  void runOnOperation() final {
+    MLIRContext& context = getContext();
+    ConversionTarget target(context);
+    target.addLegalDialect<SdyDialect>();
+    target.addDynamicallyLegalOp<CustomCallOp>([](CustomCallOp op) {
+      return op.getCallTargetName() != kShardingCustomCallTargetName &&
+             op.getCallTargetName() != kShardingGroupCustomCallTargetName;
+    });
+    RewritePatternSet patterns(&context);
+    patterns.add<SdyCustomCallPattern>(&context);
+    if (failed(applyPartialConversion(getOperation(), target,
+                                      std::move(patterns)))) {
+      signalPassFailure();
+    }
+  }
+
+  StringRef getArgument() const override {
+    return "sdy-import-sdy-custom-calls";
+  }
+
+  StringRef getDescription() const override {
+    return "Converts a CustomCall with target name Sharding into a "
+           "ShardingConstraintOp and with target name ShardingGroup into a "
+           "ShardingGroupOp.";
+  }
+};
+
+}  // namespace
+
+std::unique_ptr<Pass> createImportSdyCustomCallsPass() {
+  return std::make_unique<ImportSdyCustomCallsPass>();
+}
+
+void registerImportSdyCustomCallsPass() {
+  registerPass(createImportSdyCustomCallsPass);
+}
+
+}  // namespace sdy
+}  // namespace mlir
diff --git a/shardy/round_trip_import/import_sdy_custom_calls.h b/shardy/round_trip_import/import_sdy_custom_calls.h
new file mode 100644
index 0000000..5961dbd
--- /dev/null
+++ b/shardy/round_trip_import/import_sdy_custom_calls.h
@@ -0,0 +1,37 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_IMPORT_SDY_CUSTOM_CALLS_H_
+#define SHARDY_ROUND_TRIP_IMPORT_IMPORT_SDY_CUSTOM_CALLS_H_
+
+#include <memory>
+
+#include "mlir/Pass/Pass.h"
+
+namespace mlir {
+namespace sdy {
+
+// Creates a pass that imports sdy tagged `CustomCall` ops. Namely it converts
+// * xla.sdy.Sharding -> ShardingConstraintOp
+// * xla.sdy.ShardingGroup -> ShardingGroupOp
+std::unique_ptr<Pass> createImportSdyCustomCallsPass();
+
+// Register the xla-sdy-import-sdy-custom-calls pass.
+void registerImportSdyCustomCallsPass();
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_IMPORT_SDY_CUSTOM_CALLS_H_
diff --git a/shardy/round_trip_import/import_shardy_attrs.cc b/shardy/round_trip_import/import_shardy_attrs.cc
new file mode 100644
index 0000000..02c2c82
--- /dev/null
+++ b/shardy/round_trip_import/import_shardy_attrs.cc
@@ -0,0 +1,211 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "import_shardy_attrs.h"
+
+#include <cassert>
+#include <cstdint>
+#include <memory>
+#include <optional>
+
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/StringRef.h"
+#include "mlir/AsmParser/AsmParser.h"
+#include "mlir/Dialect/Func/IR/FuncOps.h"
+#include "mlir/IR/Attributes.h"
+#include "mlir/IR/Builders.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/IR/BuiltinOps.h"
+#include "mlir/IR/BuiltinTypes.h"
+#include "mlir/IR/Diagnostics.h"
+#include "mlir/IR/MLIRContext.h"
+#include "mlir/IR/Operation.h"
+#include "mlir/IR/PatternMatch.h"
+#include "mlir/IR/SymbolTable.h"
+#include "mlir/IR/Value.h"
+#include "mlir/IR/Visitors.h"
+#include "mlir/Parser/Parser.h"
+#include "mlir/Pass/Pass.h"
+#include "mlir/Pass/PassManager.h"
+#include "mlir/Pass/PassRegistry.h"
+#include "mlir/Support/LLVM.h"
+#include "mlir/Support/TypeID.h"
+#include "mlir/Transforms/DialectConversion.h"
+#include "shardy/dialect/sdy/ir/constants.h"
+#include "shardy/dialect/sdy/ir/dialect.h"
+#include "shardy/round_trip_import/constants.h"
+#include "shardy/round_trip_import/utils.h"
+#include "stablehlo/dialect/StablehloOps.h"
+
+namespace mlir {
+namespace sdy {
+
+namespace {
+
+using ::mlir::func::FuncOp;
+
+// Builds the shardy attributes coming from Shardy previously. This means
+// the module was exported from Shardy and we are now round-tripping back.
+// This should happen after the meshes were created from the `ModuleOp` attrs
+// (see `SdyRoundTripImportShardyAttrsPass`).
+void convertShardyAttrs(FuncOp funcOp, IRRewriter& rewriter) {
+  // Copy over the argument shardings, but not the result shardings yet.
+  // We need to wait until after we've converted all the Operations before
+  // copying the result shardings.
+  for (auto [argNum, argType] : llvm::enumerate(funcOp.getArgumentTypes())) {
+    funcOp.removeArgAttr(argNum, kXlaShardingAttr);
+    // Attempt to extract the TensorShardingAttr from the frontend attributes of
+    // the function argument/result.
+    if (DictionaryAttr dictAttr = getFuncArgFrontendAttrs(funcOp, argNum)) {
+      if (auto sharding = parseStringAttr<TensorShardingAttr>(
+              dictAttr, kShardingRoundTripAttr)) {
+        funcOp.setArgAttr(argNum, kShardingAttr, sharding);
+        removeFrontendAttribute(funcOp, kShardingRoundTripAttr, argNum);
+      }
+    }
+  }
+
+  // Due to `SdyRoundTripExportShardingsPass` keeping `mhlo.sharding`s, remove
+  // them purely for cleanliness of the module.
+  for (int64_t resNum = 0; resNum < funcOp.getNumResults(); ++resNum) {
+    funcOp.removeResultAttr(
+        resNum, StringAttr::get(funcOp.getContext(), kXlaShardingAttr));
+  }
+
+  // Extract the round-tripped SDY shardy attributes from the operations.
+  funcOp.front().walk([&](Operation* op) {
+    op->removeAttr(kXlaShardingAttr);
+    DictionaryAttr dictAttr = getFrontendAttrs(op);
+    if (!dictAttr) {
+      return;
+    }
+    // `SendOp` and `RecvOp` can have a sharding when doing TPU callbacks
+    // through JAX.
+    if (isa<stablehlo::SendOp, stablehlo::RecvOp>(op)) {
+      auto sharding = parseStringAttr<TensorShardingPerValueAttr>(
+          dictAttr, kShardingRoundTripAttr);
+      // Expect sharding to exist for SendOp/RecvOp.
+      assert(sharding != nullptr);
+      op->setAttr(kShardingAttr, sharding);
+    }
+    // NOTE: we are only setting the sharding on known custom-calls. For any
+    // other op that has a `kShardingRoundTripAttr` we discard it. XLA sometimes
+    // creates new instructions, copying over the operand's frontend attrs,
+    // which may mean the shapes are wrong when the new instruction is a reshape
+    // for example. This does mean we can't fully round-trip b/w HLO and MLIR
+    // after SDY propagation.
+    if (auto customCallOp = dyn_cast<stablehlo::CustomCallOp>(op)) {
+      StringRef targetName = customCallOp.getCallTargetName();
+      if (targetName == kFuncResultShardingTargetName) {
+        // This is a temporary CustomCallOp that holds the sharding from a
+        // func result. When importing we want to move that sharding to the
+        // func result and delete the CustomCallOp.
+        auto shardingPerValueAttr = parseStringAttr<TensorShardingPerValueAttr>(
+            dictAttr, kShardingRoundTripAttr);
+        for (OpOperand& use :
+             llvm::make_early_inc_range(customCallOp->getUses())) {
+          // We currently ignore users that are not the func return op.
+          // This might happen due to inlined func ops that originally had
+          // result shardings.
+          // TODO(b/370984308): explore if we need to support this properly.
+          if (isa<func::ReturnOp>(use.getOwner())) {
+            funcOp.setResultAttr(use.getOperandNumber(), kShardingAttr,
+                                 shardingPerValueAttr.getSharding(0));
+            use.set(customCallOp.getOperand(0));
+          }
+        }
+        rewriter.replaceOp(customCallOp, customCallOp.getOperand(0));
+        return;
+      }
+      if (targetName == kShardingCustomCallTargetName ||
+          isPythonCallbackCustomCall(customCallOp)) {
+        customCallOp->setAttr(kShardingAttr,
+                              parseStringAttr<TensorShardingPerValueAttr>(
+                                  dictAttr, kShardingRoundTripAttr));
+      }
+    }
+    removeFrontendAttribute(op, kShardingRoundTripAttr);
+
+    // Import sharding rules.
+    if (auto shardingRuleAttr = parseStringAttr<OpShardingRuleAttr>(
+            dictAttr, kShardingRuleRoundTripAttr)) {
+      op->setAttr(kShardingRuleAttr, shardingRuleAttr);
+      removeFrontendAttribute(op, kShardingRuleRoundTripAttr);
+    }
+  });
+}
+
+class SdyRoundTripImportShardyAttrsPass
+    : public PassWrapper<SdyRoundTripImportShardyAttrsPass,
+                         OperationPass<ModuleOp>> {
+ public:
+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(
+      SdyRoundTripImportShardyAttrsPass)
+
+  void runOnOperation() final {
+    ModuleOp moduleOp = getOperation();
+
+    // We can use the saved string attributes to restore the original mesh and
+    // value shardings with the original mesh axis names and priorities on the
+    // sharding. If there is no `kMeshesRoundTripAttr, there were no meshes in
+    // the original Shardy model.
+    std::optional<DictionaryAttr> meshesAttr =
+        tryGetFrontendAttr<DictionaryAttr>(moduleOp, kMeshesRoundTripAttr);
+    ArrayRef<NamedAttribute> sdyMeshes = meshesAttr.has_value()
+                                             ? meshesAttr.value().getValue()
+                                             : ArrayRef<NamedAttribute>();
+
+    IRRewriter rewriter(moduleOp);
+    // Insert the meshes before any functions.
+    rewriter.setInsertionPointToStart(moduleOp.getBody());
+    SymbolTable symbolTable(moduleOp);
+    for (NamedAttribute mesh : sdyMeshes) {
+      auto meshAttr = cast<MeshAttr>(mesh.getValue());
+      symbolTable.insert(
+          rewriter.create<MeshOp>(moduleOp.getLoc(), mesh.getName(), meshAttr));
+    }
+    removeFrontendAttribute(moduleOp, kMeshesRoundTripAttr);
+
+    for (auto funcOp : moduleOp.getOps<FuncOp>()) {
+      convertShardyAttrs(funcOp, rewriter);
+    }
+  }
+
+  StringRef getArgument() const override {
+    return "sdy-round-trip-import-shardy-attrs";
+  }
+
+  StringRef getDescription() const override {
+    return "Converts the shardy attributes from strings in MHLO frontend "
+           "attributes to SDY meshes, shardings and sharding rules.";
+  }
+
+  void getDependentDialects(DialectRegistry& registry) const final {
+    registry.insert<SdyDialect>();
+  }
+};
+
+}  // namespace
+
+std::unique_ptr<Pass> createSdyRoundTripImportShardyAttrsPass() {
+  return std::make_unique<SdyRoundTripImportShardyAttrsPass>();
+}
+
+void registerSdyRoundTripImportShardyAttrsPass() {
+  registerPass(createSdyRoundTripImportShardyAttrsPass);
+}
+
+}  // namespace sdy
+}  // namespace mlir
diff --git a/shardy/round_trip_import/import_shardy_attrs.h b/shardy/round_trip_import/import_shardy_attrs.h
new file mode 100644
index 0000000..1d30a79
--- /dev/null
+++ b/shardy/round_trip_import/import_shardy_attrs.h
@@ -0,0 +1,40 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_IMPORT_SHARDY_ATTRS_H_
+#define SHARDY_ROUND_TRIP_IMPORT_IMPORT_SHARDY_ATTRS_H_
+
+#include <memory>
+
+#include "mlir/Pass/Pass.h"
+
+namespace mlir {
+namespace sdy {
+
+// Creates the pass to convert frontend attributes to SDY attributes:
+//
+// - Converts shardings from `kShardingRoundTripAttr` to `kShardingAttr`
+// - Converts sharding rules from `kShardingRuleRoundTripAttr` to
+//   `kShardingRuleAttr`
+// - Converts meshes from `kMeshesRoundTripAttr` to sdy.mesh symbols
+std::unique_ptr<Pass> createSdyRoundTripImportShardyAttrsPass();
+
+// Registers the xla-sdy-round-trip-import-shardy-attrs pass.
+void registerSdyRoundTripImportShardyAttrsPass();
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_IMPORT_SHARDY_ATTRS_H_
diff --git a/shardy/round_trip_import/import_uninlineable_func_calls.cc b/shardy/round_trip_import/import_uninlineable_func_calls.cc
new file mode 100644
index 0000000..9f2ce6d
--- /dev/null
+++ b/shardy/round_trip_import/import_uninlineable_func_calls.cc
@@ -0,0 +1,158 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "shardy/round_trip_import/import_uninlineable_func_calls.h"
+
+#include <cassert>
+#include <iterator>
+#include <memory>
+#include <string>
+
+#include "llvm/ADT/DenseMap.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/Support/FormatVariadic.h"
+#include "llvm/Support/Threading.h"
+#include "mlir/Dialect/Func/IR/FuncOps.h"
+#include "mlir/IR/Attributes.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/IR/BuiltinOps.h"
+#include "mlir/IR/Diagnostics.h"
+#include "mlir/IR/OperationSupport.h"
+#include "mlir/IR/PatternMatch.h"
+#include "mlir/IR/SymbolTable.h"
+#include "mlir/Pass/Pass.h"
+#include "mlir/Pass/PassRegistry.h"
+#include "mlir/Support/LLVM.h"
+#include "mlir/Support/TypeID.h"
+#include "mlir/Transforms/DialectConversion.h"
+#include "shardy/dialect/sdy/ir/constants.h"
+#include "shardy/dialect/sdy/ir/dialect.h"
+#include "shardy/dialect/sdy/ir/utils.h"
+#include "shardy/round_trip_import/constants.h"
+#include "shardy/round_trip_import/utils.h"
+
+namespace mlir {
+namespace sdy {
+
+namespace {
+
+using func::CallOp;
+using func::FuncOp;
+
+bool isInlineableCallOp(CallOp callOp) {
+  if (hasFrontendAttr(callOp, kXlaBackendConfigAttr)) {
+    return false;
+  }
+  auto inlineableAttr =
+      tryGetFrontendAttr<BoolAttr>(callOp, kXlaInlineableAttr);
+  return !inlineableAttr || inlineableAttr->getValue();
+}
+
+void importCallOp(
+    CallOp callOp,
+    llvm::SmallDenseMap<StringRef, Region*>& calleeNameToMovedRegion,
+    IRRewriter& rewriter, SymbolTable& symbolTable) {
+  SmallVector<NamedAttribute> namedCompAttrs;
+  llvm::copy_if(callOp->getDiscardableAttrs(),
+                std::back_inserter(namedCompAttrs),
+                [](const NamedAttribute& attr) {
+                  return attr.getName() != kShardingAttr;
+                });
+
+  StringRef calleeName = callOp.getCallee();
+  rewriter.setInsertionPoint(callOp);
+  auto namedCompOp = rewriter.create<NamedComputationOp>(
+      callOp->getLoc(), callOp->getResultTypes(), calleeName,
+      callOp.getOperands(),
+      /*inShardings=*/nullptr,
+      /*outShardings=*/getShardingPerValue(callOp));
+  namedCompOp->setAttrs(namedCompAttrs);
+
+  Region& namedCompRegion = namedCompOp.getRegion();
+  if (auto movedRegionIt = calleeNameToMovedRegion.find(calleeName);
+      movedRegionIt != calleeNameToMovedRegion.end()) {
+    static llvm::once_flag onceFlag;
+    emitOpWarningOnce(
+        onceFlag, callOp,
+        llvm::formatv("uninlineable function @{0} has multiple call ops, we "
+                      "need to clone the function body for each call",
+                      calleeName)
+            .str());
+    rewriter.cloneRegionBefore(*movedRegionIt->second, namedCompRegion,
+                               namedCompRegion.begin());
+  } else {
+    FuncOp funcOp = symbolTable.lookup<FuncOp>(calleeName);
+    assert(funcOp &&
+           ("Failed to lookup function: " + std::string(calleeName)).c_str());
+    inlineRegionAndConvertTerminatorOp<ReturnOp>(funcOp.getBody(),
+                                                 namedCompRegion);
+    calleeNameToMovedRegion[calleeName] = &namedCompRegion;
+  }
+
+  rewriter.replaceOp(callOp, namedCompOp);
+}
+
+class ImportUninlineableFuncCallsPass
+    : public PassWrapper<ImportUninlineableFuncCallsPass,
+                         OperationPass<ModuleOp>> {
+ public:
+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(ImportUninlineableFuncCallsPass)
+
+  void runOnOperation() final {
+    ModuleOp moduleOp = getOperation();
+    IRRewriter rewriter(moduleOp.getContext());
+    SymbolTable symbolTable(moduleOp);
+    // For every callee name, the first CallOp encountered with that symbol will
+    // move the body of the callee into the created NamedComputationOp, and map
+    // the symbol name to the moved region. Subsequent CallOps with that symbol
+    // will clone the mapped region.
+    llvm::SmallDenseMap<StringRef, Region*> calleeNameToMovedRegion;
+
+    moduleOp->walk([&](CallOp op) {
+      if (isInlineableCallOp(op)) {
+        return;
+      }
+      importCallOp(op, calleeNameToMovedRegion, rewriter, symbolTable);
+    });
+
+    // Erase all func ops that now have no call ops.
+    for (auto [calleeName, _] : calleeNameToMovedRegion) {
+      symbolTable.erase(symbolTable.lookup(calleeName));
+    }
+  }
+
+  StringRef getArgument() const override {
+    return "xla-sdy-import-uninlineable-func-calls";
+  }
+
+  StringRef getDescription() const override {
+    return "Creates a pass that converts a `CallOp` with a `backend_config` "
+           "or `inlineable=false` frontend attr to a `NamedComputationOp` with "
+           "the function body inlined and the name of the callee.";
+  }
+};
+
+}  // namespace
+
+std::unique_ptr<Pass> createImportUninlineableFuncCallsPass() {
+  return std::make_unique<ImportUninlineableFuncCallsPass>();
+}
+
+void registerImportUninlineableFuncCallsPass() {
+  registerPass(createImportUninlineableFuncCallsPass);
+}
+
+}  // namespace sdy
+}  // namespace mlir
diff --git a/shardy/round_trip_import/import_uninlineable_func_calls.h b/shardy/round_trip_import/import_uninlineable_func_calls.h
new file mode 100644
index 0000000..350b091
--- /dev/null
+++ b/shardy/round_trip_import/import_uninlineable_func_calls.h
@@ -0,0 +1,43 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_IMPORT_UNINLINEABLE_FUNC_CALLS_H_
+#define SHARDY_ROUND_TRIP_IMPORT_IMPORT_UNINLINEABLE_FUNC_CALLS_H_
+
+#include <memory>
+
+#include "mlir/Pass/Pass.h"
+
+namespace mlir {
+namespace sdy {
+
+// Creates a pass that converts a `CallOp` with a `backend_config` or
+// `inlineable=false` frontend attr to a `NamedComputationOp` with the function
+// body inlined and name of the callee.
+//
+// This pass is used to handle host offloading and GPU stream calls which are
+// non inlined functions that require the callee to be propagated through.
+//
+// NOTE: In case there are multiple call ops for the same callee, we will clone
+// the function body for each call op and emit a warning.
+std::unique_ptr<mlir::Pass> createImportUninlineableFuncCallsPass();
+
+// Register the xla-sdy-import-uninlineable-calls pass.
+void registerImportUninlineableFuncCallsPass();
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_IMPORT_UNINLINEABLE_FUNC_CALLS_H_
diff --git a/shardy/round_trip_import/pipelines.cc b/shardy/round_trip_import/pipelines.cc
new file mode 100644
index 0000000..69c82db
--- /dev/null
+++ b/shardy/round_trip_import/pipelines.cc
@@ -0,0 +1,66 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "shardy/round_trip_import/pipelines.h"
+
+#include <cassert>
+#include <functional>
+
+#include "mlir/Dialect/Func/IR/FuncOps.h"
+#include "mlir/Pass/PassManager.h"
+#include "mlir/Pass/PassRegistry.h"
+#include "mlir/Transforms/GreedyPatternRewriteDriver.h"
+#include "mlir/Transforms/Passes.h"
+#include "shardy/round_trip_import/import_uninlineable_func_calls.h"
+#include "shardy/round_trip_import/import_sdy_custom_calls.h"
+#include "shardy/round_trip_import/import_shardy_attrs.h"
+#include "shardy/round_trip_import/shard_map_import.h"
+#include "stablehlo/transforms/optimization/Passes.h"
+
+namespace mlir {
+namespace sdy {
+
+void addSdyRoundTripImportPipeline(OpPassManager& pm) {
+  GreedyRewriteConfig config;
+  config.setUseTopDownTraversal(true)
+      .setRegionSimplificationLevel(GreedySimplifyRegionLevel::Disabled)
+      .enableFolding(false)
+      .enableConstantCSE(false);
+  pm.addNestedPass<func::FuncOp>(
+      stablehlo::createStablehloAggressiveSimplificationPass({}, config));
+  pm.addPass(createSdyRoundTripImportShardyAttrsPass());
+  pm.addPass(createSdyRoundTripShardMapImportPass());
+  pm.addPass(createImportSdyCustomCallsPass());
+  pm.addPass(createImportUninlineableFuncCallsPass());
+}
+
+void registerSdyRoundTripImportPipeline() {
+  PassPipelineRegistration<> importPipeline(
+      "sdy-round-trip-import-pipeline",
+      "Run passes to import a StableHLO module into the SDY (Shardy) dialect.",
+      addSdyRoundTripImportPipeline);
+}
+
+void registerAllSdyRoundTripImportPassesAndPipeline() {
+  registerImportSdyCustomCallsPass();
+  registerImportUninlineableFuncCallsPass();
+  registerSdyRoundTripImportShardyAttrsPass();
+  registerSdyRoundTripShardMapImportPass();
+
+  registerSdyRoundTripImportPipeline();
+}
+
+}  // namespace sdy
+}  // namespace mlir
diff --git a/shardy/round_trip_import/pipelines.h b/shardy/round_trip_import/pipelines.h
new file mode 100644
index 0000000..b1b549f
--- /dev/null
+++ b/shardy/round_trip_import/pipelines.h
@@ -0,0 +1,41 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_PIPELINES_H_
+#define SHARDY_ROUND_TRIP_IMPORT_PIPELINES_H_
+
+#include "mlir/Pass/PassManager.h"
+
+namespace mlir {
+namespace sdy {
+
+// Add the sdy-round-trip-import-pipeline in `pm`. The pipeline,
+// including a sequence of passes, imports an StableHLO module into the
+// SDY (Shardy) dialect.
+//
+// The module is assumed to have `kShardingRoundTripAttr` and
+// `kMeshesRoundTripAttr`.
+void addSdyRoundTripImportPipeline(OpPassManager& pm);
+
+// Register the sdy-round-trip-import-pipeline.
+void registerSdyRoundTripImportPipeline();
+
+// Register all sdy-round-trip-import passes and the pipeline.
+void registerAllSdyRoundTripImportPassesAndPipeline();
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_PIPELINES_H_
diff --git a/shardy/round_trip_import/shard_map_import.cc b/shardy/round_trip_import/shard_map_import.cc
new file mode 100644
index 0000000..6393fea
--- /dev/null
+++ b/shardy/round_trip_import/shard_map_import.cc
@@ -0,0 +1,197 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "shardy/round_trip_import/shard_map_import.h"
+
+#include <cassert>
+#include <memory>
+#include <utility>
+
+#include "llvm/ADT/StringRef.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "mlir/Dialect/Func/IR/FuncOps.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/IR/BuiltinOps.h"
+#include "mlir/IR/Diagnostics.h"
+#include "mlir/IR/DialectRegistry.h"
+#include "mlir/IR/MLIRContext.h"
+#include "mlir/IR/Operation.h"
+#include "mlir/IR/PatternMatch.h"
+#include "mlir/IR/SymbolTable.h"
+#include "mlir/IR/TypeRange.h"
+#include "mlir/IR/Value.h"
+#include "mlir/IR/ValueRange.h"
+#include "mlir/IR/Visitors.h"
+#include "mlir/Pass/Pass.h"
+#include "mlir/Pass/PassManager.h"
+#include "mlir/Pass/PassRegistry.h"
+#include "mlir/Support/LLVM.h"
+#include "mlir/Support/TypeID.h"
+#include "mlir/Transforms/DialectConversion.h"
+#include "shardy/dialect/sdy/ir/dialect.h"
+#include "shardy/dialect/sdy/ir/utils.h"
+#include "shardy/round_trip_import/constants.h"
+#include "shardy/round_trip_import/utils.h"
+#include "stablehlo/dialect/StablehloOps.h"
+
+namespace mlir {
+namespace sdy {
+
+namespace {
+
+using ::mlir::func::CallOp;
+using ::mlir::func::FuncOp;
+using ::mlir::stablehlo::CustomCallOp;
+
+// Converts a CallOp calling a @xla.sdy.manual_computation_body func with in/out
+// shardings and manual axes as frontend attrs, wrapped with custom calls that
+// change the shape of the arguments/results to a `ManualComputationOp`. See
+// `SdyRoundTripShardMapExportPass` for its counterpart.
+class ManualComputationPattern : public OpConversionPattern<CallOp> {
+ public:
+  explicit ManualComputationPattern(MLIRContext* context,
+                                    const SymbolTable& symbolTable)
+      : OpConversionPattern<CallOp>(context), symbolTable(symbolTable) {}
+
+  LogicalResult matchAndRewrite(
+      CallOp callOp, OpAdaptor adaptor,
+      ConversionPatternRewriter& rewriter) const override {
+    if (!callOp.getCallee().contains(kManualComputationBodyFuncName)) {
+      return failure();
+    }
+
+    // NOTE: if the original `ManualComputationOp` had no operands (results),
+    // then a @GlobalToLocalShape (@LocalToGlobalShape) custom call won't be
+    // present. So we have to take the operands/results of the newly created
+    // `ManualComputationOp` differently depending on whether the original had
+    // operands/results.
+    CustomCallOp globalToLocalShape;
+    ValueRange operands = callOp->getOperands();
+    if (!operands.empty()) {
+      // An input to `sdy.manual_computation` can have a dimension of size 0
+      // (i.e. 0 num-elements), in which case, the corresponding result of
+      // `GlobalToLocalShape` custom call would be replaced with a constant of
+      // the same shape. Therefore, we skip such operands until we find the
+      // first one that is produced by the custom call.
+      auto customCallResIt = llvm::find_if(operands, [](Value operand) {
+        return operand.getDefiningOp<CustomCallOp>();
+      });
+      assert(customCallResIt != operands.end());
+      globalToLocalShape = (*customCallResIt).getDefiningOp<CustomCallOp>();
+      assert(globalToLocalShape.getCallTargetName() ==
+             kGlobalToLocalShapeCallTargetName);
+      operands = globalToLocalShape->getOperands();
+    }
+    TypeRange resultTypes = callOp->getResultTypes();
+    CustomCallOp localToGlobalShape;
+    if (!resultTypes.empty()) {
+      assert(
+          callOp->getResult(0).hasOneUse() &&
+          "all CallOp results should be used by a single LocalToGlobalShape");
+      localToGlobalShape =
+          cast<CustomCallOp>(*callOp->getResult(0).getUsers().begin());
+      resultTypes = localToGlobalShape->getResultTypes();
+      assert(localToGlobalShape.getCallTargetName() ==
+             kLocalToGlobalShapeCallTargetName);
+    }
+
+    auto shmapBodyFunc = symbolTable.lookup<FuncOp>(callOp.getCallee());
+    if (shmapBodyFunc.empty()) {
+      return callOp->emitOpError(
+          "expected a unique FuncOp per "
+          "@xla.sdy.manual_computation_body call. Were "
+          "functions maybe somehow shared/de-duped between "
+          "two ManualComputations?");
+    }
+
+    DictionaryAttr frontendAttrs = getFrontendAttrs(callOp);
+    assert(frontendAttrs &&
+           "Expected in/out shardings and manual axes as frontend attrs on the "
+           "CallOp during round tripping.");
+    auto manualComputationOp = rewriter.replaceOpWithNewOp<ManualComputationOp>(
+        callOp, resultTypes, operands,
+        parseStringAttr<TensorShardingPerValueAttr>(frontendAttrs,
+                                                    kInShardings),
+        parseStringAttr<TensorShardingPerValueAttr>(frontendAttrs,
+                                                    kOutShardings),
+        parseStringAttr<ManualAxesAttr>(frontendAttrs, kManualAxes));
+    inlineRegionAndConvertTerminatorOp<ReturnOp>(
+        shmapBodyFunc.getBody(), manualComputationOp.getRegion(), rewriter);
+    rewriter.eraseOp(shmapBodyFunc);
+    if (globalToLocalShape) {
+      rewriter.eraseOp(globalToLocalShape);
+    }
+    if (localToGlobalShape) {
+      rewriter.replaceOp(localToGlobalShape, manualComputationOp->getResults());
+    }
+    return success();
+  }
+
+ private:
+  const SymbolTable& symbolTable;
+};
+
+class SdyRoundTripShardMapImportPass
+    : public PassWrapper<SdyRoundTripShardMapImportPass,
+                         OperationPass<ModuleOp>> {
+ public:
+  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(SdyRoundTripShardMapImportPass)
+
+ private:
+  void runOnOperation() final {
+    ModuleOp module = getOperation();
+    SymbolTableCollection symbolTableCollection;
+    SymbolTable& symbolTable = symbolTableCollection.getSymbolTable(module);
+    MLIRContext& context = getContext();
+    ConversionTarget target(context);
+    target.addDynamicallyLegalOp<CallOp>([](CallOp op) {
+      return !op.getCallee().contains(kManualComputationBodyFuncName);
+    });
+    target.addLegalOp<ManualComputationOp, ReturnOp, CustomCallOp>();
+    RewritePatternSet patterns(&context);
+    patterns.add<ManualComputationPattern>(&context, symbolTable);
+    if (failed(applyPartialConversion(module, target, std::move(patterns)))) {
+      signalPassFailure();
+    }
+  }
+
+  StringRef getArgument() const override {
+    return "sdy-round-trip-shard-map-import";
+  }
+
+  StringRef getDescription() const override {
+    return "converts a CallOp calling a @xla.sdy.manual_computation_body func "
+           "with in/out shardings and manual axes as frontend attrs, wrapped "
+           "with a pair of `CustomCallOps` that change the shape of the "
+           "arguments/results, to a ManualComputationOp";
+  }
+  void getDependentDialects(DialectRegistry& registry) const final {
+    registry.insert<SdyDialect>();
+  }
+};
+
+}  // namespace
+
+void registerSdyRoundTripShardMapImportPass() {
+  registerPass(createSdyRoundTripShardMapImportPass);
+}
+
+std::unique_ptr<Pass> createSdyRoundTripShardMapImportPass() {
+  return std::make_unique<SdyRoundTripShardMapImportPass>();
+}
+
+}  // namespace sdy
+}  // namespace mlir
diff --git a/shardy/round_trip_import/shard_map_import.h b/shardy/round_trip_import/shard_map_import.h
new file mode 100644
index 0000000..a57bf44
--- /dev/null
+++ b/shardy/round_trip_import/shard_map_import.h
@@ -0,0 +1,38 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_SHARD_MAP_IMPORT_H_
+#define SHARDY_ROUND_TRIP_IMPORT_SHARD_MAP_IMPORT_H_
+
+#include <memory>
+
+#include "mlir/Pass/Pass.h"
+
+namespace mlir {
+namespace sdy {
+
+// Creates the pass that converts a `CallOp` calling
+// `@xla.sdy.manual_computation_body` with in/out shardings and manual
+// axes as frontend attrs, wrapped with a pair of `CustomCallOp`s that change
+// the shape of the arguments/results, to a `ManualComputationOp`.
+std::unique_ptr<Pass> createSdyRoundTripShardMapImportPass();
+
+// Registers the xla-sdy-round-trip-shard-map-import pass.
+void registerSdyRoundTripShardMapImportPass();
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_SHARD_MAP_IMPORT_H_
diff --git a/shardy/round_trip_import/test/BUILD b/shardy/round_trip_import/test/BUILD
new file mode 100644
index 0000000..673ff96
--- /dev/null
+++ b/shardy/round_trip_import/test/BUILD
@@ -0,0 +1,21 @@
+# Lit tests for the Shardy round-trip import passes.
+
+load("//shardy:lit.bzl", "glob_lit_tests")
+
+package(default_visibility = ["//visibility:public"])
+
+filegroup(
+    name = "test_data",
+    testonly = True,
+    data = [
+        "//shardy/tools:sdy_opt",
+        "@llvm-project//llvm:FileCheck",
+    ],
+)
+
+glob_lit_tests(
+    name = "all_tests",
+    data = [":test_data"],
+    driver = "@llvm-project//mlir:run_lit.sh",
+    test_file_exts = ["mlir"],
+)
diff --git a/shardy/round_trip_import/test/import_uninlineable_func_calls.mlir b/shardy/round_trip_import/test/import_uninlineable_func_calls.mlir
new file mode 100644
index 0000000..e01152f
--- /dev/null
+++ b/shardy/round_trip_import/test/import_uninlineable_func_calls.mlir
@@ -0,0 +1,133 @@
+// RUN: sdy_opt --split-input-file %s -xla-sdy-import-uninlineable-func-calls  2>&1 | FileCheck %s
+// RUN: sdy_opt %s -split-input-file -xla-sdy-import-uninlineable-func-calls -verify-diagnostics
+
+sdy.mesh @mesh = #sdy.mesh<["x"=2, "y"=2]>
+
+// CHECK-LABEL: func @backend_config_no_out_shardings
+func.func @backend_config_no_out_shardings(%arg0: tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) -> (tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) {
+  // CHECK-NEXT: %[[NC:.*]] = sdy.named_computation<"foo">(%arg0) (%arg1: tensor<8x2xi32>) {
+  // CHECK-NEXT:   %[[MULT:.*]] = stablehlo.multiply %arg1, %arg1 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  // CHECK-NEXT:   sdy.return %[[MULT]] : tensor<8x2xi32>
+  // CHECK-NEXT: } {mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"},
+  // CHECK-SAME:    random_attr = "random_value"}
+  // CHECK-SAME: (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // CHECK-NEXT: %[[MOVE_TO_HOST:.*]] = stablehlo.custom_call @MoveToHost(%[[NC]]) {backend_config = ""} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // CHECK-NEXT: return %[[MOVE_TO_HOST]] : tensor<8x2xi32>
+  %0 = call @foo(%arg0) {random_attr = "random_value", mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"}} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  %1 = stablehlo.custom_call @MoveToHost(%0) {backend_config = ""} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  return %1 : tensor<8x2xi32>
+}
+
+// CHECK-NOT: func private @foo
+func.func private @foo(%arg0: tensor<8x2xi32>) -> tensor<8x2xi32> {
+  %0 = stablehlo.multiply %arg0, %arg0 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  return %0 : tensor<8x2xi32>
+}
+
+// CHECK-LABEL: func @backend_config_out_shardings
+func.func @backend_config_out_shardings(%arg0: tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) -> (tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) {
+  // CHECK-NEXT: %[[NC:.*]] = sdy.named_computation<"bar">(%arg0) out_shardings=[<@mesh, [{"x"}, {"y"}]>] (%arg1: tensor<8x2xi32>) {
+  // CHECK-NEXT:   %[[MULT:.*]] = stablehlo.multiply %arg1, %arg1 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  // CHECK-NEXT:   sdy.return %[[MULT]] : tensor<8x2xi32>
+  // CHECK-NEXT: } {mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"},
+  // CHECK-SAME:    random_attr = "random_value"}
+  // CHECK-SAME: (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // CHECK-NEXT: %[[MOVE_TO_HOST:.*]] = stablehlo.custom_call @MoveToHost(%[[NC]]) {backend_config = ""} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // CHECK-NEXT: return %[[MOVE_TO_HOST]] : tensor<8x2xi32>
+  %0 = call @bar(%arg0) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {"y"}]>]>, random_attr = "random_value", mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"}} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  %1 = stablehlo.custom_call @MoveToHost(%0) {backend_config = ""} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  return %1 : tensor<8x2xi32>
+}
+
+// NOTE: we ignore any arg/result shardings on the function.
+// CHECK-NOT: func private @bar
+func.func private @bar(%arg0: tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {}]>}) -> (tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"y"}]>}) {
+  %0 = stablehlo.multiply %arg0, %arg0 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  return %0 : tensor<8x2xi32>
+}
+
+// CHECK-LABEL: func @inlineable_false
+func.func @inlineable_false(%arg0: tensor<8x2xi32>, %arg1: tensor<8x2xi32>) -> (tensor<8x2xi32>) {
+  // CHECK-NEXT: %[[NC:.*]]:2 = sdy.named_computation<"baz">(%arg0, %arg1) out_shardings=[<@mesh, [{"x"}, {}]>, <@mesh, [{}, {"y"}]>] (%arg2: tensor<8x2xi32>, %arg3: tensor<8x2xi32>) {
+  // CHECK-NEXT:   %[[MULT:.*]] = stablehlo.multiply %arg2, %arg3 : tensor<8x2xi32>
+  // CHECK-NEXT:   sdy.return %[[MULT]], %arg3 : tensor<8x2xi32>, tensor<8x2xi32>
+  // CHECK-NEXT: } {mhlo.frontend_attributes = {inlineable = "false"}}
+  // CHECK-SAME: (tensor<8x2xi32>, tensor<8x2xi32>) -> (tensor<8x2xi32>, tensor<8x2xi32>)
+  // CHECK-NEXT: %[[ADD:.*]] = stablehlo.add %[[NC]]#0, %[[NC]]#1 : tensor<8x2xi32>
+  // CHECK-NEXT: return %[[ADD]] : tensor<8x2xi32>
+  %0:2 = call @baz(%arg0, %arg1) {mhlo.frontend_attributes = {inlineable = "false"}, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {}]>, <@mesh, [{}, {"y"}]>]>} : (tensor<8x2xi32>, tensor<8x2xi32>) -> (tensor<8x2xi32>, tensor<8x2xi32>)
+  %1 = stablehlo.add %0#0, %0#1 : tensor<8x2xi32>
+  return %1 : tensor<8x2xi32>
+}
+
+// CHECK-NOT: func private @baz
+func.func private @baz(%arg0: tensor<8x2xi32>, %arg1: tensor<8x2xi32>) -> (tensor<8x2xi32>, tensor<8x2xi32>) {
+  %0 = stablehlo.multiply %arg0, %arg1 : tensor<8x2xi32>
+  return %0, %arg1 : tensor<8x2xi32>, tensor<8x2xi32>
+}
+
+// CHECK-LABEL: func @inlineable_true
+func.func @inlineable_true(%arg0: tensor<8x2xi32>, %arg1: tensor<8x2xi32>) -> (tensor<8x2xi32>) {
+  // CHECK-NEXT: %[[CALL:.*]]:2 =  call @qux(%arg0, %arg1) {mhlo.frontend_attributes = {inlineable = "true"}, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {}]>, <@mesh, [{}, {"y"}]>]>}
+  // CHECK-NEXT: %[[ADD:.*]] = stablehlo.add %[[CALL]]#0, %[[CALL]]#1 : tensor<8x2xi32>
+  // CHECK-NEXT: return %[[ADD]] : tensor<8x2xi32>
+  %0:2 = call @qux(%arg0, %arg1) {mhlo.frontend_attributes = {inlineable = "true"}, sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {}]>, <@mesh, [{}, {"y"}]>]>} : (tensor<8x2xi32>, tensor<8x2xi32>) -> (tensor<8x2xi32>, tensor<8x2xi32>)
+  %1 = stablehlo.add %0#0, %0#1 : tensor<8x2xi32>
+  return %1 : tensor<8x2xi32>
+}
+
+// CHECK: func private @qux
+func.func private @qux(%arg0: tensor<8x2xi32>, %arg1: tensor<8x2xi32>) -> (tensor<8x2xi32>, tensor<8x2xi32>) {
+  %0 = stablehlo.multiply %arg0, %arg1 : tensor<8x2xi32>
+  return %0, %arg1 : tensor<8x2xi32>, tensor<8x2xi32>
+}
+
+// Don't import if there is no backend_config or inlineable attr.
+// CHECK-LABEL: func @no_backend_config_or_inlineable_attr
+func.func @no_backend_config_or_inlineable_attr(%arg0: tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) -> (tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) {
+  // CHECK-NEXT: %[[CALL:.*]] = call @quux(%arg0) : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // CHECK-NEXT: return %[[CALL]] : tensor<8x2xi32>
+  %0 = call @quux(%arg0) : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  return %0 : tensor<8x2xi32>
+}
+
+// CHECK: func private @quux
+func.func private @quux(%arg0: tensor<8x2xi32>) -> tensor<8x2xi32> {
+  %0 = stablehlo.multiply %arg0, %arg0 : tensor<8x2xi32>
+  return %0 : tensor<8x2xi32>
+}
+
+// -----
+
+sdy.mesh @mesh = #sdy.mesh<["x"=2, "y"=2]>
+
+// CHECK-LABEL: func @multiple_call_ops_same_name
+func.func @multiple_call_ops_same_name(%arg0: tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) -> (tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {"y"}]>}) {
+  // CHECK-NEXT: %[[NC_0:.*]] = sdy.named_computation<"foobar">(%arg0) out_shardings=[<@mesh, [{"x"}, {"y"}]>] (%arg1: tensor<8x2xi32>) {
+  // CHECK-NEXT:   %[[MULT_0:.*]] = stablehlo.multiply %arg1, %arg1 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  // CHECK-NEXT:   sdy.return %[[MULT_0]] : tensor<8x2xi32>
+  // CHECK-NEXT: } {mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"},
+  // CHECK-SAME:    random_attr = "random_value"}
+  // CHECK-SAME: (tensor<8x2xi32>) -> tensor<8x2xi32>
+
+  // CHECK-NEXT: %[[NC_1:.*]] = sdy.named_computation<"foobar">(%[[NC_0]]) out_shardings=[<@mesh, [{"x"}, {"y"}]>] (%arg1: tensor<8x2xi32>) {
+  // CHECK-NEXT:   %[[MULT_1:.*]] = stablehlo.multiply %arg1, %arg1 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  // CHECK-NEXT:   sdy.return %[[MULT_1]] : tensor<8x2xi32>
+  // CHECK-NEXT: } {mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"},
+  // CHECK-SAME:    random_attr = "random_value"}
+  // CHECK-SAME: (tensor<8x2xi32>) -> tensor<8x2xi32>
+
+  // CHECK-NEXT: %[[MOVE_TO_HOST:.*]] = stablehlo.custom_call @MoveToHost(%[[NC_1]]) {backend_config = ""} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // CHECK-NEXT: return %[[MOVE_TO_HOST]] : tensor<8x2xi32>
+  %0 = call @foobar(%arg0) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {"y"}]>]>, random_attr = "random_value", mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"}} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  // expected-warning @+1 {{uninlineable function @foobar has multiple call ops, we need to clone the function body for each call}}
+  %1 = call @foobar(%0) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}, {"y"}]>]>, random_attr = "random_value", mhlo.frontend_attributes = {backend_config = "{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}"}} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  %2 = stablehlo.custom_call @MoveToHost(%1) {backend_config = ""} : (tensor<8x2xi32>) -> tensor<8x2xi32>
+  return %2 : tensor<8x2xi32>
+}
+
+// CHECK-NOT: func private @foobar
+func.func private @foobar(%arg0: tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}, {}]>}) -> (tensor<8x2xi32> {sdy.sharding = #sdy.sharding<@mesh, [{}, {"y"}]>}) {
+  %0 = stablehlo.multiply %arg0, %arg0 {mhlo.frontend_attributes = {_xla_compute_type = "host"}} : tensor<8x2xi32>
+  return %0 : tensor<8x2xi32>
+}
diff --git a/shardy/round_trip_import/test/sdy_round_trip_import_pipeline.mlir b/shardy/round_trip_import/test/sdy_round_trip_import_pipeline.mlir
new file mode 100644
index 0000000..86f6082
--- /dev/null
+++ b/shardy/round_trip_import/test/sdy_round_trip_import_pipeline.mlir
@@ -0,0 +1,174 @@
+// RUN: sdy_opt %s --split-input-file -sdy-round-trip-import-pipeline 2>&1 | FileCheck %s
+
+// CHECK-LABEL: module @multiple_func_result_shardings
+module @multiple_func_result_shardings attributes {mhlo.frontend_attributes = {xla.sdy.meshes =
+    "{mesh = #sdy.mesh<[\\\22a\\\22=8, \\\22b\\\22=8, \\\22c\\\22=8]>, mesh2 = #sdy.mesh<[\\\22a\\\22=1, \\\22b\\\22=4, \\\22c\\\22=1]>}"}} {
+  // CHECK: sdy.mesh @mesh = <["a"=8, "b"=8, "c"=8]>
+
+  // CHECK: sdy.mesh @mesh2 = <["a"=1, "b"=4, "c"=1]>
+
+  // CHECK-LABEL: func @func_results_with_sharding
+  // CHECK-SAME:    %arg0: tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"b"}p2]>},
+  // CHECK-SAME:    %arg1: tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p1]>},
+  // CHECK-SAME:    %arg2: tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"c"}p0]>}
+  // CHECK-SAME:  ) -> (
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p0]>},
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"b"}p2]>},
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p1]>},
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"c"}p0]>},
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"b"}p2]>},
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p3]>}) {
+  // CHECK-NEXT:   return %arg0, %arg1, %arg0, %arg1, %arg1, %arg2
+  // CHECK-NEXT: }
+  func.func @func_results_with_sharding(
+    %arg0: tensor<32xi32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\\\22b\\\22}p2]>"}},
+    %arg1: tensor<32xi32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\\\22a\\\22}p1]>"}},
+    %arg2: tensor<32xi32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\\\22c\\\22}p0]>"}}
+  ) -> (tensor<32xi32>, tensor<32xi32>, tensor<32xi32>, tensor<32xi32>, tensor<32xi32>, tensor<32xi32>) {
+    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p0]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %1 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg1) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22b\\\22}p2]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %2 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p1]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %3 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg1) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22c\\\22}p0]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %4 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg2) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p3]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    return %0, %1, %2, %3, %1, %4 : tensor<32xi32>, tensor<32xi32>, tensor<32xi32>, tensor<32xi32>, tensor<32xi32>, tensor<32xi32>
+  }
+
+  // This might happen due to inlined funcs that originally had result shardings
+  // CHECK-LABEL: func @func_result_shardings_used_by_other_ops(
+  // CHECK-SAME:    %arg0: tensor<32xi32>, %arg1: tensor<32xi32>
+  // CHECK-SAME:  ) -> (
+  // CHECK-SAME:    tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"b"}p2]>},
+  // CHECK-SAME:    tensor<32xi32>) {
+  // CHECK-NEXT:   %[[ADD:.*]] =  stablehlo.add %arg0, %arg1
+  // CHECK-NEXT:   return %arg0, %[[ADD]]
+  // CHECK-NEXT: }
+  func.func @func_result_shardings_used_by_other_ops(
+    %arg0: tensor<32xi32>, %arg1: tensor<32xi32>
+  ) -> (tensor<32xi32>, tensor<32xi32>) {
+    %0 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p0]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %1 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22b\\\22}p2]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %2 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%arg1) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p3]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %3 = stablehlo.add %1, %2 : tensor<32xi32>
+    return %1, %3 : tensor<32xi32>, tensor<32xi32>
+  }
+
+  // CHECK-LABEL: func @while_with_sinked_constants
+  func.func @while_with_sinked_constants(%arg0: tensor<32x96xf32>) -> tensor<32x96xf32> {
+    // CHECK-NEXT: %[[C0:.*]] = stablehlo.constant dense<0>
+    // CHECK-NEXT: %[[WHILE:.*]]:2 = stablehlo.while(%iterArg = %arg0, %iterArg_0 = %[[C0]])
+    // CHECK-NEXT:   cond {
+    // CHECK-NEXT:   %[[C32:.*]] = stablehlo.constant dense<32>
+    // CHECK-NEXT:   %[[COND:.*]] = stablehlo.compare LT, %iterArg_0, %[[C32]]
+    // CHECK-NEXT:   stablehlo.return %[[COND]]
+    // CHECK-NEXT: } do {
+    // CHECK-NEXT:   %[[C1:.*]] = stablehlo.constant dense<1>
+    // CHECK-NEXT:   %[[ADD_0:.*]] = stablehlo.add %iterArg_0, %[[C1]]
+    // CHECK-NEXT:   %[[ADD_1:.*]] = stablehlo.add %iterArg, %iterArg
+    // CHECK-NEXT:   stablehlo.return %[[ADD_1]], %[[ADD_0]]
+    // CHECK-NEXT: }
+    // CHECK-NEXT: return %[[WHILE]]#0
+    %0 = stablehlo.constant dense<0> : tensor<i32>
+    %1:2 = stablehlo.while(%iterArg = %arg0, %iterArg_0 = %0) : tensor<32x96xf32>, tensor<i32>
+      cond {
+      %2 = stablehlo.constant dense<32> : tensor<i32>
+      %3 = stablehlo.compare LT, %iterArg_0, %2 : (tensor<i32>, tensor<i32>) -> tensor<i1>
+      stablehlo.return %3 : tensor<i1>
+    } do {
+      %2 = stablehlo.constant dense<1> : tensor<i32>
+      %3 = stablehlo.add %iterArg_0, %2 : tensor<i32>
+      %4 = stablehlo.add %iterArg, %iterArg : tensor<32x96xf32>
+      stablehlo.return %4, %3 : tensor<32x96xf32>, tensor<i32>
+    }
+    return %1#0 : tensor<32x96xf32>
+  }
+
+  // CHECK-LABEL: func @discard_shardings_on_unknown_ops(
+  // CHECK-SAME: %arg0: tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p0]>})
+  // CHECK-SAME: -> (tensor<32xi32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p4]>}) {
+  func.func @discard_shardings_on_unknown_ops(
+    %arg0: tensor<32xi32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<@mesh, [{\\\22a\\\22}p0]>"}}
+  ) -> tensor<32xi32> {
+    // CHECK-NEXT: %[[ADD:.*]] = stablehlo.add %arg0, %arg0 : tensor<32xi32>
+    // CHECK-NEXT: %[[SHARDING:.*]] = sdy.sharding_constraint %[[ADD]] <@mesh, [{"a"}p2]> : tensor<32xi32>
+    // CHECK-NEXT: %[[UNKNOWN:.*]] = stablehlo.custom_call @UnknownCustomCall(%[[SHARDING]]) : (tensor<32xi32>) -> tensor<32xi32>
+    // CHECK-NEXT: return %[[UNKNOWN]]
+    %0 = stablehlo.add %arg0, %arg0 {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p1]>]>"}} : tensor<32xi32>
+    %1 = stablehlo.custom_call @Sharding(%0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p2]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %2 = stablehlo.custom_call @UnknownCustomCall(%1) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p3]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %3 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%2) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<@mesh, [{\\\22a\\\22}p4]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    return %3 : tensor<32xi32>
+  }
+
+  // CHECK-LABEL: func @inlined_mesh(
+  // CHECK-SAME: %arg0: tensor<32xi32> {sdy.sharding = #sdy.sharding<mesh<["a"=2, "b"=2]>, [{"a"}]>})
+  // CHECK-SAME: -> (tensor<32xi32> {sdy.sharding = #sdy.sharding<mesh<[], device_ids=[5]>, []>}) {
+  func.func @inlined_mesh(
+    %arg0: tensor<32xi32> {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding<mesh<[\\\22a\\\22=2, \\\22b\\\22=2]>, [{\\\22a\\\22}]>"}}
+  ) -> tensor<32xi32> {
+    // CHECK-NEXT: %[[SHARDING:.*]] = sdy.sharding_constraint %arg0 <mesh<["c"=4]>, [{"c"}]> : tensor<32xi32>
+    // CHECK-NEXT: return %[[SHARDING]]
+    %0 = stablehlo.custom_call @Sharding(%arg0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<mesh<[\\\22c\\\22=4]>, [{\\\22c\\\22}]>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    %1 = stablehlo.custom_call @xla.sdy.FuncResultSharding(%0) {mhlo.frontend_attributes = {xla.sdy.sharding = "#sdy.sharding_per_value<[<mesh<[], device_ids=[5]>, []>]>"}} : (tensor<32xi32>) -> tensor<32xi32>
+    return %1 : tensor<32xi32>
+  }
+}
+
+// -----
+
+// CHECK-NOT: sdy.mesh @mesh
+
+module @no_meshes_module attributes {mhlo.frontend_attributes = {xla.sdy.meshes = "{}"}} {
+  // CHECK-LABEL: func @no_sharding_rule
+  func.func @no_sharding_rule(%arg0: tensor<8x2xf32>, %arg1: tensor<8x2xf32>) -> tensor<8x2xf64> {
+    // CHECK-NEXT: stablehlo.custom_call @foo(%arg0, %arg1) : (tensor<8x2xf32>, tensor<8x2xf32>) -> tensor<8x2xf64>
+    %0 = stablehlo.custom_call @foo(%arg0, %arg1) : (tensor<8x2xf32>, tensor<8x2xf32>) -> tensor<8x2xf64>
+   return %0 : tensor<8x2xf64>
+  }
+
+  // CHECK-LABEL: func @op_sharding_rule
+  func.func @op_sharding_rule(%arg0: tensor<8x2xf32>, %arg1: tensor<8x2xf32>) -> tensor<8x2xf64> {
+    // CHECK-NEXT: stablehlo.custom_call @foo(%arg0, %arg1) {sdy.sharding_rule = #sdy.op_sharding_rule<([i, j], [i, j])->([i, j]) {i=8, j=2}>}
+    %0 = stablehlo.custom_call @foo(%arg0, %arg1)
+      {mhlo.frontend_attributes = {xla.sdy.sharding_rule = "#sdy.op_sharding_rule<([i, j], [i, j])->([i, j]) {i=8, j=2}>"}} : (tensor<8x2xf32>, tensor<8x2xf32>) -> tensor<8x2xf64>
+    return %0 : tensor<8x2xf64>
+  }
+}
+
+// -----
+
+// CHECK-NOT: sdy.mesh @mesh
+
+module @no_meshes_attr_module {
+  // CHECK-LABEL: func @op_sharding_rule
+  func.func @op_sharding_rule(%arg0: tensor<8x2xf32>, %arg1: tensor<8x2xf32>) -> tensor<8x2xf64> {
+    // CHECK-NEXT: stablehlo.custom_call @foo(%arg0, %arg1) {sdy.sharding_rule = #sdy.op_sharding_rule<([i, j], [i, j])->([i, j]) {i=8, j=2}>}
+    %0 = stablehlo.custom_call @foo(%arg0, %arg1)
+      {mhlo.frontend_attributes = {xla.sdy.sharding_rule = "#sdy.op_sharding_rule<([i, j], [i, j])->([i, j]) {i=8, j=2}>"}} : (tensor<8x2xf32>, tensor<8x2xf32>) -> tensor<8x2xf64>
+    return %0 : tensor<8x2xf64>
+  }
+}
+
+// -----
+
+// CHECK-LABEL: func @import_sharding_group
+// CHECK-SAME:      %arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {
+func.func @import_sharding_group(%arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {
+  // CHECK sdy.sharding_group %arg0 group_id = 21:  tensor<8x8xf32>
+  stablehlo.custom_call @xla.sdy.ShardingGroup(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding_group_id = "21 : i64"}} : (tensor<8x8xf32>) -> ()
+  return %arg0 : tensor<8x8xf32>
+}
+
+// -----
+
+func.func @callback_no_result(%arg0: tensor<f64>) {
+  // CHECK:      %[[C:.*]] = stablehlo.constant
+  // CHECK-NEXT: stablehlo.custom_call @xla_python_cpu_callback(%[[C]], %arg0) {
+  // CHECK-SAME:   api_version = 2 : i32, backend_config = "56238273106176",
+  // CHECK-SAME:   has_side_effect = true,
+  // CHECK-SAME:   operand_layouts = [dense<> : tensor<0xindex>, dense<> : tensor<0xindex>],
+  // CHECK-SAME:   result_layouts = []
+  // CHECK-SAME: } : (tensor<i64>, tensor<f64>) -> ()
+  %c = stablehlo.constant dense<56238273106176> : tensor<i64>
+  stablehlo.custom_call @xla_python_cpu_callback(%c, %arg0) {api_version = 2 : i32, backend_config = "56238273106176", has_side_effect = true, operand_layouts = [dense<> : tensor<0xindex>, dense<> : tensor<0xindex>], result_layouts = []} : (tensor<i64>, tensor<f64>) -> ()
+  return
+}
diff --git a/shardy/round_trip_import/test/sdy_round_trip_shard_map_import.mlir b/shardy/round_trip_import/test/sdy_round_trip_shard_map_import.mlir
new file mode 100644
index 0000000..87e56b3
--- /dev/null
+++ b/shardy/round_trip_import/test/sdy_round_trip_shard_map_import.mlir
@@ -0,0 +1,250 @@
+// RUN: sdy_opt %s -sdy-round-trip-shard-map-import 2>&1 | FileCheck %s
+
+sdy.mesh @mesh_0 = <["a"=4, "b"=2]>
+sdy.mesh @mesh_1 = <["a"=2, "b"=2, "c"=2, "d"=2]>
+
+// CHECK-LABEL: func @single_manual_comp
+func.func @single_manual_comp(%arg0: tensor<8x16xf32>, %arg1: tensor<16x32xf32>) -> (tensor<8x32xf32>) {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body
+  // CHECK:               %[[MAN_COMP:.*]] = sdy.manual_computation(%arg0, %arg1)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_0, [{"a"}, {"b"}]>, <@mesh_0, [{"b"}, {}], replicated={"a"}>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_0, [{"a"}, {}], replicated={"b"}>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"a", "b"}
+  // CHECK-SAME:              (%arg2: tensor<2x8xf32>, %arg3: tensor<8x32xf32>) {
+  // CHECK-NEXT:            %[[ADD_0:.*]] = stablehlo.add %arg2, %arg2 : tensor<2x8xf32>
+  // CHECK-NEXT:            %[[DOT:.*]] = stablehlo.dot %[[ADD_0]], %arg3 : (tensor<2x8xf32>, tensor<8x32xf32>) -> tensor<2x32xf32>
+  // CHECK-NEXT:            %[[REDUCE:.*]] = "stablehlo.all_reduce"(%[[DOT]])
+  // CHECK-NEXT:            ^bb0(%arg4: tensor<f32>, %arg5: tensor<f32>):
+  // CHECK-NEXT:              %[[ADD_1:.*]] = stablehlo.add %arg4, %arg5 : tensor<f32>
+  // CHECK-NEXT:              stablehlo.return %[[ADD_1]] : tensor<f32>
+  // CHECK-NEXT:            }) : (tensor<2x32xf32>) -> tensor<2x32xf32>
+  // CHECK-NEXT:            sdy.return %[[REDUCE]] : tensor<2x32xf32>
+  // CHECK-NEXT:          } : (tensor<8x16xf32>, tensor<16x32xf32>) -> tensor<8x32xf32>
+  // CHECK-NEXT:          return %[[MAN_COMP]] : tensor<8x32xf32>
+  %0:2 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0, %arg1) : (tensor<8x16xf32>, tensor<16x32xf32>) -> (tensor<2x8xf32>, tensor<8x32xf32>)
+  %1 = call @xla.sdy.manual_computation_body(%0#0, %0#1) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {\\\22b\\\22}]>, <@mesh_0, [{\\\22b\\\22}, {}], replicated={\\\22a\\\22}>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22, \\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}], replicated={\\\22b\\\22}>]>"}} : (tensor<2x8xf32>, tensor<8x32xf32>) -> tensor<2x32xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x32xf32>) -> tensor<8x32xf32>
+  return %2 : tensor<8x32xf32>
+}
+
+// CHECK-LABEL: func @single_manual_comp_name_is_not_prefix_nor_suffix
+func.func @single_manual_comp_name_is_not_prefix_nor_suffix(%arg0: tensor<8x8xf32>) -> (tensor<8x8xf32>) {
+  // CHECK-NOT: call @my_model.___call__.fwd.xla.sdy.manual_computation_body_14.1234
+  // CHECK:               %[[MAN_COMP:.*]] = sdy.manual_computation(%arg0)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_0, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_0, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"a"}
+  // CHECK-SAME:              (%arg1: tensor<2x8xf32>) {
+  // CHECK-NEXT:            sdy.return %arg1 : tensor<2x8xf32>
+  // CHECK-NEXT:          } : (tensor<8x8xf32>) -> tensor<8x8xf32>
+  // CHECK-NEXT:          return %[[MAN_COMP]] : tensor<8x8xf32>
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<8x8xf32>) -> tensor<2x8xf32>
+  %1 = call @my_model.___call__.fwd.xla.sdy.manual_computation_body_14.1234(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}]>]>"}} : (tensor<2x8xf32>) -> tensor<2x8xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x8xf32>) -> tensor<8x8xf32>
+  return %2 : tensor<8x8xf32>
+}
+
+// CHECK-LABEL: func @manual_comp_using_another
+func.func @manual_comp_using_another(%arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body_0
+  // CHECK:               %[[MAN_COMP_0:.*]] = sdy.manual_computation(%arg0)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_0, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_0, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"a"}
+  // CHECK-SAME:              (%arg1: tensor<2x8xf32>) {
+  // CHECK-NEXT:            sdy.return %arg1 : tensor<2x8xf32>
+  // CHECK-NEXT:          } : (tensor<8x8xf32>) -> tensor<8x8xf32>
+  // CHECK-NOT: call @xla.sdy.manual_computation_body_1
+  // CHECK-NEXT:          %[[MAN_COMP_1:.*]] = sdy.manual_computation(%[[MAN_COMP_0]])
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_0, [{}, {"b"}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_0, [{}, {"b"}]>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"b"}
+  // CHECK-SAME:              (%arg1: tensor<8x4xf32>) {
+  // CHECK-NEXT:            sdy.return %arg1 : tensor<8x4xf32>
+  // CHECK-NEXT:          } : (tensor<8x8xf32>) -> tensor<8x8xf32>
+  // CHECK-NEXT:          return %[[MAN_COMP_1]] : tensor<8x8xf32>
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<8x8xf32>) -> tensor<2x8xf32>
+  %1 = call @xla.sdy.manual_computation_body_0(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}]>]>"}} : (tensor<2x8xf32>) -> tensor<2x8xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x8xf32>) -> tensor<8x8xf32>
+  %3 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%2) : (tensor<8x8xf32>) -> tensor<8x4xf32>
+  %4 = call @xla.sdy.manual_computation_body_1(%3) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{}, {\\\22b\\\22}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{}, {\\\22b\\\22}]>]>"}} : (tensor<8x4xf32>) -> tensor<8x4xf32>
+  %5 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%4) : (tensor<8x4xf32>) -> tensor<8x8xf32>
+  return %5 : tensor<8x8xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_3(
+func.func @xla.sdy.manual_computation_body_3(%arg0: tensor<2x8xf32>) -> tensor<2x8xf32> {
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<2x8xf32>) -> tensor<2x4xf32>
+  %1 = call @xla.sdy.manual_computation_body_2(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{}, {\\\22b\\\22}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{}, {\\\22b\\\22}]>]>"}} : (tensor<2x4xf32>) -> tensor<2x4xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x4xf32>) -> tensor<2x8xf32>
+  return %2 : tensor<2x8xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_2(
+func.func @xla.sdy.manual_computation_body_2(%arg0: tensor<2x4xf32>) -> tensor<2x4xf32> {
+  %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x4xf32>
+  return %0 : tensor<2x4xf32>
+}
+
+// CHECK-LABEL: func @nested_shmaps
+func.func @nested_shmaps(%arg0: tensor<4x8xf32>) -> tensor<4x8xf32> {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body_3
+  // CHECK:               %[[MAN_COMP_0:.*]] = sdy.manual_computation(%arg0)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_1, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_1, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"a"}
+  // CHECK-SAME:              (%arg1: tensor<2x8xf32>) {
+  // CHECK-NEXT:            %[[MAN_COMP_1:.*]] = sdy.manual_computation(%arg1)
+  // CHECK-SAME{LITERAL}:       in_shardings=[<@mesh_1, [{}, {"b"}]>]
+  // CHECK-SAME{LITERAL}:       out_shardings=[<@mesh_1, [{}, {"b"}]>]
+  // CHECK-SAME{LITERAL}:       manual_axes={"b"}
+  // CHECK-SAME:                (%arg2: tensor<2x4xf32>) {
+  // CHECK-NEXT:              %[[MULT:.*]] = stablehlo.multiply %arg2, %arg2 : tensor<2x4xf32>
+  // CHECK-NEXT:              sdy.return %[[MULT]] : tensor<2x4xf32>
+  // CHECK-NEXT:            } : (tensor<2x8xf32>) -> tensor<2x8xf32>
+  // CHECK-NEXT:            sdy.return %[[MAN_COMP_1]] : tensor<2x8xf32>
+  // CHECK-NEXT:          } : (tensor<4x8xf32>) -> tensor<4x8xf32>
+  // CHECK-NEXT:          return %[[MAN_COMP_0]] : tensor<4x8xf32>
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<4x8xf32>) -> tensor<2x8xf32>
+  %1 = call @xla.sdy.manual_computation_body_3(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{\\\22a\\\22}, {}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{\\\22a\\\22}, {}]>]>"}} : (tensor<2x8xf32>) -> tensor<2x8xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x8xf32>) -> tensor<4x8xf32>
+  return %2 : tensor<4x8xf32>
+}
+
+// CHECK-LABEL: func @nested_shmaps_extra_op
+func.func @nested_shmaps_extra_op(%arg0: tensor<4x8xf32>) -> tensor<4x8xf32> {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body_5
+  // CHECK:               %[[MAN_COMP_0:.*]] = sdy.manual_computation(%arg0)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_1, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_1, [{"a"}, {}]>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"a"}
+  // CHECK-SAME:              (%arg1: tensor<2x8xf32>) {
+  // CHECK-NEXT:            %[[MAN_COMP_1:.*]] = sdy.manual_computation(%arg1)
+  // CHECK-SAME{LITERAL}:       in_shardings=[<@mesh_1, [{}, {"b"}]>]
+  // CHECK-SAME{LITERAL}:       out_shardings=[<@mesh_1, [{}, {"b"}]>]
+  // CHECK-SAME{LITERAL}:       manual_axes={"b"}
+  // CHECK-SAME:                (%arg2: tensor<2x4xf32>) {
+  // CHECK-NEXT:              %[[MULT:.*]] = stablehlo.multiply %arg2, %arg2 : tensor<2x4xf32>
+  // CHECK-NEXT:              sdy.return %[[MULT]] : tensor<2x4xf32>
+  // CHECK-NEXT:            } : (tensor<2x8xf32>) -> tensor<2x8xf32>
+  // CHECK-NEXT:            %[[ADD:.*]] = stablehlo.add %[[MAN_COMP_1]], %[[MAN_COMP_1]] : tensor<2x8xf32>
+  // CHECK-NEXT:            sdy.return %[[ADD]] : tensor<2x8xf32>
+  // CHECK-NEXT:          } : (tensor<4x8xf32>) -> tensor<4x8xf32>
+  // CHECK-NEXT:          return %[[MAN_COMP_0]] : tensor<4x8xf32>
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<4x8xf32>) -> tensor<2x8xf32>
+  %1 = call @xla.sdy.manual_computation_body_5(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{\\\22a\\\22}, {}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{\\\22a\\\22}, {}]>]>"}} : (tensor<2x8xf32>) -> tensor<2x8xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x8xf32>) -> tensor<4x8xf32>
+  return %2 : tensor<4x8xf32>
+}
+
+// CHECK-LABEL: func @manual_computation_no_inputs
+func.func @manual_computation_no_inputs() -> tensor<4xi64> {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body_6
+  // CHECK:               %[[SHMAP:.*]] = sdy.manual_computation()
+  // CHECK-SAME{LITERAL}:     in_shardings=[]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_0, [{"b"}]>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"b"}
+  // CHECK-SAME{LITERAL}:     () {
+  // CHECK-NEXT:            %[[C:.*]] = stablehlo.constant dense<[2, 3]> : tensor<2xi64>
+  // CHECK-NEXT:            sdy.return %[[C]] : tensor<2xi64>
+  // CHECK-NEXT:          } : () -> tensor<4xi64>
+  // CHECK-NEXT:          return %[[SHMAP]] : tensor<4xi64>
+  %0 = call @xla.sdy.manual_computation_body_6() {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22b\\\22}]>]>"}} : () -> tensor<2xi64>
+  %1 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%0) : (tensor<2xi64>) -> tensor<4xi64>
+  return %1 : tensor<4xi64>
+}
+
+// CHECK-LABEL: func @manual_computation_no_outputs
+func.func @manual_computation_no_outputs(%arg0: tensor<4xi64>) {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body_7
+  // CHECK:               sdy.manual_computation(%arg0)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_0, [{"b"}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[]
+  // CHECK-SAME{LITERAL}:     manual_axes={"b"}
+  // CHECK-SAME{LITERAL}:     (%arg1: tensor<2xi64>) {
+  // CHECK-NEXT:            stablehlo.custom_call @sdy_testonly(%arg1) : (tensor<2xi64>) -> ()
+  // CHECK-NEXT:            sdy.return
+  // CHECK-NEXT:          } : (tensor<4xi64>) -> ()
+  // CHECK-NEXT:          return
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<4xi64>) -> tensor<2xi64>
+  call @xla.sdy.manual_computation_body_7(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22b\\\22}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[]>"}} : (tensor<2xi64>) -> ()
+  return
+}
+
+// CHECK-LABEL: func @manual_computation_zero_dim_inputs
+func.func @manual_computation_zero_dim_inputs(%arg0: tensor<0x16xf32>, %arg1: tensor<16x32xf32>) -> (tensor<0x32xf32>) {
+  // CHECK-NOT: call @xla.sdy.manual_computation_body
+  // CHECK:               %[[MAN_COMP:.*]] = sdy.manual_computation(%arg0, %arg1)
+  // CHECK-SAME{LITERAL}:     in_shardings=[<@mesh_0, [{}, {"b"}]>, <@mesh_0, [{"b"}, {}]>]
+  // CHECK-SAME{LITERAL}:     out_shardings=[<@mesh_0, [{}, {}], replicated={"b"}>]
+  // CHECK-SAME{LITERAL}:     manual_axes={"b"}
+  // CHECK-SAME:              (%arg2: tensor<0x8xf32>, %arg3: tensor<8x32xf32>) {
+  // CHECK-NEXT:            %[[DOT:.*]] = stablehlo.dot %arg2, %arg3
+  // CHECK-NEXT:            sdy.return %[[DOT]]
+  // CHECK-NEXT:          } : (tensor<0x16xf32>, tensor<16x32xf32>) -> tensor<0x32xf32>
+  // CHECK-NEXT:          return %[[MAN_COMP]]
+  %c = stablehlo.constant dense<0.000000e+00> : tensor<0x8xf32>
+  %0:2 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0, %arg1) : (tensor<0x16xf32>, tensor<16x32xf32>) -> (tensor<0x8xf32>, tensor<8x32xf32>)
+  %1 = call @xla.sdy.manual_computation_body_8(%c, %0#1) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{}, {\\\22b\\\22}]>, <@mesh_0, [{\\\22b\\\22}, {}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{}, {}], replicated={\\\22b\\\22}>]>"}} : (tensor<0x8xf32>, tensor<8x32xf32>) -> tensor<0x32xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<0x32xf32>) -> tensor<0x32xf32>
+  return %2 : tensor<0x32xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body(
+func.func @xla.sdy.manual_computation_body(%arg0: tensor<2x8xf32>, %arg1: tensor<8x32xf32>) -> tensor<2x32xf32> {
+  %0 = stablehlo.add %arg0, %arg0 : tensor<2x8xf32>
+  %1 = stablehlo.dot %0, %arg1 : (tensor<2x8xf32>, tensor<8x32xf32>) -> tensor<2x32xf32>
+  %2 = "stablehlo.all_reduce"(%1) <{replica_groups = dense<[[0], [1]]> : tensor<2x1xi64>}> ({
+  ^bb0(%arg2: tensor<f32>, %arg3: tensor<f32>):
+    %3 = stablehlo.add %arg2, %arg3 : tensor<f32>
+    stablehlo.return %3 : tensor<f32>
+  }) : (tensor<2x32xf32>) -> tensor<2x32xf32>
+  return %2 : tensor<2x32xf32>
+}
+
+func.func @my_model.___call__.fwd.xla.sdy.manual_computation_body_14.1234(%arg0: tensor<2x8xf32>) -> tensor<2x8xf32> {
+  return %arg0 : tensor<2x8xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_0(
+func.func @xla.sdy.manual_computation_body_0(%arg0: tensor<2x8xf32>) -> tensor<2x8xf32> {
+  return %arg0 : tensor<2x8xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_1(
+func.func @xla.sdy.manual_computation_body_1(%arg0: tensor<8x4xf32>) -> tensor<8x4xf32> {
+  return %arg0 : tensor<8x4xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_4(
+func.func @xla.sdy.manual_computation_body_4(%arg0: tensor<2x4xf32>) -> tensor<2x4xf32> {
+  %0 = stablehlo.multiply %arg0, %arg0 : tensor<2x4xf32>
+  return %0 : tensor<2x4xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_5(
+func.func @xla.sdy.manual_computation_body_5(%arg0: tensor<2x8xf32>) -> tensor<2x8xf32> {
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<2x8xf32>) -> tensor<2x4xf32>
+  %1 = call @xla.sdy.manual_computation_body_4(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{}, {\\\22b\\\22}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_1, [{}, {\\\22b\\\22}]>]>"}} : (tensor<2x4xf32>) -> tensor<2x4xf32>
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x4xf32>) -> tensor<2x8xf32>
+  %3 = stablehlo.add %2, %2 : tensor<2x8xf32>
+  return %3 : tensor<2x8xf32>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_6(
+func.func @xla.sdy.manual_computation_body_6() -> tensor<2xi64> {
+  %c = stablehlo.constant dense<[2, 3]> : tensor<2xi64>
+  return %c : tensor<2xi64>
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_7(
+func.func @xla.sdy.manual_computation_body_7(%arg0: tensor<2xi64>) {
+  stablehlo.custom_call @sdy_testonly(%arg0) : (tensor<2xi64>) -> ()
+  return
+}
+
+// CHECK-NOT: func @xla.sdy.manual_computation_body_7(
+func.func @xla.sdy.manual_computation_body_8(%arg0: tensor<0x8xf32>, %arg1: tensor<8x32xf32>) -> tensor<0x32xf32> {
+  %0 = stablehlo.dot %arg0, %arg1 : (tensor<0x8xf32>, tensor<8x32xf32>) -> tensor<0x32xf32>
+  return %0 : tensor<0x32xf32>
+}
diff --git a/shardy/round_trip_import/test/sdy_round_trip_shard_map_import_failure.mlir b/shardy/round_trip_import/test/sdy_round_trip_shard_map_import_failure.mlir
new file mode 100644
index 0000000..fa9fce9
--- /dev/null
+++ b/shardy/round_trip_import/test/sdy_round_trip_shard_map_import_failure.mlir
@@ -0,0 +1,19 @@
+// RUN: sdy_opt %s -sdy-round-trip-shard-map-import -split-input-file -verify-diagnostics
+
+sdy.mesh @mesh = <["a"=2]>
+
+func.func @using_same_body_func(%arg0: tensor<8x8xf32>) -> tensor<8x8xf32> {
+  %0 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%arg0) : (tensor<8x8xf32>) -> (tensor<2x8xf32>)
+  %1 = call @xla.sdy.manual_computation_body(%0) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {\\\22b\\\22}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22, \\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}], replicated={\\\22b\\\22}>]>"}} : (tensor<2x8xf32>) -> (tensor<2x8xf32>)
+  %2 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%1) : (tensor<2x8xf32>) -> (tensor<8x8xf32>)
+  %3 = stablehlo.custom_call @xla.sdy.GlobalToLocalShape(%2) : (tensor<8x8xf32>) -> (tensor<2x8xf32>)
+  // expected-error @+2 {{'func.call' op expected a unique FuncOp per @xla.sdy.manual_computation_body call}}
+  // expected-error @+1 {{failed to legalize operation 'func.call'}}
+  %4 = call @xla.sdy.manual_computation_body(%3) {mhlo.frontend_attributes = {xla.sdy.in_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {\\\22b\\\22}]>]>", xla.sdy.manual_axes = "#sdy<manual_axes{\\\22a\\\22, \\\22b\\\22}>", xla.sdy.out_shardings = "#sdy.sharding_per_value<[<@mesh_0, [{\\\22a\\\22}, {}], replicated={\\\22b\\\22}>]>"}} : (tensor<2x8xf32>) -> (tensor<2x8xf32>)
+  %5 = stablehlo.custom_call @xla.sdy.LocalToGlobalShape(%4) : (tensor<2x8xf32>) -> (tensor<8x8xf32>)
+  return %5 : tensor<8x8xf32>
+}
+
+func.func @xla.sdy.manual_computation_body(%arg0: tensor<2x8xf32>) -> tensor<2x8xf32> {
+  return %arg0 : tensor<2x8xf32>
+}
diff --git a/shardy/round_trip_import/test/sdy_round_trip_sharding_group_import_failure.mlir b/shardy/round_trip_import/test/sdy_round_trip_sharding_group_import_failure.mlir
new file mode 100644
index 0000000..36352d4
--- /dev/null
+++ b/shardy/round_trip_import/test/sdy_round_trip_sharding_group_import_failure.mlir
@@ -0,0 +1,18 @@
+// RUN: sdy_opt %s -sdy-import-sdy-custom-calls -split-input-file -verify-diagnostics
+
+func.func @sharding_group_import_failure_if_no_group_id(%arg0: tensor<16x16xf32>) -> tensor<16x16xf32> {
+  // expected-error @+2 {{failed to legalize operation 'stablehlo.custom_call' that was explicitly marked illegal}}
+  // expected-error @+1 {{expected CustomCallOp with a sharding group id.}}
+  stablehlo.custom_call @xla.sdy.ShardingGroup(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {}} : (tensor<16x16xf32>) -> ()
+  return %arg0 : tensor<16x16xf32>
+}
+
+// -----
+
+func.func @sharding_group_import_with_used_result(%arg0: tensor<8x8xf32>) -> tuple<tuple<>> {
+  // expected-error @+2 {{failed to legalize operation 'stablehlo.custom_call' that was explicitly marked illegal}}
+  // expected-error @+1 {{xla.sdy.ShardingGroup CustomCallOp should have no uses.}}
+  %0 = stablehlo.custom_call @xla.sdy.ShardingGroup(%arg0) {has_side_effect = true, mhlo.frontend_attributes = {xla.sdy.sharding_group_id = "21 : i64"}} : (tensor<8x8xf32>) -> tuple<>
+  %1 = "stablehlo.tuple"(%0) : (tuple<>) -> tuple<tuple<>>
+  return %1 : tuple<tuple<>>
+}
diff --git a/shardy/round_trip_import/utils.cc b/shardy/round_trip_import/utils.cc
new file mode 100644
index 0000000..3d8a5e3
--- /dev/null
+++ b/shardy/round_trip_import/utils.cc
@@ -0,0 +1,162 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "shardy/round_trip_import/utils.h"
+
+#include <cstdint>
+#include <functional>
+#include <string>
+
+#include "llvm/ADT/ArrayRef.h"
+#include "llvm/ADT/SmallVector.h"
+#include "llvm/ADT/StringRef.h"
+#include "mlir/Dialect/Func/IR/FuncOps.h"
+#include "mlir/IR/Attributes.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/IR/Operation.h"
+#include "mlir/IR/PatternMatch.h"
+#include "mlir/IR/TypeRange.h"
+#include "mlir/Support/LLVM.h"
+#include "shardy/round_trip_import/constants.h"
+#include "stablehlo/dialect/StablehloOps.h"
+
+namespace mlir {
+namespace sdy {
+
+using ::mlir::func::FuncOp;
+using ::mlir::stablehlo::CustomCallOp;
+
+DictionaryAttr getFrontendAttrs(Operation* op) {
+  return op->getAttrOfType<DictionaryAttr>(kFrontendAttributesAttr);
+}
+
+DictionaryAttr getFuncArgFrontendAttrs(FuncOp funcOp, unsigned int index) {
+  return funcOp.getArgAttrOfType<DictionaryAttr>(index,
+                                                 kFrontendAttributesAttr);
+}
+
+namespace {
+
+SmallVector<NamedAttribute> getExistingFrontendAttributes(
+    DictionaryAttr frontendAttributes, StringRef excludedAttribute) {
+  SmallVector<NamedAttribute> dictEntries;
+  if (!frontendAttributes) {
+    return dictEntries;
+  }
+  for (NamedAttribute entry : frontendAttributes) {
+    if (entry.getName() != excludedAttribute) {
+      dictEntries.push_back(entry);
+    }
+  }
+  return dictEntries;
+}
+
+void removeFrontendAttribute(
+    DictionaryAttr frontendAttributes, StringRef attributeName,
+    std::function<void(ArrayRef<NamedAttribute>)> setAttr,
+    std::function<void()> removeAttr) {
+  SmallVector<NamedAttribute> existingAttributes =
+      getExistingFrontendAttributes(frontendAttributes, attributeName);
+  if (!existingAttributes.empty()) {
+    setAttr(existingAttributes);
+  } else {
+    removeAttr();
+  }
+}
+
+void setFrontendAttrs(Operation* op, ArrayRef<NamedAttribute> frontendAttrs) {
+  return op->setAttr(kFrontendAttributesAttr,
+                     DictionaryAttr::get(op->getContext(), frontendAttrs));
+}
+
+void setFuncArgFrontendAttrs(FuncOp funcOp, unsigned int index,
+                             ArrayRef<NamedAttribute> frontendAttrs) {
+  funcOp.setArgAttr(index, kFrontendAttributesAttr,
+                    DictionaryAttr::get(funcOp.getContext(), frontendAttrs));
+}
+
+}  // namespace
+
+void removeFrontendAttribute(Operation* op, StringRef attributeName) {
+  removeFrontendAttribute(
+      getFrontendAttrs(op), attributeName,
+      [&](ArrayRef<NamedAttribute> newDict) { setFrontendAttrs(op, newDict); },
+      [&]() { op->removeAttr(kFrontendAttributesAttr); });
+}
+
+void removeFrontendAttribute(FuncOp funcOp, StringRef attributeName,
+                             int64_t argNum) {
+  removeFrontendAttribute(
+      getFuncArgFrontendAttrs(funcOp, argNum), attributeName,
+      [&](ArrayRef<NamedAttribute> newDict) {
+        setFuncArgFrontendAttrs(funcOp, argNum, newDict);
+      },
+      [&]() { funcOp.removeArgAttr(argNum, kFrontendAttributesAttr); });
+}
+
+bool hasFrontendAttr(Operation* op, StringRef key) {
+  return hasKey(getFrontendAttrs(op), key);
+}
+
+bool hasKey(DictionaryAttr dictAttr, StringRef key) {
+  return dictAttr && dictAttr.contains(key);
+}
+
+bool isPythonCallbackCustomCall(stablehlo::CustomCallOp op) {
+  StringRef targetName = op.getCallTargetName();
+  return targetName == kPythonCpuCallbackCustomCallTargetName ||
+         targetName == kPythonGpuCallbackCustomCallTargetName ||
+         targetName == kFFIPythonCpuCallbackCustomCallTargetName ||
+         targetName == kFFIPythonGpuCallbackCustomCallTargetName;
+}
+
+std::string cunescape(llvm::StringRef escapedValue) {
+  std::string unescapedValue;
+  unescapedValue.reserve(escapedValue.size());
+
+  for (int i = 0; i < escapedValue.size(); i++) {
+    if (escapedValue[i] == '\\' && i + 1 < escapedValue.size()) {
+      switch (escapedValue[i + 1]) {
+        case 'n':
+          unescapedValue += '\n';
+          break;
+
+        case 't':
+          unescapedValue += '\t';
+          break;
+
+        case '\\':
+          unescapedValue += '\\';
+          break;
+        case '"':
+          unescapedValue += '"';
+          break;
+
+        default:
+          unescapedValue += escapedValue[i];
+          i--;  // To accommodate i++ after this.
+          break;
+      }
+      i++;
+    } else {
+      unescapedValue += escapedValue[i];
+    }
+  }
+
+  return unescapedValue;
+}
+
+}  // namespace sdy
+}  // namespace mlir
diff --git a/shardy/round_trip_import/utils.h b/shardy/round_trip_import/utils.h
new file mode 100644
index 0000000..89a7e2e
--- /dev/null
+++ b/shardy/round_trip_import/utils.h
@@ -0,0 +1,91 @@
+/* Copyright 2025 The Shardy Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SHARDY_ROUND_TRIP_IMPORT_UTILS_H_
+#define SHARDY_ROUND_TRIP_IMPORT_UTILS_H_
+
+#include <cstdint>
+#include <optional>
+#include <string>
+
+#include "mlir/AsmParser/AsmParser.h"
+#include "mlir/Dialect/Func/IR/FuncOps.h"
+#include "mlir/IR/Attributes.h"
+#include "mlir/IR/Builders.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/IR/MLIRContext.h"
+#include "mlir/IR/PatternMatch.h"
+#include "mlir/IR/TypeRange.h"
+#include "mlir/Support/LLVM.h"
+#include "stablehlo/dialect/StablehloOps.h"
+
+namespace mlir {
+namespace sdy {
+
+// Gets the "frontend_attributes" `DictionaryAttr` from `op`. If it doesn't
+// exist, return nullptr.
+DictionaryAttr getFrontendAttrs(Operation* op);
+
+// Gets the `frontend_attributes` `DictionaryAttr` from `funcOp`'s arg at
+// `index`. If it doesn't exist, return nullptr.
+DictionaryAttr getFuncArgFrontendAttrs(func::FuncOp funcOp, unsigned int index);
+
+// Remove `attributeName` from the frontend attributes of `op`.
+void removeFrontendAttribute(Operation* op, StringRef attributeName);
+
+// Remove `attributeName` from the argument at `argNum`'s frontend attributes
+// of `funcOp`.
+void removeFrontendAttribute(func::FuncOp funcOp, StringRef attributeName,
+                             int64_t argNum);
+
+// Checks if "frontend_attributes" `DictionaryAttr` from `op` contains `key`.
+bool hasFrontendAttr(Operation* op, StringRef key);
+
+// Checks if `dictAttr` exists and contains `key`.
+bool hasKey(DictionaryAttr dictAttr, StringRef key);
+
+std::string cunescape(llvm::StringRef escapedValue);
+
+// Parses `attrName` from `dictAttr` to an attribute of type `AttrTy`.
+template <typename AttrTy>
+AttrTy parseStringAttr(DictionaryAttr dictAttr, llvm::StringRef attrName) {
+  if (Attribute stringAttr = dictAttr.get(attrName)) {
+    std::string unescapedValue =
+        cunescape(cast<StringAttr>(stringAttr).getValue());
+    return cast<AttrTy>(
+        parseAttribute(unescapedValue, stringAttr.getContext()));
+  }
+  return nullptr;
+}
+
+// Checks if `op`'s "frontend_attributes" `DictionaryAttr` contains `attrName`
+// and parses it to an attribute of type `AttrTy`. If it doesn't exist, then
+// returns std::nullopt.
+template <typename AttrTy>
+std::optional<AttrTy> tryGetFrontendAttr(Operation* op, StringRef attrName) {
+  DictionaryAttr dictAttr = getFrontendAttrs(op);
+  if (hasKey(dictAttr, attrName)) {
+    return parseStringAttr<AttrTy>(dictAttr, attrName);
+  }
+  return std::nullopt;
+}
+
+// Whether `op` is a Python callback custom call.
+bool isPythonCallbackCustomCall(stablehlo::CustomCallOp op);
+
+}  // namespace sdy
+}  // namespace mlir
+
+#endif  // SHARDY_ROUND_TRIP_IMPORT_UTILS_H_
diff --git a/shardy/tools/BUILD b/shardy/tools/BUILD
index a51ddd0..cde5dfe 100644
--- a/shardy/tools/BUILD
+++ b/shardy/tools/BUILD
@@ -10,6 +10,7 @@ cc_binary(
     deps = [
         "//shardy/dialect/sdy/ir:register",
         "//shardy/dialect/sdy/transforms:passes",
+        "//shardy/round_trip_import:pipelines",
         "@llvm-project//mlir:AllPassesAndDialects",
         "@llvm-project//mlir:FuncExtensions",
         "@llvm-project//mlir:IR",
diff --git a/shardy/tools/sdy_opt_main.cc b/shardy/tools/sdy_opt_main.cc
index 154f4a9..e771629 100644
--- a/shardy/tools/sdy_opt_main.cc
+++ b/shardy/tools/sdy_opt_main.cc
@@ -25,6 +25,7 @@ limitations under the License.
 #include "mlir/Tools/mlir-opt/MlirOptMain.h"
 #include "shardy/dialect/sdy/ir/register.h"
 #include "shardy/dialect/sdy/transforms/passes.h"
+#include "shardy/round_trip_import/pipelines.h"

 int main(int argc, char** argv) {
   mlir::registerAllPasses();
@@ -37,6 +38,9 @@ int main(int argc, char** argv) {
   // Register all SDY passes and pipelines.
   mlir::sdy::registerAllSdyPassesAndPipelines();

+  // Register all SDY round-trip-import passes and the pipeline.
+  mlir::sdy::registerAllSdyRoundTripImportPassesAndPipeline();
+
   return mlir::asMainReturnCode(
       mlir::MlirOptMain(argc, argv, "SDY pass driver\n", registry));
 }
--
2.25.1
