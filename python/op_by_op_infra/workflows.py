# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

"""
This file exposes hooks into op by op infra, aka workflows for frontends to use.
It is meant to simplify and abstract away all complexities of the infra.
"""

from typing import List, Optional

import ttmlir.workflow_utils as workflow_utils
from ttmlir.ir import Module

from .pydantic_models import OpTest


def split_and_execute(
    module: Module | str,
    *,
    full_test_name: Optional[str] = None,
    filepath: Optional[str] = None,
    frontend: Optional[str] = None,
    model_name: Optional[str] = None,
) -> List[OpTest]:
    """
    Splits the original `module` (SHLO/TTIR/TTNN) into constituent operations, compiles
    each of them down to TTNN graph, creates flatbuffer from it and runs it on device.

    This workflow is meant to track execution progress of individual ops from original
    module.

    Parameters
    ----------
    module: Module | str
        Original MLIR module (or module str) processed by the workflow.

    full_test_name: Optional[str]
        Path to the model test file + additional suffix specifying test uniquely.

    filepath: Optional[str]
        Path to the file in which test is written.

    frontend: Optional[str]
        Name of the frontend using op by op infra.

    model_name: Optional[str]
        Name of the ML model which was passed as original MLIR module to the workflow.

    Returns
    -------
    List[OpTest]
        List of `OpTest` pydantic models, each holding info for one particular
        constituent op.
    """
    execution_results = workflow_utils.split_and_execute(module)
    return workflow_utils.convert_results_to_pydantic_models(
        execution_results,
        full_test_name=full_test_name,
        filepath=filepath,
        frontend=frontend,
        model_name=model_name,
    )


def compile_split_and_execute(
    module: Module | str,
    *,
    full_test_name: Optional[str] = None,
    filepath: Optional[str] = None,
    frontend: Optional[str] = None,
    model_name: Optional[str] = None,
) -> List[OpTest]:
    """
    Compiles the original `module` (SHLO/TTIR/TTNN) down to TTNN graph, splits it into
    constituent operations, creates flatbuffer for each of them and runs it on device.

    This workflow is meant to track execution progress of individual ops from TTNN graph
    generated by compiling original module.

    Parameters
    ----------
    module: Module | str
        Original MLIR module (or module str) processed by the workflow.

    full_test_name: Optional[str]
        Path to the model test file + additional suffix specifying test uniquely.

    filepath: Optional[str]
        Path to the file in which test is written.

    frontend: Optional[str]
        Name of the frontend using op by op infra.

    model_name: Optional[str]
        Name of the ML model which was passed as original MLIR module to the workflow.

    Returns
    -------
    List[OpTest]
        List of `OpTest` pydantic models, each holding info for one particular
        constituent op.
    """
    execution_results = workflow_utils.compile_split_and_execute(module)
    return workflow_utils.convert_results_to_pydantic_models(
        execution_results,
        full_test_name=full_test_name,
        filepath=filepath,
        frontend=frontend,
        model_name=model_name,
    )


def split_compile_split_and_execute(
    module: Module | str,
    *,
    full_test_name: Optional[str] = None,
    filepath: Optional[str] = None,
    frontend: Optional[str] = None,
    model_name: Optional[str] = None,
) -> List[OpTest]:
    """
    Splits the original `module` (SHLO/TTIR/TTNN) into constituent operations, compiles
    each of them down to TTNN graph, splits it into constituent TTNN operations, creates
    flatbuffer for each of them and runs it on device.

    This workflow is meant to track execution progress of individual ops from TTNN graph
    generated by compiling individual ops from original module.

    Parameters
    ----------
    module: Module | str
        Original MLIR module (or module str) processed by the workflow.

    full_test_name: Optional[str]
        Path to the model test file + additional suffix specifying test uniquely.

    filepath: Optional[str]
        Path to the file in which test is written.

    frontend: Optional[str]
        Name of the frontend using op by op infra.

    model_name: Optional[str]
        Name of the ML model which was passed as original MLIR module to the workflow.

    Returns
    -------
    List[OpTest]
        List of `OpTest` pydantic models, each holding info for one particular
        constituent TTNN op.
    """
    execution_results = workflow_utils.split_compile_split_and_execute(module)
    return workflow_utils.convert_results_to_pydantic_models(
        execution_results,
        full_test_name=full_test_name,
        filepath=filepath,
        frontend=frontend,
        model_name=model_name,
    )
