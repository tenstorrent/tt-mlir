// SPDX-FileCopyrightText: (c) 2024 Tenstorrent AI ULC
//
// SPDX-License-Identifier: Apache-2.0

#include "ttmlir/Conversion/StableHLOToTTIR/ShardingUtils.h"

#include "mlir/IR/BuiltinTypes.h"
#include "mlir/IR/Operation.h"
#include "mlir/IR/Value.h"
#include "mlir/Transforms/DialectConversion.h"
#include "llvm/ADT/SmallVector.h"

#include <numeric>

namespace mlir {
namespace tt {
namespace sharding_utils {

// Parse GSPMD devices string and fill out MeshSharding info.
llvm::Expected<bool> MeshSharding::parseGSPMDDevicesStr(StringRef devicesStr) {
  // This function extract dimensions from targetDimsStr "[x,y,z]" and saves it
  // to targetDims.
  auto parseDimsFromDimensionStr =
      [](StringRef targetDimsStr, SmallVector<int64_t> &targetDims) -> bool {
    if (!targetDimsStr.consume_front("[") || !targetDimsStr.consume_back("]")) {
      return false;
    }
    SmallVector<StringRef> dimsStr;
    targetDimsStr.split(dimsStr, ",");
    targetDims.clear();
    for (auto dim : dimsStr) {
      int64_t d;
      if (dim.getAsInteger<int64_t>(10, d)) {
        return false;
      }
      targetDims.push_back(d);
    }
    return true;
  };

  // devicesStr is generated by splitting whole string using space " ". Thus, it
  // is not supposed to include any trailing space. e.g., "[4,2,1]<=[2,4]T(1,0)"
  auto [axesStr, restStr] = devicesStr.split("<=");
  // Parse devices string before "<=" e.g., [4,2,1].
  if (!parseDimsFromDimensionStr(axesStr, shardShape)) {
    return llvm::createStringError("Fail to parse GSPMD devices axes string: " +
                                   axesStr);
  }
  // Parse devices string after "<=" e.g., [8] or [2,4]T(1,0).
  auto [reshapeStr, unused] = restStr.split("T");
  // Parse reshape[0] string e.g., [8] or [2,4].
  if (!parseDimsFromDimensionStr(reshapeStr, meshShape)) {
    return llvm::createStringError(
        "Fail to parse GSPMD devices reshape string: " + reshapeStr);
  }
  return true;
}

// Based on current MeshSharding info, finalize sharding dimensions.
llvm::Expected<bool> MeshSharding::determineGSPMDShardingDims() {
  // This code is based on following assumption.
  // 1. Hardware mesh is two dimenion such as 2x4, 1x2, ...
  // 2. Hardware mesh only supports either line or mesh config
  // e.g., t3k 1x8 or 2x4
  SmallVector<int64_t> orgShardShape = shardShape;
  if (lastTileDimReplicate) {
    shardShape.pop_back();
  }
  // Determine obvious properties first.
  bool reverseOrder = meshShape.size() != 1;
  // totalDevices is the total number of multi-chips such as 8 for t3k. Thus, no
  // overflow is expected with int64_t.
  int64_t totalDevices =
      std::accumulate(meshShape.begin(), meshShape.end(), int64_t{1},
                      std::multiplies<int64_t>());
  // Detect line device config (1xN).
  bool isLineDeviceConfig =
      llvm::any_of(orgShardShape, [&](int64_t s) { return s == totalDevices; });
  // Detect hardware mesh. For reverse order sharding, meshShape already
  // includes hardware mesh. For non reverse order case, extract hardware mesh
  // by traversing from front to back and picking none-zero values.
  if (!reverseOrder) {
    if (isLineDeviceConfig) {
      // Device with line config must be 1xN, not Nx1.
      meshShape = {1, meshShape[0]};
    } else {
      meshShape.clear();
      // e.g., orgShardShape [1,2,4] or [2,1,4] leads to [2,4]
      llvm::copy_if(orgShardShape, std::back_inserter(meshShape),
                    [](int64_t s) { return s != int64_t{1}; });
    }
  }

  if (meshShape.size() != 2) {
    // Currently, we are only supporting 2d hardware mesh config.
    return llvm::createStringError(
        "Only support 2d hardware mesh config. mesh.size()=%d",
        meshShape.size());
  }

  // Determine shardDims based on the shardShape and meshShape.
  // shard_dims indicate in which dimension we shard the tensor. For T3K,
  // detected meshShape will be [2, 4] and shard_dims will be [ a, b ] depending
  // on the sharding intention.
  // For example, if shardShape is [1,2,1,4], shard_dims is supposed to be [1,
  // 3] or if shardShape is [1,4,1,2], then shard_dims should be [3, 1].
  shardDims.assign(meshShape.size(), -1);
  // Skip the first 1 of 1xN hardware.
  uint64_t shardingCnt = isLineDeviceConfig;
  for (uint64_t i = 0; i < shardShape.size(); ++i) {
    // Check sharding dimension only.
    if (shardShape[i] != 1) {
      auto shardDimIdx =
          (reverseOrder) ? (meshShape.size() - 1 - shardingCnt) : shardingCnt;
      // Positive shardShape[i] and meshShape[shardDimIdx] is supposed to be
      // identical.
      if (shardShape[i] > 0 && shardShape[i] != meshShape[shardDimIdx]) {
        return llvm::createStringError(
            "Fail to determine shardDims. shardShape[%d] (%d) != meshShape[%d] "
            "(%d)",
            i, shardShape[i], shardDimIdx, meshShape[shardDimIdx]);
      }
      shardDims[shardDimIdx] = i;
      shardingCnt++;
    }
  }

  return true;
}

// OpenXLA has its own lexer, but we will use simple string-based parser here.
// This parsing is mainly based on "Sharding Attribute" section in
// https://github.com/sdasgup3/stablehlo/blob/80082431d1af0933e6202ecc8a6f8801e039235b/docs/spec.md#sharding-attribute
llvm::Expected<bool>
MeshSharding::convertGSPMDShardingToMeshSharding(StringRef shardingStr) {
  shardType = mlir::tt::MeshShardType::Manual;
  lastTileDimReplicate = false;

  // Parse string and tokenize.
  if (!shardingStr.consume_front("{") || !shardingStr.consume_back("}")) {
    return llvm::createStringError(std::errc::invalid_argument,
                                   "Fail to parse GSPMD sharding.");
  }
  SmallVector<StringRef> shardingStrTokens;
  shardingStr.split(shardingStrTokens, " ");

  // Parse string tokens.
  for (auto str : shardingStrTokens) {
    if (str.contains("manual")) {
      // manual: already sharded, so no action is needed
      if (shardType != tt::MeshShardType::Manual) {
        return llvm::createStringError(std::errc::invalid_argument,
                                       "Fail to parse GSPMD sharding.");
      }
      setNonDevicesShardType(tt::MeshShardType::Manual);
    } else if (str.contains("replicated")) {
      // replicated: all devices have whole data
      if (shardType != tt::MeshShardType::Manual) {
        return llvm::createStringError(std::errc::invalid_argument,
                                       "Fail to parse GSPMD sharding.");
      }
      setNonDevicesShardType(tt::MeshShardType::Replicate);
    } else if (str.contains("maximal")) {
      // maximal: one device has whole data
      if (shardType != tt::MeshShardType::Manual) {
        return llvm::createStringError(std::errc::invalid_argument,
                                       "Fail to parse GSPMD sharding.");
      }
      setNonDevicesShardType(tt::MeshShardType::Maximal);
    } else if (str.consume_front("device=")) {
      // maximal should followed by "device" to put data on
      if (shardType != tt::MeshShardType::Maximal) {
        return llvm::createStringError(std::errc::invalid_argument,
                                       "Fail to parse GSPMD sharding.");
      }
      int64_t d;
      if (str.getAsInteger<int64_t>(10, d)) {
        return llvm::createStringError(std::errc::invalid_argument,
                                       "Fail to parse GSPMD sharding.");
      }
      deviceIds.push_back(d);
    } else if (str.consume_front("devices=")) {
      // other: "devices" detail sharding plan
      if (shardType != tt::MeshShardType::Manual) {
        return llvm::createStringError(std::errc::invalid_argument,
                                       "Fail to parse GSPMD sharding.");
      }
      shardType = tt::MeshShardType::Devices;
      auto error = parseGSPMDDevicesStr(str);
      if (auto e = error.takeError()) {
        return e;
      }
    } else if (str.contains("last_tile_dim_replicate")) {
      // other: replicate last tile dim
      if (shardType != tt::MeshShardType::Devices) {
        return llvm::createStringError(
            std::errc::invalid_argument,
            "Fail to parse GSPMD sharding in last_tile_dim_replicate.");
      }
      lastTileDimReplicate = true;
    } else {
      return llvm::createStringError("Unknown GSPMD sharding: " + str);
    }
  }

  // Determine shard dims for devices.
  if (shardType == tt::MeshShardType::Devices) {
    auto error = determineGSPMDShardingDims();
    if (auto e = error.takeError()) {
      return e;
    }
  }

  return true;
}

// Convert sdy.sharding to meshSharding based on sdy::MeshAttr.
llvm::Expected<bool> MeshSharding::convertSdyShardingToMeshSharding(
    sdy::TensorShardingAttr sdySharding, sdy::MeshAttr meshAttr,
    tt::MeshShardDirection direction) {

  shardDirection = direction;

  if (meshAttr.getAxes().empty()) {
    if (meshAttr.getDeviceIds().empty()) {
      // replicated
      setNonDevicesShardType(mlir::tt::MeshShardType::Replicate);
    } else {
      // maximal
      setNonDevicesShardType(mlir::tt::MeshShardType::Maximal);
      deviceIds = llvm::SmallVector<int64_t>(meshAttr.getDeviceIds());
    }
    return true;
  }

  shardType = tt::MeshShardType::Devices;
  shardShape.assign(sdySharding.getRank(), 1);
  shardDims.assign(meshAttr.getAxes().size(), -1);

  llvm::SmallDenseMap<::llvm::StringRef, int64_t> axisPosition;
  for (auto [idx, meshAxisAttr] : llvm::enumerate(meshAttr.getAxes())) {
    axisPosition[meshAxisAttr.getName()] = idx;
    meshShape.push_back(meshAxisAttr.getSize());
  }

  if (!sdySharding.isFullyClosed()) {
    return llvm::createStringError(
        "Sharding with open dimension is currently not supported.");
  }

  // Iterate each dimSharding in TensorShardingAttr
  for (auto [dimIdx, dimSharding] :
       llvm::enumerate(sdySharding.getDimShardings())) {
    for (auto [axisIdx, axes] : llvm::enumerate(dimSharding.getAxes())) {
      // Check if there is any subaxis sharding
      if (auto subAxis = axes.getSubAxisInfo()) {
        return llvm::createStringError(
            "Sharding with subaxis partitioning is currently not supported.");
      }
      shardShape[dimIdx] *= axes.getSize(meshAttr);
      // Sharding makes sense when it is higher than 1.
      if (axes.getSize(meshAttr) > 1) {
        shardDims[axisPosition[axes.getName()]] = dimIdx;
      }
    }
  }

  // totalPartition is the total number of multi-chips such as 8 for t3k. Thus,
  // no overflow is expected with int64_t.
  int64_t totalPartition =
      std::accumulate(shardShape.begin(), shardShape.end(), int64_t{1},
                      std::multiplies<int64_t>());
  // No partition indicates replicate to all devices.
  if (totalPartition == 1) {
    setNonDevicesShardType(mlir::tt::MeshShardType::Replicate);
  }

  return true;
}

} // namespace sharding_utils
} // namespace tt
} // namespace mlir
